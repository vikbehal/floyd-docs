{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nWelcome to \nFloydHub\n! Here you'll find comprehensive information for training and deploying your deep learning and AI applications with our platform. We've tried to make this documentation user-friendly and example-filled, but if you have any questions, please visit the \ncommunity forum\n or \ncontact us\n.\n\n\nThe fastest way to get up and running is to use our \nquickstart guide\n, which walks through an entire FloydHub training job step-by-step. You'll create a new Project on the FloydHub web dashboard, connect it to a local directory on your computer, and then kick-off a job using the FloydHub CLI to train your deep learning model on FloydHub's GPU servers.\n\n\nDeep learning without the DevOps:\n\n\nFrictionless data science\n\n\nWhy worry about provisioning GPUs, installing drivers, or managing software dependency hell? With FloydHub, we take care of your entire deep learning DevOps workflow - so you can focus on the science.\n\n\nTraining a TensorFlow model using GPUs on the cloud is as simple as executing this command on your terminal: \n\nfloyd run --gpu --env tensorflow \npython train.py\n. Try it now with our \nquickstart guide\n.\n\n\nPowerful workflow tools\n\n\nWhether you're using our web dashboard or our command line interface, our tools make your work easier and your team more productive:\n\n\n\n\nInteractive Jupyter Notebook support\n\n\nEnd-to-end version control for data science\n\n\nFull reproducibility of jobs\n\n\nDeploy models as REST endpoints to integrate with your apps\n\n\n\n\nDeep learning community\n\n\nFloydHub hosts open source Projects and Datasets that you can discover, clone, and reproduce (or reconfigure with your own Dataset).\n\n\nTry it now with the \nNeural Style Transfer\n.\n\n\n\n\n\n\n\n\nWe're here to help!\n\n\nWe're always happy to help with any questions you might have! \nSearch\n our documentation or check answers to \nfrequently asked questions\n. The \nFloydHub community forum\n is another place to ask questions, request features, or share cool Projects. For more help, \nsend us an email\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#introduction", 
            "text": "Welcome to  FloydHub ! Here you'll find comprehensive information for training and deploying your deep learning and AI applications with our platform. We've tried to make this documentation user-friendly and example-filled, but if you have any questions, please visit the  community forum  or  contact us .  The fastest way to get up and running is to use our  quickstart guide , which walks through an entire FloydHub training job step-by-step. You'll create a new Project on the FloydHub web dashboard, connect it to a local directory on your computer, and then kick-off a job using the FloydHub CLI to train your deep learning model on FloydHub's GPU servers.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#deep-learning-without-the-devops", 
            "text": "", 
            "title": "Deep learning without the DevOps:"
        }, 
        {
            "location": "/#frictionless-data-science", 
            "text": "Why worry about provisioning GPUs, installing drivers, or managing software dependency hell? With FloydHub, we take care of your entire deep learning DevOps workflow - so you can focus on the science.  Training a TensorFlow model using GPUs on the cloud is as simple as executing this command on your terminal:  floyd run --gpu --env tensorflow  python train.py . Try it now with our  quickstart guide .", 
            "title": "Frictionless data science"
        }, 
        {
            "location": "/#powerful-workflow-tools", 
            "text": "Whether you're using our web dashboard or our command line interface, our tools make your work easier and your team more productive:   Interactive Jupyter Notebook support  End-to-end version control for data science  Full reproducibility of jobs  Deploy models as REST endpoints to integrate with your apps", 
            "title": "Powerful workflow tools"
        }, 
        {
            "location": "/#deep-learning-community", 
            "text": "FloydHub hosts open source Projects and Datasets that you can discover, clone, and reproduce (or reconfigure with your own Dataset).  Try it now with the  Neural Style Transfer .", 
            "title": "Deep learning community"
        }, 
        {
            "location": "/#were-here-to-help", 
            "text": "We're always happy to help with any questions you might have!  Search  our documentation or check answers to  frequently asked questions . The  FloydHub community forum  is another place to ask questions, request features, or share cool Projects. For more help,  send us an email .", 
            "title": "We're here to help!"
        }, 
        {
            "location": "/getstarted/quick_start/", 
            "text": "Introduction\n\n\nWith this quickstart guide, we've tried to make it as easy as possible to get up and running with FloydHub.\n\n\nWe'll start with an overview of FloydHub and then jump into running your first job using TensorFlow and the MNIST dataset (better known as the \"Hello, world!\" of data science). We'll be training a convolutional neural network (CNN) model to recognize hand-written digits using FloydHub's GPU servers. For more details on the data and the model, please refer to the \nTensorflow documentation\n.\n\n\nPlatform overview\n\n\nTo help you get oriented with FloydHub, let's start by defining some basics:\n\n\nTools\n\n\n\n\nfloyd-cli\n: Convenient command line tool to interact with FloydHub from your terminal\n\n\nDashboard\n: Website to create, monitor, and explore Projects and Datasets\n\n\n\n\nFeatures\n\n\n\n\nJob\n: Command executed from the \nfloyd-cli\n with optional configurations (including mounting Datasets, importing libraries like TensorFlow or PyTorch, running in Jupyter Notebook mode, or processing on GPU instances)\n\n\nProject\n: Collection of Jobs and their corresponding code, Datasets, logs, and results\n\n\nDataset\n: Input data that can be connected to a Project via a Job\n\n\n\n\nSetting up your first Project on FloydHub\n\n\nQuick preparation checklist\n\n\n\n\nCreate a FloydHub account\n\n\nInstall \nfloyd-cli\n on your computer\n\n\nLog in to FloydHub through \nfloyd-cli\n\n\n\n\nGet the code\n\n\nClone the \nquick-start repository\n from GitHub onto your computer.\n\n\n$ git clone https://github.com/floydhub/quick-start.git\nCloning into \nquick-start\n...\n...\n$ \ncd\n quick-start\n\n\n\n\n$ ls\nLICENSE    mnist_cnn.py    mnist_cnn.ipynb    README.md\n\n\n\n\nThis repository contains two important files: \nmnist_cnn.py\n (a Python script to train a convolutional neural network model against the MNIST dataset) and \nmnist_cnn.ipynb\n (a Jupyter Notebook to interactively explore the MNIST dataset). \n\n\nIn this quickstart tutorial, we'll only be using the Python script. Our separate \nJupyter Notebook tutorial\n explains how to run this Project in Jupyter Notebook mode.\n\n\nInitialize your Project\n\n\nIf you're a new user, then you should already see a default Project named \nquick-start\n in your \nProjects dashboard\n.\n\n\n\n\nAlternatively, you can simply create a new Project named \nquick-start\n in the FloydHub Dashboard with these \ninstructions\n.\n\n\nWe'll need to link the Python model-training code with your \nquick-start\n Project on FloydHub. Use the \nfloyd init\n command in the current directory of your terminal to initialize your Project. \n\n\n$ floyd init quick-start\nProject \nquick-start\n initialized in the current directory\n\n\n\n\nThis tells FloydHub that all the Jobs you run from this local directory belong to your Project named \nquick-start\n.\n\n\nRunning your first Job\n\n\nRunning a job on FloydHub is simple - when you use the \nfloyd run\n command, the \nfloyd-cli\n tool syncs your code with FloydHub's servers and runs the command in the cloud. \n\n\nFloydHub will run any command you provide as a new Job - even a Job as simple as listing your current directory with the \nls\n command. However, FloydHub is specialized for running deep learning and data science processing commands.\n\n\nFor this tutorial, we'll run the \nmnist_cnn.py\n Python script on FloydHub's GPU servers to train our convolutional neural network model against the MNIST data.\n\n\n$ floyd run --gpu --env tensorflow \npython mnist_cnn.py\n\nSyncing code ...\nRUN ID                  NAME               \n----------------------  -------------------\nAKpnXqj9BEU6d8KhmygTyb  alice/quick-start/1\n\nTo view the logs enter:\n    floyd logs alice/quick-start/1\n\n\n\n\nCongratulations! Your first job is now running on FloydHub's GPU servers. Behind the scenes, FloydHub does the following:\n\n\n\n\nSyncs your local code to FloydHub's servers\n\n\nProvisions a GPU instance on the cloud (because you set the \n--gpu\n flag)\n\n\nSets up a deep learning environment with GPU drivers and Tensorflow installed (because you set the enviroment flag to \n--env tensorflow\n)\n\n\nExecutes the command \npython mnist_cnn.py\n inside this environment\n\n\nStores the output logs and generated output data\n\n\nTerminates the GPU instance once the command finishes execution\n\n\n\n\nMonitoring your Job\n\n\nYou can view the status of your Job from your terminal using the \nfloyd status\n command. You can specify a single Job name (e.g. \nfloyd status alice/quick-start/1\n) to get its status, or the \nfloyd-cli\n will show the status of all Jobs in the current Project.\n\n\n$ floyd status\nRUN ID                  CREATED        STATUS    DURATION\n(\ns\n)\n  NAME                 INSTANCE    DESCRIPTION\n----------------------  ---------      --------  -----------  -------------------  ---------   -----------\nAKpnXqj9BEU6d8KhmygTyb  just now       running            \n15\n  alice/quick-start:1  gpu         \n\n\n\n\nYou can also view the status of your job in your browser by visiting the \nJob URL\n printed by the \nfloyd run\n command. For example, \nhttps://www.floydhub.com/alice/quick-start/1\n\n\n\n\nViewing your Job's logs\n\n\nIt's easy to view the logs generated by the job from your terminal with the \nfloyd logs\n command. You'll need to specify the Job name in the command.\n\n\n$ floyd logs -t alice/quick-start/1\n...\n\n2017\n-07-12 \n16\n:00:07,446 INFO - Starting attempt \n1\n at \n2017\n-07-12 \n16\n:00:07.436349\n\n2017\n-07-12 \n16\n:00:09,088 INFO - Starting container...\n\n2017\n-07-12 \n16\n:00:09,297 INFO - \n...\n\n##############################################################################\n\n\n2017\n-07-12 \n16\n:00:09,297 INFO - Run Output:\n\n2017\n-07-12 \n16\n:01:46,154 INFO - Successfully downloaded train-images-idx3-ubyte.gz \n9912422\n bytes.\n\n2017\n-07-12 \n16\n:01:46,158 INFO - Iter \n1280\n, Minibatch \nLoss\n=\n \n39855\n.289062, Training \nAccuracy\n=\n \n0\n.17969\n\n2017\n-07-12 \n16\n:01:46,159 INFO - Iter \n2560\n, Minibatch \nLoss\n=\n \n14964\n.132812, Training \nAccuracy\n=\n \n0\n.42969\n...\n\n##############################################################################\n\n...\n\n\n\n\nThe output of your code is printed in the \nRun Output\n section of the logs, between the \n#########\n lines. Anything you log or print in your code will appear here, so this is a great way to monitor the progress of your model training command. In our \nquick-start\n project, we're logging the Training Accuracy of our model.\n\n\nUsing the \n-t\n (tail) flag will stream the logs as they are generated.\n\n\nYou can also view the logs in your browser using your \nJob URL\n. However, the logs in the Dashboard are not currently refreshed dynamically, so you'll need to refresh your browser periodically or press \nF5\n to get the latest logs from the Dashboard.\n\n\nViewing the Job output\n\n\nThe model that we trained in this quickstart tutorial does not save any new output models - instead it simply prints the model results to the logs. We'll explore how to save model outputs in the Jupyter Notebook tutorial.\n\n\nIterating on your Project\n\n\nCongratulations! You've run your first job on FloydHub \ud83c\udf89\n\n\nAt this point, you can edit your Python code locally to make improvements or adjustments, and then kick off a new Job with the \nfloyd run\n command. The \nfloyd-cli\n will upload the newest versions of your code and submit another Job to the FloydHub servers. Along the way, FloydHub will be managing and tracking of all the iterations of Jobs within your Project.\n\n\nYou can always view details on all of the Jobs in your current Project with the \nfloyd status\n command from your terminal, or by visiting the \nProject URL\n in your browser.\n\n\nExample: \nwww.floydhub.com/alice/quick-start\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Quick Start"
        }, 
        {
            "location": "/getstarted/quick_start/#introduction", 
            "text": "With this quickstart guide, we've tried to make it as easy as possible to get up and running with FloydHub.  We'll start with an overview of FloydHub and then jump into running your first job using TensorFlow and the MNIST dataset (better known as the \"Hello, world!\" of data science). We'll be training a convolutional neural network (CNN) model to recognize hand-written digits using FloydHub's GPU servers. For more details on the data and the model, please refer to the  Tensorflow documentation .", 
            "title": "Introduction"
        }, 
        {
            "location": "/getstarted/quick_start/#platform-overview", 
            "text": "To help you get oriented with FloydHub, let's start by defining some basics:", 
            "title": "Platform overview"
        }, 
        {
            "location": "/getstarted/quick_start/#tools", 
            "text": "floyd-cli : Convenient command line tool to interact with FloydHub from your terminal  Dashboard : Website to create, monitor, and explore Projects and Datasets", 
            "title": "Tools"
        }, 
        {
            "location": "/getstarted/quick_start/#features", 
            "text": "Job : Command executed from the  floyd-cli  with optional configurations (including mounting Datasets, importing libraries like TensorFlow or PyTorch, running in Jupyter Notebook mode, or processing on GPU instances)  Project : Collection of Jobs and their corresponding code, Datasets, logs, and results  Dataset : Input data that can be connected to a Project via a Job", 
            "title": "Features"
        }, 
        {
            "location": "/getstarted/quick_start/#setting-up-your-first-project-on-floydhub", 
            "text": "", 
            "title": "Setting up your first Project on FloydHub"
        }, 
        {
            "location": "/getstarted/quick_start/#quick-preparation-checklist", 
            "text": "Create a FloydHub account  Install  floyd-cli  on your computer  Log in to FloydHub through  floyd-cli", 
            "title": "Quick preparation checklist"
        }, 
        {
            "location": "/getstarted/quick_start/#get-the-code", 
            "text": "Clone the  quick-start repository  from GitHub onto your computer.  $ git clone https://github.com/floydhub/quick-start.git\nCloning into  quick-start ...\n...\n$  cd  quick-start  $ ls\nLICENSE    mnist_cnn.py    mnist_cnn.ipynb    README.md  This repository contains two important files:  mnist_cnn.py  (a Python script to train a convolutional neural network model against the MNIST dataset) and  mnist_cnn.ipynb  (a Jupyter Notebook to interactively explore the MNIST dataset).   In this quickstart tutorial, we'll only be using the Python script. Our separate  Jupyter Notebook tutorial  explains how to run this Project in Jupyter Notebook mode.", 
            "title": "Get the code"
        }, 
        {
            "location": "/getstarted/quick_start/#initialize-your-project", 
            "text": "If you're a new user, then you should already see a default Project named  quick-start  in your  Projects dashboard .   Alternatively, you can simply create a new Project named  quick-start  in the FloydHub Dashboard with these  instructions .  We'll need to link the Python model-training code with your  quick-start  Project on FloydHub. Use the  floyd init  command in the current directory of your terminal to initialize your Project.   $ floyd init quick-start\nProject  quick-start  initialized in the current directory  This tells FloydHub that all the Jobs you run from this local directory belong to your Project named  quick-start .", 
            "title": "Initialize your Project"
        }, 
        {
            "location": "/getstarted/quick_start/#running-your-first-job", 
            "text": "Running a job on FloydHub is simple - when you use the  floyd run  command, the  floyd-cli  tool syncs your code with FloydHub's servers and runs the command in the cloud.   FloydHub will run any command you provide as a new Job - even a Job as simple as listing your current directory with the  ls  command. However, FloydHub is specialized for running deep learning and data science processing commands.  For this tutorial, we'll run the  mnist_cnn.py  Python script on FloydHub's GPU servers to train our convolutional neural network model against the MNIST data.  $ floyd run --gpu --env tensorflow  python mnist_cnn.py \nSyncing code ...\nRUN ID                  NAME               \n----------------------  -------------------\nAKpnXqj9BEU6d8KhmygTyb  alice/quick-start/1\n\nTo view the logs enter:\n    floyd logs alice/quick-start/1  Congratulations! Your first job is now running on FloydHub's GPU servers. Behind the scenes, FloydHub does the following:   Syncs your local code to FloydHub's servers  Provisions a GPU instance on the cloud (because you set the  --gpu  flag)  Sets up a deep learning environment with GPU drivers and Tensorflow installed (because you set the enviroment flag to  --env tensorflow )  Executes the command  python mnist_cnn.py  inside this environment  Stores the output logs and generated output data  Terminates the GPU instance once the command finishes execution", 
            "title": "Running your first Job"
        }, 
        {
            "location": "/getstarted/quick_start/#monitoring-your-job", 
            "text": "You can view the status of your Job from your terminal using the  floyd status  command. You can specify a single Job name (e.g.  floyd status alice/quick-start/1 ) to get its status, or the  floyd-cli  will show the status of all Jobs in the current Project.  $ floyd status\nRUN ID                  CREATED        STATUS    DURATION ( s )   NAME                 INSTANCE    DESCRIPTION\n----------------------  ---------      --------  -----------  -------------------  ---------   -----------\nAKpnXqj9BEU6d8KhmygTyb  just now       running             15   alice/quick-start:1  gpu           You can also view the status of your job in your browser by visiting the  Job URL  printed by the  floyd run  command. For example,  https://www.floydhub.com/alice/quick-start/1", 
            "title": "Monitoring your Job"
        }, 
        {
            "location": "/getstarted/quick_start/#viewing-your-jobs-logs", 
            "text": "It's easy to view the logs generated by the job from your terminal with the  floyd logs  command. You'll need to specify the Job name in the command.  $ floyd logs -t alice/quick-start/1\n... 2017 -07-12  16 :00:07,446 INFO - Starting attempt  1  at  2017 -07-12  16 :00:07.436349 2017 -07-12  16 :00:09,088 INFO - Starting container... 2017 -07-12  16 :00:09,297 INFO - \n... ##############################################################################  2017 -07-12  16 :00:09,297 INFO - Run Output: 2017 -07-12  16 :01:46,154 INFO - Successfully downloaded train-images-idx3-ubyte.gz  9912422  bytes. 2017 -07-12  16 :01:46,158 INFO - Iter  1280 , Minibatch  Loss =   39855 .289062, Training  Accuracy =   0 .17969 2017 -07-12  16 :01:46,159 INFO - Iter  2560 , Minibatch  Loss =   14964 .132812, Training  Accuracy =   0 .42969\n... ############################################################################## \n...  The output of your code is printed in the  Run Output  section of the logs, between the  #########  lines. Anything you log or print in your code will appear here, so this is a great way to monitor the progress of your model training command. In our  quick-start  project, we're logging the Training Accuracy of our model.  Using the  -t  (tail) flag will stream the logs as they are generated.  You can also view the logs in your browser using your  Job URL . However, the logs in the Dashboard are not currently refreshed dynamically, so you'll need to refresh your browser periodically or press  F5  to get the latest logs from the Dashboard.", 
            "title": "Viewing your Job's logs"
        }, 
        {
            "location": "/getstarted/quick_start/#viewing-the-job-output", 
            "text": "The model that we trained in this quickstart tutorial does not save any new output models - instead it simply prints the model results to the logs. We'll explore how to save model outputs in the Jupyter Notebook tutorial.", 
            "title": "Viewing the Job output"
        }, 
        {
            "location": "/getstarted/quick_start/#iterating-on-your-project", 
            "text": "Congratulations! You've run your first job on FloydHub \ud83c\udf89  At this point, you can edit your Python code locally to make improvements or adjustments, and then kick off a new Job with the  floyd run  command. The  floyd-cli  will upload the newest versions of your code and submit another Job to the FloydHub servers. Along the way, FloydHub will be managing and tracking of all the iterations of Jobs within your Project.  You can always view details on all of the Jobs in your current Project with the  floyd status  command from your terminal, or by visiting the  Project URL  in your browser.  Example:  www.floydhub.com/alice/quick-start", 
            "title": "Iterating on your Project"
        }, 
        {
            "location": "/getstarted/quick_start/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/", 
            "text": "In this tutorial, we will run a Python \nJupyter Notebook\n on FloydHub. Notebooks allow you to create and share documents that contain live code, visualizations and explanatory texts. This is an \nexample Notebook\n. It is great for interactively writing and debugging your code and visualizing your results and data. \n\n\nSimilar to the \nQuick Start guide\n, we will train a CNN model for handwritten digit recognition using PyTorch and the MNIST database.\n\n\nIf you are new to FloydHub, please ensure you have followed the \nQuick Start guide\n first. It introduces some important concepts used in this tutorial.\n\n\nWhat we will accomplish in this guide\n\n\n\n\nLearn how to create a new project on FloydHub\n\n\nStart a Jupyter notebook on FloydHub's GPU server\n\n\nInteractively run and debug your code\n\n\nMount datasets to use in your code\n\n\n\n\nQuick preparation checklist\n\n\n\n\nYou must have a \nFloydHub account\n\n\nYou must have \nfloyd-cli\n \ninstalled on your computer\n\n\nYou must \nlog in to FloydHub through the CLI\n\n\n\n\nSetup\n\n\nCreate a new project\n\n\nFor this tutorial, we will create a new Project. This project will be a collection of the jobs you run and their data, logs and results.\n\n\nTo create a new Project, visit \nwww.floydhub.com/projects\n and click on the \"New Project\" button on the top right hand corner.\n\n\n\n\nWe will name this project \nmnist-pytorch\n. Feel free to provide an apt description.\n\n\nThe \nVisibility\n field indicates who can see your project. If you set it to \nPublic\n, anyone can see your project, your code and data. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your code or data is proprietary, please select \nPrivate\n. This will ensure that only you and your team will have access to this project.\n\n\nGet the code\n\n\nWe will clone the \nquick-start repository\n from Github to your local machine and run it on FloydHub. Run the \ngit clone\n command in a brand new directory on your computer:\n\n\n$ git clone https://github.com/floydhub/quick-start-pytorch.git\nCloning into \nquick-start-pytorch\n...\n$ \ncd\n quick-start-pytorch\n\n\n\n\n$ ls\n$ README.md mnist.ipynb\n\n\n\n\nIn this guide, we will use the \nmnist_cnn.ipynb\n Jupyter Notebook.\n\n\nInitialize new project\n\n\nNow that we have the code, we want to associate this directory with the new project you just created on FloydHub. Ensure that you are inside the \nquick-start-pytorch\n directory and execute:\n\n\n$ floyd init mnist-pytorch\nProject \nmnist-pytorch\n initialized in the current directory\n\n\n\n\nThis tells Floyd that all the jobs run from this directory belong to the same project.\n\n\nRunning Jupyter Notebook on FloydHub\n\n\nStarting a Jupyter Notebook on FloydHub is very simple. Use the \nfloyd run\n command with \n--mode jupyter\n flag.\n\n\nExecute the following command from the command line:\n\n\n$ floyd run --mode jupyter --gpu --env pytorch\nCreating project run. Total upload size: \n21\n.9KiB\nSyncing code ...\n\n[================================]\n \n23333\n/23333 - \n00\n:00:00\nRUN ID                  NAME\n----------------------  ---------------------\nMhDNgxBHi74EKaffBKSbTN  saip/mnist-pytorch/3\n\nSetting up your instance and waiting \nfor\n Jupyter notebook to become available ..............\n\nPath to jupyter notebook: https://www.floydhub.com/notebooks/pCoPyzZtYeo6mE9PpSWsmY\n\nTo view logs enter:\n    floyd logs saip/mnist-pytorch/3\n\nOpening the jupyter notebook in your browser now ...\n\n\n\n\nThis will take a little bit. As it executes, Floyd is doing the following behind the scenes:\n\n\n\n\nSync your local code to FloydHub's server\n\n\nProvision a GPU instance on the cloud (if you want CPU, drop the \n--gpu\n flag)\n\n\nSet up an deep learning environment with PyTorch installed (because \n--env pytorch\n)\n\n\nStart a Jupyter server on the cloud, and open the url in your browser\n\n\n\n\nYou can also open the link to the your Jupyter dashboard using the displayed URL. For example:\n\n\n\n\nOpen the \nmnist.ipynb\n Notebook and start training your model interactively!\n\n\nNext steps\n\n\nCheck the status of your job\n\n\nYou can view the status of your job from your terminal using the \nfloyd status\n command \n\n\n$ floyd status saip/mnist-pytorch/3\nRUN ID                  CREATED         STATUS      DURATION\n(\ns\n)\n  NAME                   INSTANCE    DESCRIPTION\n----------------------  --------------  --------  -------------  ---------------------  ----------  -------------\nMhDNgxBHi74EKaffBKSbTN  \n16\n minutes ago  running               \n0\n  saip/mnist-pytorch/3   gpu\n\n\n\n\nYou can also view the status by going to the project page in the web dashboard.\n\n\nStopping your Notebook\n\n\n\n\nWarning\n\n\nJupyter Notebooks are designed for interactive development. Your job starts running on FloydHub's server when you execute the \nfloyd run --mode jupyter\n command and it continues to be active till you explicitly stop your job.\n\n\nHence, even if you are not actively executing code inside your Notebook, the Jupyter server is still active on FloydHub and you are billed for the time.\n\n\n\n\nTo stop your notebook you can use the \nfloyd stop\n command.\n\n\n$ floyd stop saip/mnist-pytorch/3\nExperiment shutdown request submitted. Check status to confirm shutdown\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Jupyter Notebook"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#what-we-will-accomplish-in-this-guide", 
            "text": "Learn how to create a new project on FloydHub  Start a Jupyter notebook on FloydHub's GPU server  Interactively run and debug your code  Mount datasets to use in your code", 
            "title": "What we will accomplish in this guide"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#quick-preparation-checklist", 
            "text": "You must have a  FloydHub account  You must have  floyd-cli   installed on your computer  You must  log in to FloydHub through the CLI", 
            "title": "Quick preparation checklist"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#setup", 
            "text": "", 
            "title": "Setup"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#create-a-new-project", 
            "text": "For this tutorial, we will create a new Project. This project will be a collection of the jobs you run and their data, logs and results.  To create a new Project, visit  www.floydhub.com/projects  and click on the \"New Project\" button on the top right hand corner.   We will name this project  mnist-pytorch . Feel free to provide an apt description.  The  Visibility  field indicates who can see your project. If you set it to  Public , anyone can see your project, your code and data. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your code or data is proprietary, please select  Private . This will ensure that only you and your team will have access to this project.", 
            "title": "Create a new project"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#get-the-code", 
            "text": "We will clone the  quick-start repository  from Github to your local machine and run it on FloydHub. Run the  git clone  command in a brand new directory on your computer:  $ git clone https://github.com/floydhub/quick-start-pytorch.git\nCloning into  quick-start-pytorch ...\n$  cd  quick-start-pytorch  $ ls\n$ README.md mnist.ipynb  In this guide, we will use the  mnist_cnn.ipynb  Jupyter Notebook.", 
            "title": "Get the code"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#initialize-new-project", 
            "text": "Now that we have the code, we want to associate this directory with the new project you just created on FloydHub. Ensure that you are inside the  quick-start-pytorch  directory and execute:  $ floyd init mnist-pytorch\nProject  mnist-pytorch  initialized in the current directory  This tells Floyd that all the jobs run from this directory belong to the same project.", 
            "title": "Initialize new project"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#running-jupyter-notebook-on-floydhub", 
            "text": "Starting a Jupyter Notebook on FloydHub is very simple. Use the  floyd run  command with  --mode jupyter  flag.  Execute the following command from the command line:  $ floyd run --mode jupyter --gpu --env pytorch\nCreating project run. Total upload size:  21 .9KiB\nSyncing code ... [================================]   23333 /23333 -  00 :00:00\nRUN ID                  NAME\n----------------------  ---------------------\nMhDNgxBHi74EKaffBKSbTN  saip/mnist-pytorch/3\n\nSetting up your instance and waiting  for  Jupyter notebook to become available ..............\n\nPath to jupyter notebook: https://www.floydhub.com/notebooks/pCoPyzZtYeo6mE9PpSWsmY\n\nTo view logs enter:\n    floyd logs saip/mnist-pytorch/3\n\nOpening the jupyter notebook in your browser now ...  This will take a little bit. As it executes, Floyd is doing the following behind the scenes:   Sync your local code to FloydHub's server  Provision a GPU instance on the cloud (if you want CPU, drop the  --gpu  flag)  Set up an deep learning environment with PyTorch installed (because  --env pytorch )  Start a Jupyter server on the cloud, and open the url in your browser   You can also open the link to the your Jupyter dashboard using the displayed URL. For example:   Open the  mnist.ipynb  Notebook and start training your model interactively!", 
            "title": "Running Jupyter Notebook on FloydHub"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#next-steps", 
            "text": "", 
            "title": "Next steps"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#check-the-status-of-your-job", 
            "text": "You can view the status of your job from your terminal using the  floyd status  command   $ floyd status saip/mnist-pytorch/3\nRUN ID                  CREATED         STATUS      DURATION ( s )   NAME                   INSTANCE    DESCRIPTION\n----------------------  --------------  --------  -------------  ---------------------  ----------  -------------\nMhDNgxBHi74EKaffBKSbTN   16  minutes ago  running                0   saip/mnist-pytorch/3   gpu  You can also view the status by going to the project page in the web dashboard.", 
            "title": "Check the status of your job"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#stopping-your-notebook", 
            "text": "Warning  Jupyter Notebooks are designed for interactive development. Your job starts running on FloydHub's server when you execute the  floyd run --mode jupyter  command and it continues to be active till you explicitly stop your job.  Hence, even if you are not actively executing code inside your Notebook, the Jupyter server is still active on FloydHub and you are billed for the time.   To stop your notebook you can use the  floyd stop  command.", 
            "title": "Stopping your Notebook"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#floyd-stop-saipmnist-pytorch3-experiment-shutdown-request-submitted-check-status-to-confirm-shutdown", 
            "text": "", 
            "title": "$ floyd stop saip/mnist-pytorch/3"
        }, 
        {
            "location": "/getstarted/quick_start_jupyter/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/guides/basics/install/", 
            "text": "Floyd CLI is a python based command line tool to interact with FloydHub from your terminal.\n\n\nfloyd-cli\n is available on \npypi\n and\nruns on both Python 2.7 and Python 3.5.\n\n\nUse pip to install the CLI.\n\n\n$ pip install -U floyd-cli\n\n\n\n\nUse pip3 if you only want to install the CLI for python 3:\n\n\n$ pip3 install -U floyd-cli\n\n\n\n\nAfter installation you can view the commands supported by the CLI using the\n\n--help\n option.\n\n\n$ floyd --help\nUsage: floyd \n[\nOPTIONS\n]\n COMMAND \n[\nARGS\n]\n...\n\n  Floyd CLI interacts with Floyd server and executes your commands. More\n  \nhelp\n is available under each \ncommand\n listed below.\n\n...\n\n\n\n\nDetailed documentation for the floyd commands is available in the \ndocumentation\n.\n\n\nHaving trouble installing the CLI?\n\n\nSee the list of \nFAQs related to installation\n.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Install Floyd CLI"
        }, 
        {
            "location": "/guides/basics/install/#having-trouble-installing-the-cli", 
            "text": "See the list of  FAQs related to installation .", 
            "title": "Having trouble installing the CLI?"
        }, 
        {
            "location": "/guides/basics/install/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/guides/basics/login/", 
            "text": "Login using floyd-cli\n\n\nQuick Preparation Checklist\n\n\n\n\nYou must have a \nFloydHub account\n\n\nYou must be \nlogged in to your web dashboard\n\n\nYou must have \nfloyd-cli\n \ninstalled on your computer\n\n\n\n\nYou can use the \nfloyd login\n command to login to your FloydHub account through your command line\n\n\n$ floyd login\nAuthentication token page will now open in your browser. Continue? \n[\nY/n\n]\n: y\nPlease copy and paste the authentication token.\nThis is an invisible field. Paste token and press ENTER:\n\n\n\n\nThis will open your browser and display your authentication token. You can also access this directly at \nfloydhub.com/settings/security\n. (\nNote:\n only visible if you are \nlogged in\n to your web dashboard). \n\n\n\n\nCopy the token and paste it in your terminal.\n\n\nHaving problems with logging in using floyd-cli?\n\n\n\n\nIf you cannot open your browser from the terminal (e.g. you are SSH-ing into a remote server), use the \n--token\n flag. See \nfloyd login\n for more details\n\n\nAre you on a Windows machine? Please see our \nFAQs for Windows\n\n\nOther problems? Check out our \nLogin FAQs\n or \ncontact us", 
            "title": "Login using Floyd CLI"
        }, 
        {
            "location": "/guides/basics/login/#login-using-floyd-cli", 
            "text": "", 
            "title": "Login using floyd-cli"
        }, 
        {
            "location": "/guides/basics/login/#quick-preparation-checklist", 
            "text": "You must have a  FloydHub account  You must be  logged in to your web dashboard  You must have  floyd-cli   installed on your computer   You can use the  floyd login  command to login to your FloydHub account through your command line  $ floyd login\nAuthentication token page will now open in your browser. Continue?  [ Y/n ] : y\nPlease copy and paste the authentication token.\nThis is an invisible field. Paste token and press ENTER:  This will open your browser and display your authentication token. You can also access this directly at  floydhub.com/settings/security . ( Note:  only visible if you are  logged in  to your web dashboard).    Copy the token and paste it in your terminal.", 
            "title": "Quick Preparation Checklist"
        }, 
        {
            "location": "/guides/basics/login/#having-problems-with-logging-in-using-floyd-cli", 
            "text": "If you cannot open your browser from the terminal (e.g. you are SSH-ing into a remote server), use the  --token  flag. See  floyd login  for more details  Are you on a Windows machine? Please see our  FAQs for Windows  Other problems? Check out our  Login FAQs  or  contact us", 
            "title": "Having problems with logging in using floyd-cli?"
        }, 
        {
            "location": "/guides/basics/create_new/", 
            "text": "Create a new Project\n\n\nA \nProject\n is a collection of the jobs you run and their data, logs and results. If you have used GitHub, projects in FloydHub are a lot like code repositories.\n\n\nTo create a new Project, visit \nwww.floydhub.com/projects\n and click on the \"New Project\" button on the top right hand corner.\n\n\n\n\nGive the project a name and an apt description.\n\n\nThe \nVisibility\n field indicates who can see your project. If you set it to \nPublic\n, anyone can see your project, your code and data. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your code or data is proprietary, please select \nPrivate\n. This will ensure that only you and your team will have access to this project.\n\n\nOnce you have created a Project, you can start running jobs using the \nfloyd run\n command. For example, to start a Jupyter Notebook job:\n\n\n$ floyd init quick-start\nProject \nquick-start\n initialized in the current directory\n\n$ floyd run --gpu --env tensorflow --mode jupyter\nSyncing code ...\n\n\n\n\nCreate a new Dataset\n\n\nA \nDataset\n is a collection of data. If you have used Github, datasets in FloydHub are also a lot like code repositories, except they are for storing and versioning data.\n\n\nTo create a new Dataset, visit \nwww.floydhub.com/datasets\n and click on the \"New Dataset\" button on the top right hand corner.\n\n\n\n\nGive the dataset a name and an apt description.\n\n\nThe \nVisibility\n field indicates who can see your dataset. If you set it to \nPublic\n, anyone can see your dataset and data versions. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your data is proprietary, please select \nPrivate\n. This will ensure that only you and your team will have access to this dataset.\n\n\nOnce you have created a dataset, you can upload data from your terminal using the \nfloyd data\n command. For example:\n\n\n$ floyd data init imagenet-2017\nDataset \nimagenet-2017\n initialized in current directory\n...\n$ floyd data upload\nCompressing data...", 
            "title": "Create new Project and Dataset"
        }, 
        {
            "location": "/guides/basics/create_new/#create-a-new-project", 
            "text": "A  Project  is a collection of the jobs you run and their data, logs and results. If you have used GitHub, projects in FloydHub are a lot like code repositories.  To create a new Project, visit  www.floydhub.com/projects  and click on the \"New Project\" button on the top right hand corner.   Give the project a name and an apt description.  The  Visibility  field indicates who can see your project. If you set it to  Public , anyone can see your project, your code and data. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your code or data is proprietary, please select  Private . This will ensure that only you and your team will have access to this project.  Once you have created a Project, you can start running jobs using the  floyd run  command. For example, to start a Jupyter Notebook job:  $ floyd init quick-start\nProject  quick-start  initialized in the current directory\n\n$ floyd run --gpu --env tensorflow --mode jupyter\nSyncing code ...", 
            "title": "Create a new Project"
        }, 
        {
            "location": "/guides/basics/create_new/#create-a-new-dataset", 
            "text": "A  Dataset  is a collection of data. If you have used Github, datasets in FloydHub are also a lot like code repositories, except they are for storing and versioning data.  To create a new Dataset, visit  www.floydhub.com/datasets  and click on the \"New Dataset\" button on the top right hand corner.   Give the dataset a name and an apt description.  The  Visibility  field indicates who can see your dataset. If you set it to  Public , anyone can see your dataset and data versions. If you are working on an open source project, this is a great way to share and contribute to the FloydHub community. If your data is proprietary, please select  Private . This will ensure that only you and your team will have access to this dataset.  Once you have created a dataset, you can upload data from your terminal using the  floyd data  command. For example:  $ floyd data init imagenet-2017\nDataset  imagenet-2017  initialized in current directory\n...\n$ floyd data upload\nCompressing data...", 
            "title": "Create a new Dataset"
        }, 
        {
            "location": "/guides/basics/delete/", 
            "text": "This guide explains how to delete Projects, Jobs, Datasets and Data.\n\n\nDeleting a Project\n\n\nYou can delete a project by clicking \nDelete project\n button on the Settings tab of the project on the web dashboard.\n\n\nExample: \nhttps://www.floydhub.com/alice/projects/quick-start/settings\n\n\n\n\n\n\nImportant\n: Please note that deleting a project will delete all its jobs and their corresponding code, output data and logs. This \ncannot\n be restored. Please be absolutely sure you want to delete a project before proceeding.\n\n\nWe recommend deleting individual jobs rather than projects.\n\n\nDeleting a Job\n\n\nYou can delete an individual job by clicking on \nDelete job\n button on the Settings tab of the job's page on the web dashboard.\n\n\nExample: \nhttps://www.floydhub.com/alice/projects/quick-start/1/settings\n\n\n\n\nDeleting a Job from CLI\n\n\nYou can also delete a job from the CLI using the \nfloyd delete\n command.\n\n\n$ floyd delete alice/projects/quick-start/1\n\nDelete Run: alice/quick-start/1? \n[\ny/N\n]\n: y\nJob BD4JMXSgCi2r2afbq3n3Vo: Deleted\n\n\n\n\nDeleting output of a Job\n\n\nIt is not possible to delete just the output of a job. You will have to delete the job itself.\n\n\nDeleting a Dataset\n\n\nDeleting a Dataset is similar to deleting a Project. Click the \nDelete dataset\n button on the Settings tab of the dataset on the web dashboard.\n\n\nExample: \nhttps://www.floydhub.com/alice/datasets/quick-start/settings\n\n\n\n\n\n\nImportant\n: Please note that deleting a dataset will delete all its individual versions of data. This \ncannot\n be restored. Please be absolutely sure you want to delete a dataset before proceeding.\n\n\nWe recommend deleting individual data versions rather than the entire dataset.\n\n\nDeleting a uploaded datasource\n\n\nYou can delete a particular version of a Dataset by clicking on \nDelete data\n button on the Settings tab of the data's page on the web dashboard.\n\n\nExample: \nhttps://www.floydhub.com/alice/datasets/quick-start/1/settings\n\n\n\n\nDeleting an uploaded datasource from CLI\n\n\nYou can also delete an uploaded datasource from the CLI using the \nfloyd data delete\n command.\n\n\n$ floyd data delete alice/datasets/quick-start/1\n\nDelete Data: alice/quick-start/1? \n[\ny/N\n]\n: y\nData alice/datasets/quick-start/1: Deleted", 
            "title": "Delete Project, Jobs and Data"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-a-project", 
            "text": "You can delete a project by clicking  Delete project  button on the Settings tab of the project on the web dashboard.  Example:  https://www.floydhub.com/alice/projects/quick-start/settings    Important : Please note that deleting a project will delete all its jobs and their corresponding code, output data and logs. This  cannot  be restored. Please be absolutely sure you want to delete a project before proceeding.  We recommend deleting individual jobs rather than projects.", 
            "title": "Deleting a Project"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-a-job", 
            "text": "You can delete an individual job by clicking on  Delete job  button on the Settings tab of the job's page on the web dashboard.  Example:  https://www.floydhub.com/alice/projects/quick-start/1/settings", 
            "title": "Deleting a Job"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-a-job-from-cli", 
            "text": "You can also delete a job from the CLI using the  floyd delete  command.  $ floyd delete alice/projects/quick-start/1\n\nDelete Run: alice/quick-start/1?  [ y/N ] : y\nJob BD4JMXSgCi2r2afbq3n3Vo: Deleted", 
            "title": "Deleting a Job from CLI"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-output-of-a-job", 
            "text": "It is not possible to delete just the output of a job. You will have to delete the job itself.", 
            "title": "Deleting output of a Job"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-a-dataset", 
            "text": "Deleting a Dataset is similar to deleting a Project. Click the  Delete dataset  button on the Settings tab of the dataset on the web dashboard.  Example:  https://www.floydhub.com/alice/datasets/quick-start/settings    Important : Please note that deleting a dataset will delete all its individual versions of data. This  cannot  be restored. Please be absolutely sure you want to delete a dataset before proceeding.  We recommend deleting individual data versions rather than the entire dataset.", 
            "title": "Deleting a Dataset"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-a-uploaded-datasource", 
            "text": "You can delete a particular version of a Dataset by clicking on  Delete data  button on the Settings tab of the data's page on the web dashboard.  Example:  https://www.floydhub.com/alice/datasets/quick-start/1/settings", 
            "title": "Deleting a uploaded datasource"
        }, 
        {
            "location": "/guides/basics/delete/#deleting-an-uploaded-datasource-from-cli", 
            "text": "You can also delete an uploaded datasource from the CLI using the  floyd data delete  command.  $ floyd data delete alice/datasets/quick-start/1\n\nDelete Data: alice/quick-start/1?  [ y/N ] : y\nData alice/datasets/quick-start/1: Deleted", 
            "title": "Deleting an uploaded datasource from CLI"
        }, 
        {
            "location": "/guides/basics/using_gpu/", 
            "text": "Running your job on CPU vs. GPU\n\n\nWhen you run a job using the \nfloyd run\n command, it is executed on a CPU instance on FloydHub's servers, by default. \n\n\n$ floyd run \npython mnist_cnn.py\n\n\n\n\n\nYou can also force your job to execute on on a CPU using the \n--cpu\n flag\n\n\n$ floyd run --cpu \npython mnist_cnn.py\n\n\n\n\n\nIf you want to run your job on a GPU, simply add the \n--gpu\n flag. Just make sure your code is optimized to use the available GPU.\n\n\n$ floyd run --gpu \npython mnist_cnn.py\n\n\n\n\n\nChecking GPU stats\n\n\nYou can check the GPU stats by running a dummy job that executes the \nnvidia-smi\n command.\n\n\n$ floyd run --gpu \nnvidia-smi\n\nSyncing code...\n...\n\n$ floyd logs -t \nJOB_NAME\n\n\nMon Jul \n31\n \n22\n:45:14 \n2017\n       \n+-----------------------------------------------------------------------------+\n\n|\n NVIDIA-SMI \n375\n.66                 Driver Version: \n375\n.66                    \n|\n\n\n|\n-------------------------------+----------------------+----------------------+\n\n|\n GPU  Name        Persistence-M\n|\n Bus-Id        Disp.A \n|\n Volatile Uncorr. ECC \n|\n\n\n|\n Fan  Temp  Perf  Pwr:Usage/Cap\n|\n         Memory-Usage \n|\n GPU-Util  Compute M. \n|\n\n\n|\n===============================\n+\n======================\n+\n======================\n|\n\n\n|\n   \n0\n  Tesla K80           Off  \n|\n \n0000\n:00:1E.0     Off \n|\n                    \n0\n \n|\n\n\n|\n N/A   43C    P8    25W / 149W \n|\n      0MiB / 11439MiB \n|\n      \n0\n%      Default \n|\n\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n\n|\n Processes:                                                       GPU Memory \n|\n\n\n|\n  GPU       PID  Type  Process name                               Usage      \n|\n\n\n|\n=============================================================================\n|\n\n\n|\n  No running processes found                                                 \n|\n\n+-----------------------------------------------------------------------------+\n\n\n\n\nIf you are using a Jupyter Notebook, you can also just execute the \n!nvidia-smi\n command inside it. (\nMake note\n of the \n!\n character at the beginning of the command)", 
            "title": "Using CPU vs GPU"
        }, 
        {
            "location": "/guides/basics/using_gpu/#running-your-job-on-cpu-vs-gpu", 
            "text": "When you run a job using the  floyd run  command, it is executed on a CPU instance on FloydHub's servers, by default.   $ floyd run  python mnist_cnn.py   You can also force your job to execute on on a CPU using the  --cpu  flag  $ floyd run --cpu  python mnist_cnn.py   If you want to run your job on a GPU, simply add the  --gpu  flag. Just make sure your code is optimized to use the available GPU.  $ floyd run --gpu  python mnist_cnn.py", 
            "title": "Running your job on CPU vs. GPU"
        }, 
        {
            "location": "/guides/basics/using_gpu/#checking-gpu-stats", 
            "text": "You can check the GPU stats by running a dummy job that executes the  nvidia-smi  command.  $ floyd run --gpu  nvidia-smi \nSyncing code...\n...\n\n$ floyd logs -t  JOB_NAME \n\nMon Jul  31   22 :45:14  2017        \n+-----------------------------------------------------------------------------+ |  NVIDIA-SMI  375 .66                 Driver Version:  375 .66                     |  | -------------------------------+----------------------+----------------------+ |  GPU  Name        Persistence-M |  Bus-Id        Disp.A  |  Volatile Uncorr. ECC  |  |  Fan  Temp  Perf  Pwr:Usage/Cap |          Memory-Usage  |  GPU-Util  Compute M.  |  | =============================== + ====================== + ====================== |  |     0   Tesla K80           Off   |   0000 :00:1E.0     Off  |                      0   |  |  N/A   43C    P8    25W / 149W  |       0MiB / 11439MiB  |        0 %      Default  | \n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+ |  Processes:                                                       GPU Memory  |  |   GPU       PID  Type  Process name                               Usage       |  | ============================================================================= |  |   No running processes found                                                  | \n+-----------------------------------------------------------------------------+  If you are using a Jupyter Notebook, you can also just execute the  !nvidia-smi  command inside it. ( Make note  of the  !  character at the beginning of the command)", 
            "title": "Checking GPU stats"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/", 
            "text": "Floydhub's \nenvironments\n come with many common deep learning and machine learning packages and dependencies preinstalled. Examples of pre-installed packages include \nnumpy\n, \nscipy\n, \nOpenCV\n, \nOpenAI Gym\n, \nSpaCy\n, etc.\n\n\nIf you need additional or custom packages, you can install them before running your job.\n\n\nInstalling Python dependencies\n\n\nIf your code needs additional Python packages at run time, you can add them to a special file named \nfloyd_requirements.txt\n. \n\n\nIt is similar to Python's \nrequirements.txt\n file and should be present in the same directory from where you issue the \nfloyd run\n command. This is a special file that will be read before your job is started and the packages listed here will be installed before running your job.\n\n\n\n\nHere is an \nfloyd_requirements.txt\n example file:\n\n\nredis\n\ntqdm\n==\n4\n.11.2\n\n\n\n\nWhen this file is present in the project's root directory, any job that is run inside this project will have the \nredis\n and \ntqdm\n (version \n4.11.2\n) packages installed and available at runtime.\n\n\nNotes\n\n\n\n\nOnly Python packages\n: This will only install Python packages available in \nPyPi\n. Please ensure that the package you are trying to install is available.\n\n\nOne package per line\n: Ensure that you have only one package per line in \nfloyd_requirements.txt\n\n\nInstalling specific versions\n: You can install specific versions of packages using the \npackage\n==\nversion\n notation. For example, an entry \ntqdm\n will install the latest version of the package, but \ntqdm==4.11.2\n will force install that specific version.\n\n\n\n\nInstalling dependencies inside Jupyter Notebook\n\n\nYou can install packages (Python or otherwise) interactively inside Jupyter Notebooks. To execute a non-Python command inside a Notebook, prepend it with \n!\n.\n\n\nFor example, to install \ntextblob\n, you can execute \n!pip install textblob\n inside your Notebook:\n\n\n\n\nYou can also use this method to install non-Python packages. For example, to install \nOpenAI Universe\n inside your Notebook, you can execute \n!git clone https://github.com/openai/universe.git \n cd universe \n pip install -e .\n\n\n\n\nInstalling other dependencies\n\n\nYou might want to install non-Python packages or other packages that have custom installation steps. If you are using a Jupyter Notebook, you can follow \nthese steps\n to install arbitrary packages interactively.\n\n\nIf you are running a script using the \nfloyd run \ncommand\n command, you can do one of the following:\n\n\n\n\nInclude the installation steps in the \ncommand\n\n\n\n\nFor example, to install \nOpenAI Universe\n before running your actual script \ntrain.py\n:\n\n\n$ floyd run \ngit clone https://github.com/openai/universe.git \n cd universe \n pip install -e . \n python train.py\n\n\n\n\n\nThis will clone the Universe git repo, install it and then execute \npython train.py\n.\n\n\n\n\nCreate an installation script\n:\n\n\n\n\nIncluding the setup instructions in the \nrun\n command can get unwieldy very soon. An alternative would be to create a bash script with the sequence of setup commands (say, \nsetup.sh\n) and then execute this bash script as part of your \nfloyd run\n.\n\n\nsetup.sh\n\n\n#!/bin/bash\n\n\ngit clone https://github.com/openai/universe.git\n\ncd\n universe\npip install -e . \n\n\n\n\nExecute the setup bash script in your \nfloyd run\n command before your actual job:\n\n\n$ floyd run \nbash setup.sh \n python train.py\n\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Installing extra dependencies"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/#installing-python-dependencies", 
            "text": "If your code needs additional Python packages at run time, you can add them to a special file named  floyd_requirements.txt .   It is similar to Python's  requirements.txt  file and should be present in the same directory from where you issue the  floyd run  command. This is a special file that will be read before your job is started and the packages listed here will be installed before running your job.   Here is an  floyd_requirements.txt  example file:  redis tqdm == 4 .11.2  When this file is present in the project's root directory, any job that is run inside this project will have the  redis  and  tqdm  (version  4.11.2 ) packages installed and available at runtime.", 
            "title": "Installing Python dependencies"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/#notes", 
            "text": "Only Python packages : This will only install Python packages available in  PyPi . Please ensure that the package you are trying to install is available.  One package per line : Ensure that you have only one package per line in  floyd_requirements.txt  Installing specific versions : You can install specific versions of packages using the  package == version  notation. For example, an entry  tqdm  will install the latest version of the package, but  tqdm==4.11.2  will force install that specific version.", 
            "title": "Notes"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/#installing-dependencies-inside-jupyter-notebook", 
            "text": "You can install packages (Python or otherwise) interactively inside Jupyter Notebooks. To execute a non-Python command inside a Notebook, prepend it with  ! .  For example, to install  textblob , you can execute  !pip install textblob  inside your Notebook:   You can also use this method to install non-Python packages. For example, to install  OpenAI Universe  inside your Notebook, you can execute  !git clone https://github.com/openai/universe.git   cd universe   pip install -e .", 
            "title": "Installing dependencies inside Jupyter Notebook"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/#installing-other-dependencies", 
            "text": "You might want to install non-Python packages or other packages that have custom installation steps. If you are using a Jupyter Notebook, you can follow  these steps  to install arbitrary packages interactively.  If you are running a script using the  floyd run  command  command, you can do one of the following:   Include the installation steps in the  command   For example, to install  OpenAI Universe  before running your actual script  train.py :  $ floyd run  git clone https://github.com/openai/universe.git   cd universe   pip install -e .   python train.py   This will clone the Universe git repo, install it and then execute  python train.py .   Create an installation script :   Including the setup instructions in the  run  command can get unwieldy very soon. An alternative would be to create a bash script with the sequence of setup commands (say,  setup.sh ) and then execute this bash script as part of your  floyd run .  setup.sh  #!/bin/bash \n\ngit clone https://github.com/openai/universe.git cd  universe\npip install -e .   Execute the setup bash script in your  floyd run  command before your actual job:  $ floyd run  bash setup.sh   python train.py", 
            "title": "Installing other dependencies"
        }, 
        {
            "location": "/guides/jobs/installing_dependencies/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/guides/jobs/tensorboard/", 
            "text": "Tensorboard\n \nis a visualization tool for Tensorflow projects. Tensorboard can help \nvisualize the Tensorflow computation graph and plot quantitative metrics about your run. This \nguide will help you understand how to enable Tensorboard in your jobs.\n\n\nKey concepts of Tensorboard\n\n\nIf you would like to know more about the concepts of Tensorboard please check out\nthe \nTensorboard README\n\nfile. This page also goes into the details of Tensorboard and explains the various \ndashboards that are present in the Tensorboard UI.\n\n\nEnabling Tensorboard in your job\n\n\nTo enable Tensorboard in your job, you need to specify a \n--tensorboard\n flag \nwhen you run the job. Tensorboard can be enabled for both CLI jobs and when running \nJupyter notebooks.\n\n\nExample\n\n\nThis code snipped will train an MNIST model and also store the training summary \nto a log directory.\n\n\ngit clone https://github.com/floydhub/tensorflow-examples\n\ncd\n tensorflow-examples/tensorboard\n\n\n# Initialize the current directory to an existing or new project\n\nfloyd init mnist-tensorboard\nfloyd run --tensorboard \npython mnist_tensorboard.py --log_dir /output/mnist --max_steps 5000\n\n\n\n\n\n\n\nNotice that the the \nlog_dir\n parameter is set to a path in the \n/output\n directory.\nOn Floydhub, \n/output\n is a special directory that Tensorboard watches. Be sure to send \nall data meant for Tensorboard to any directory under \n/output\n path.\n\n\n\n\nNow you can view the job on your Project dashboard.\n\n\n\n\nClick on the job that was just started. You will notice that the job page now has a link \nto Tensorboard. Click on it to open the Tensorboard dashboard in a new tab.\n\n\n\n\nTensorboard Dashboard\n\n\n\n\nYou can see that the \"SCALARS\" tab of Tensorboard is logging the accuracy of the \ntraining and test data along with some other values. You may need to click on the title \nbars (like \naccuracy_1\n) for the graph to open.\n\n\nThe reason why these values are appearing on the dashboard is because the \n\nmnist_tensorboard.py\n code has the following lines:\n\n\ntf\n.\nsummary\n.\nscalar\n(\ncross_entropy\n,\n \ncross_entropy\n)\n\n\n...\n\n\ntf\n.\nsummary\n.\nscalar\n(\naccuracy\n,\n \naccuracy\n)\n\n\n\n\n\nYou can read more about how to use Tensorboard to log additional information in \nthe \nTensorboard README\n.\n\n\nExplore the other tabs in the Tensorboad dashboard like \"IMAGES\" and \"GRAPHS\".\n\n\nTensorboard Tabs\n\n\n\n\nThe IMAGES dashboard shows the transformations happening to the mnist images\nin real time while the training is happening.\n\n\n\n\nThe GRAPHS dashboard shows a representation of Tensorflow's computation graph.\nYou can click into each part of the model to get more details.\n\n\n\n\nTensorboard feature is only available for Tensorflow environments. \nSee \nthis\n page for full list of Tensorflow environments you \ncan use.\n\n\n\n\nStopping Tensorboard\n\n\nTensorboard runs in the same machine where your code is running. So you do not have \nto stop it explicitly. It will be up until your job finishes and then stop automatically. \nTensorboard will become inaccessible when the job finishes in any of the \nSuccess\n, \nFailed\n, \n\nTimeout\n or \nShutdown\n states.\n\n\nTensorboard in Jupyter mode\n\n\nTensorboard can be run in Jupyter mode as well. You will notice that the links for both \nthe Jupyter notebook and the Tensorboard appear in the Job page.\n\n\n\n\nOffline Training\n\n\nUntil now, we saw how to use Tensorboard directly on Floydhub \nwhile\n your job is actively running. \nAlternatively you can also view the metrics offline after your \ntraining is done.\n\n\nFor that, you need to first download the output of your project to your local \nmachine.\n\n\nmkdir tensorboard_output \n \ncd\n tensorboard_output\nfloyd data clone floydhub/mnist-tensorboard/6/output\n\n\n\n\nThen you need to install tensorflow in your local machine. The instructions depend \non your OS. See the Tensorflow install instructions \nhere\n.\n\n\nAfter that you can just run the \ntensorboard\n command and point it to the output \ndirectory downloaded from Floydhub.\n\n\ntensorboard --logdir\n=\ntensorboard_output\n\n\n\n\nThen you can view the Tensorboard dashboard on your machine running at \n\nhttp://127.0.0.1:6006/", 
            "title": "Enabling Tensorboard"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#key-concepts-of-tensorboard", 
            "text": "If you would like to know more about the concepts of Tensorboard please check out\nthe  Tensorboard README \nfile. This page also goes into the details of Tensorboard and explains the various \ndashboards that are present in the Tensorboard UI.", 
            "title": "Key concepts of Tensorboard"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#enabling-tensorboard-in-your-job", 
            "text": "To enable Tensorboard in your job, you need to specify a  --tensorboard  flag \nwhen you run the job. Tensorboard can be enabled for both CLI jobs and when running \nJupyter notebooks.", 
            "title": "Enabling Tensorboard in your job"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#example", 
            "text": "This code snipped will train an MNIST model and also store the training summary \nto a log directory.  git clone https://github.com/floydhub/tensorflow-examples cd  tensorflow-examples/tensorboard # Initialize the current directory to an existing or new project \nfloyd init mnist-tensorboard\nfloyd run --tensorboard  python mnist_tensorboard.py --log_dir /output/mnist --max_steps 5000    Notice that the the  log_dir  parameter is set to a path in the  /output  directory.\nOn Floydhub,  /output  is a special directory that Tensorboard watches. Be sure to send \nall data meant for Tensorboard to any directory under  /output  path.   Now you can view the job on your Project dashboard.   Click on the job that was just started. You will notice that the job page now has a link \nto Tensorboard. Click on it to open the Tensorboard dashboard in a new tab.", 
            "title": "Example"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#tensorboard-dashboard", 
            "text": "You can see that the \"SCALARS\" tab of Tensorboard is logging the accuracy of the \ntraining and test data along with some other values. You may need to click on the title \nbars (like  accuracy_1 ) for the graph to open.  The reason why these values are appearing on the dashboard is because the  mnist_tensorboard.py  code has the following lines:  tf . summary . scalar ( cross_entropy ,   cross_entropy )  ...  tf . summary . scalar ( accuracy ,   accuracy )   You can read more about how to use Tensorboard to log additional information in \nthe  Tensorboard README .  Explore the other tabs in the Tensorboad dashboard like \"IMAGES\" and \"GRAPHS\".", 
            "title": "Tensorboard Dashboard"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#tensorboard-tabs", 
            "text": "The IMAGES dashboard shows the transformations happening to the mnist images\nin real time while the training is happening.   The GRAPHS dashboard shows a representation of Tensorflow's computation graph.\nYou can click into each part of the model to get more details.   Tensorboard feature is only available for Tensorflow environments. \nSee  this  page for full list of Tensorflow environments you \ncan use.", 
            "title": "Tensorboard Tabs"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#stopping-tensorboard", 
            "text": "Tensorboard runs in the same machine where your code is running. So you do not have \nto stop it explicitly. It will be up until your job finishes and then stop automatically. \nTensorboard will become inaccessible when the job finishes in any of the  Success ,  Failed ,  Timeout  or  Shutdown  states.", 
            "title": "Stopping Tensorboard"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#tensorboard-in-jupyter-mode", 
            "text": "Tensorboard can be run in Jupyter mode as well. You will notice that the links for both \nthe Jupyter notebook and the Tensorboard appear in the Job page.", 
            "title": "Tensorboard in Jupyter mode"
        }, 
        {
            "location": "/guides/jobs/tensorboard/#offline-training", 
            "text": "Until now, we saw how to use Tensorboard directly on Floydhub  while  your job is actively running. \nAlternatively you can also view the metrics offline after your \ntraining is done.  For that, you need to first download the output of your project to your local \nmachine.  mkdir tensorboard_output    cd  tensorboard_output\nfloyd data clone floydhub/mnist-tensorboard/6/output  Then you need to install tensorflow in your local machine. The instructions depend \non your OS. See the Tensorflow install instructions  here .  After that you can just run the  tensorboard  command and point it to the output \ndirectory downloaded from Floydhub.  tensorboard --logdir = tensorboard_output  Then you can view the Tensorboard dashboard on your machine running at  http://127.0.0.1:6006/", 
            "title": "Offline Training"
        }, 
        {
            "location": "/guides/data/storing_output/", 
            "text": "Most jobs generate output files (eg. model checkpoints, logs, evaluation output). In Floyd, \n/output\n is a special directory used to store outputs. \n\n\nAny file or directory you create at runtime under the \n/output\n directory will be retained and available to you for download after your job finishes.\n\n\nExample 1\n\n\nThis job runs a Python script called \nhelloworld.py\n and redirects its output logs into the file \n/output/my-output-file.txt\n:\n\n\n$ floyd init quick-start\n$ floyd run \npython helloworld.py \n /output/my-output-file.txt\n\nSyncing code ...\n...\n\n\n\n\nNOTE\n: This is a simple example that only stores the standard output of \nhelloworld.py\n. Since the file is created under the special \n/output\n directory, it will be saved even after your job has ended. \n\n\nExample 2\n\n\nIf you want to save and retain your model checkpoints and other data inside your code, you should write them to \n/output\n.\n\n\nHere is a sample Tensorflow example that saves the model weights:\n\n\nsave_restore_model.py\n\n\nimport tensorflow as tf\n\n...\n\n\nsaver\n \n=\n tf.train.Saver\n()\n\nwith tf.Session\n()\n as sess:\n    sess.run\n(\ninit\n)\n\n    ...\n    \nsave_path\n \n=\n saver.save\n(\nsess, \n/output/model.ckpt\n)\n\n    print\n(\nModel saved in file: %s\n % save_path\n)\n\n    ...\n\n\n\nAgain, since the model is stored under the special \n/output\n directory, they will be saved even after your job ends. \n\n\nYou can view or refer to this output using the \nfloyd output\n command\n\n\n$ floyd output floydhub/projects/quick-start/1/output\nOpening output directory in your browser...\n\n\n\n\nAlternatively, you can visit the \nOutput\n tab of the job on your dashboard\n\n\n\n\nUsing output as a data source\n\n\nYou can use the output of one job as the input to your next job. To see how to mount output data, please see \nthis guide\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Storing output data"
        }, 
        {
            "location": "/guides/data/storing_output/#example-1", 
            "text": "This job runs a Python script called  helloworld.py  and redirects its output logs into the file  /output/my-output-file.txt :  $ floyd init quick-start\n$ floyd run  python helloworld.py   /output/my-output-file.txt \nSyncing code ...\n...  NOTE : This is a simple example that only stores the standard output of  helloworld.py . Since the file is created under the special  /output  directory, it will be saved even after your job has ended.", 
            "title": "Example 1"
        }, 
        {
            "location": "/guides/data/storing_output/#example-2", 
            "text": "If you want to save and retain your model checkpoints and other data inside your code, you should write them to  /output .  Here is a sample Tensorflow example that saves the model weights:  save_restore_model.py  import tensorflow as tf\n\n... saver   =  tf.train.Saver () \nwith tf.Session ()  as sess:\n    sess.run ( init ) \n    ...\n     save_path   =  saver.save ( sess,  /output/model.ckpt ) \n    print ( Model saved in file: %s  % save_path ) \n    ...  Again, since the model is stored under the special  /output  directory, they will be saved even after your job ends.   You can view or refer to this output using the  floyd output  command  $ floyd output floydhub/projects/quick-start/1/output\nOpening output directory in your browser...  Alternatively, you can visit the  Output  tab of the job on your dashboard", 
            "title": "Example 2"
        }, 
        {
            "location": "/guides/data/storing_output/#using-output-as-a-data-source", 
            "text": "You can use the output of one job as the input to your next job. To see how to mount output data, please see  this guide", 
            "title": "Using output as a data source"
        }, 
        {
            "location": "/guides/data/storing_output/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/guides/data/mounting_data/", 
            "text": "In this guide, we will explain how to attach a datasource to your job.\n\n\nDatasets\n\n\nFloyd datasets are directories of data files that can be used in a project run. To create a new dataset, please follow \n\nthis guide\n. You can view the datasets you \nhave created in the \ndatasets page\n in the dashboard. You can also view \npublic datasets by searching for it on FloydHub.\n\n\nMounting datasets\n\n\nOverview\n\n\nYou can mount one or more datasets when you run a job using the \nfloyd run\n command. \nThis automatically makes the mounted datasets available for you to use in your job, without having to download them each time.\n\n\nTo mount a specific version of a dataset, you need to specify its \nfull name\n and the \nmount point\n. \nThe syntax is \n--data \ndata_name\n:\nmount_point\n\n\nFor example, to mount the \nVGG 19-layers\n dataset under \n/vgg\n:\n\nfloyd run --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg --mode jupyter\n\n\n\nThis will spin up a Jupyter Notebook, inside which you will have access to the VGGNet pre-trained models under \n/vgg\n.\n\n\n\n\nNote\n: You can use the \n--data\n flag with \nfloyd run\n when you are running a command too.\n\n\n$ floyd run --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg \npython train.py\n\n\n\n\n\nMounting the output of another job\n\n\nIn FloydHub, you can link jobs by mounting the output of one job as the input of a new job that you are going to run. This allows you to derive from an existing job or restart a stopped or timedout job.\n\n\nYou can refer to the output of a job by its name with \n/output\n appended to it.\n\n\nFor example: \nfloydhub/projects/handwriting-recognition/12/output\n refers to the output of the job \nfloydhub/projects/handwriting-recognition/12\n\n\nYou can mount this using the \n--data\n flag in the \nfloyd run\n command, similar to datasets. For example:\n\n\n$ floyd run --data floydhub/projects/handwriting-recognition/12:filtered_training_data \npython train.py\n\n\n\n\n\nThis will make the output of \nfloydhub/projects/handwriting-recognition/12\n available at \n/filtered_training_data\n for the new job to use.\n\n\nNote\n: You need to have access to the job to be able to mount it's output.\n\n\nMounting multiple datasources\n\n\nYou can attach upto 5 datasources when you run a job using the \n--data\n flag in the \nfloyd run\n command. This includes both datasets and job outputs. Ensure that the mount points for the datasets are unique.\n\n\n$ floyd run --data floydhub/datasets/mnist/2:training --data floydhub/datasets/digits/1:test \npython script.py\n\n\n\nIn this case, the above datasets will be mounted at \n/training\n and \n/test\n respectively.\n\n\nWeb dashboard\n\n\nYou can view the mounted datasets and their respective mount points for a specific job by going to the \nData\n tab:\n\n\n\n\nSymlinking your mounted data\n\n\nSometimes, your code might require your data to be available at a hardcoded location. Or you might want to combine multiple mounted datasources under a single directory. One way to do this would be to copy the data from the mounted locations to the destination, but this is inefficient for large data. \nSymlinking\n is a great solution for this.\n\n\nPlease see this guide: \nSymlinking mounted data\n\n\nDetails\n\n\nDatasource name\n\n\nThe full name of a datasource (\nusername\n/datasets/\ndataset_name\n/\nversion\n) consists of 3 parts: \n\n\n\n\nUsername\n\n\nDataset Name\n\n\nVersion\n\n\n\n\nFor example: \nfloydhub/datasets/mnist/2\n\n\nMount point\n\n\nThe mount point is the name of the directory under which the datasource will be available in your job. \n\n\n\n\nIt \ncannot\n contain subdirectories. \nvgg\n is a valid mount point, but \nvgg/2017\n is not.\n\n\nThe mount point is an absolute path. For example, \n--data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg\n will mount the data at \n/vgg\n. A common mistake is to look for the mounted data in the current directory (\n./vgg\n), rather than using the absolute path (\n/vgg\n)\n\n\n\n\nDefault mount points\n\n\nWe highly recommend that you explicitly specify the mount points for your data using the \n--data \ndata_name\n:\nmount_point\n convention.\n\n\nIf, however, you do not specify a mount point, the default values are:\n\n\n\n\n\n\nSingle data mount: If you only mount one datasource without specifying a mount point, it is mounted at \n/input\n\n\n\n\n\n\nMultiple data mounts: If you mount multiple datasource without specifying mount points, they will each be mounted under their respective GUIDs (e.g. \n/xKduBzTr4LAsc6eVPZVPVd\n). GUIDs are 32-character random strings that difficult to track down, so we highly discourage this pattern.", 
            "title": "Mounting data"
        }, 
        {
            "location": "/guides/data/mounting_data/#datasets", 
            "text": "Floyd datasets are directories of data files that can be used in a project run. To create a new dataset, please follow  this guide . You can view the datasets you \nhave created in the  datasets page  in the dashboard. You can also view \npublic datasets by searching for it on FloydHub.", 
            "title": "Datasets"
        }, 
        {
            "location": "/guides/data/mounting_data/#mounting-datasets", 
            "text": "", 
            "title": "Mounting datasets"
        }, 
        {
            "location": "/guides/data/mounting_data/#overview", 
            "text": "You can mount one or more datasets when you run a job using the  floyd run  command. \nThis automatically makes the mounted datasets available for you to use in your job, without having to download them each time.  To mount a specific version of a dataset, you need to specify its  full name  and the  mount point . \nThe syntax is  --data  data_name : mount_point  For example, to mount the  VGG 19-layers  dataset under  /vgg : floyd run --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg --mode jupyter  This will spin up a Jupyter Notebook, inside which you will have access to the VGGNet pre-trained models under  /vgg .   Note : You can use the  --data  flag with  floyd run  when you are running a command too.  $ floyd run --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg  python train.py", 
            "title": "Overview"
        }, 
        {
            "location": "/guides/data/mounting_data/#mounting-the-output-of-another-job", 
            "text": "In FloydHub, you can link jobs by mounting the output of one job as the input of a new job that you are going to run. This allows you to derive from an existing job or restart a stopped or timedout job.  You can refer to the output of a job by its name with  /output  appended to it.  For example:  floydhub/projects/handwriting-recognition/12/output  refers to the output of the job  floydhub/projects/handwriting-recognition/12  You can mount this using the  --data  flag in the  floyd run  command, similar to datasets. For example:  $ floyd run --data floydhub/projects/handwriting-recognition/12:filtered_training_data  python train.py   This will make the output of  floydhub/projects/handwriting-recognition/12  available at  /filtered_training_data  for the new job to use.  Note : You need to have access to the job to be able to mount it's output.", 
            "title": "Mounting the output of another job"
        }, 
        {
            "location": "/guides/data/mounting_data/#mounting-multiple-datasources", 
            "text": "You can attach upto 5 datasources when you run a job using the  --data  flag in the  floyd run  command. This includes both datasets and job outputs. Ensure that the mount points for the datasets are unique.  $ floyd run --data floydhub/datasets/mnist/2:training --data floydhub/datasets/digits/1:test  python script.py  \nIn this case, the above datasets will be mounted at  /training  and  /test  respectively.", 
            "title": "Mounting multiple datasources"
        }, 
        {
            "location": "/guides/data/mounting_data/#web-dashboard", 
            "text": "You can view the mounted datasets and their respective mount points for a specific job by going to the  Data  tab:", 
            "title": "Web dashboard"
        }, 
        {
            "location": "/guides/data/mounting_data/#symlinking-your-mounted-data", 
            "text": "Sometimes, your code might require your data to be available at a hardcoded location. Or you might want to combine multiple mounted datasources under a single directory. One way to do this would be to copy the data from the mounted locations to the destination, but this is inefficient for large data.  Symlinking  is a great solution for this.  Please see this guide:  Symlinking mounted data", 
            "title": "Symlinking your mounted data"
        }, 
        {
            "location": "/guides/data/mounting_data/#details", 
            "text": "", 
            "title": "Details"
        }, 
        {
            "location": "/guides/data/mounting_data/#datasource-name", 
            "text": "The full name of a datasource ( username /datasets/ dataset_name / version ) consists of 3 parts:    Username  Dataset Name  Version   For example:  floydhub/datasets/mnist/2", 
            "title": "Datasource name"
        }, 
        {
            "location": "/guides/data/mounting_data/#mount-point", 
            "text": "The mount point is the name of the directory under which the datasource will be available in your job.    It  cannot  contain subdirectories.  vgg  is a valid mount point, but  vgg/2017  is not.  The mount point is an absolute path. For example,  --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg  will mount the data at  /vgg . A common mistake is to look for the mounted data in the current directory ( ./vgg ), rather than using the absolute path ( /vgg )", 
            "title": "Mount point"
        }, 
        {
            "location": "/guides/data/mounting_data/#default-mount-points", 
            "text": "We highly recommend that you explicitly specify the mount points for your data using the  --data  data_name : mount_point  convention.  If, however, you do not specify a mount point, the default values are:    Single data mount: If you only mount one datasource without specifying a mount point, it is mounted at  /input    Multiple data mounts: If you mount multiple datasource without specifying mount points, they will each be mounted under their respective GUIDs (e.g.  /xKduBzTr4LAsc6eVPZVPVd ). GUIDs are 32-character random strings that difficult to track down, so we highly discourage this pattern.", 
            "title": "Default mount points"
        }, 
        {
            "location": "/guides/data/symlink_mounted_data/", 
            "text": "Sometimes, your code might require your data to be available at a hardcoded location. Or you might want to combine multiple mounted datasources under a single directory. One way to do this would be to copy the data from the mounted locations to the destination, but this is inefficient for large data. \nSymlinking\n is a great solution for this.\n\n\nExample 1\n\n\nYour data is mounted under \n/vgg\n using \n--data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg\n. However, your code expects the data to be present at \n/home/data/vgg/2017\n. Instead of copying the files, you can symlink the two locations\n\n\n# NOTE: Ensure that /home/data/vgg/2017 already exists\n\n$ ln -s /vgg/* /home/data/vgg/2017\n\n\n\n\nJupyter Notebook example:\n\n\n\nExample 2\n\n\nYou have two datasources mounted under \n/train\n and \n/test\n respectively. Your Python script \ntrain_and_eval.py\n expects both the datasources to be available under the same parent directory, say \n/data/train\n and \n/data/test\n. You can symlink the datasources to the respective destinations.\n\n\nTo do this, we can follow one of two solutions.\n\n\nSolution 1\n: Include the symlink commands as part of your \nfloyd run\n command.\n\n\n$ floyd run --data alice/datasets/imagenet-train/1:train --data alice/datasets/imagenet-test/1:test \nmkdir /data \n ln -s /train /data \n ln -s /test /data \n python train_and_eval.py\n\n\n\n\n\nThis example chains a series of commands, which are executed in sequence: \nmkdir\n, \nln -s /train /data\n, \nln -s /test /data\n and \npython train_and_eval.py\n\n\nSolution 2\n: Solution 1 can get unwieldy when there are many commands. An alternative would be to create a bash script (\nrun.sh\n) with the sequence of commands and then execute this bash script.\n\n\nrun.sh\n\n\n#!/bin/bash\n\n\n\n# Create a /data directory\n\nmkdir /data\n\n\n# Symlink mounted data to their destinations\n\nln -s /train /data\nln -s /test /data\n\n\n# Execute Python script\n\npython train_and_eval.py\n\n\n\nExecute the bash script using \nfloyd run\n:\n\n\n$ floyd run \nbash run.sh", 
            "title": "Symlink mounted data"
        }, 
        {
            "location": "/guides/data/symlink_mounted_data/#example-1", 
            "text": "Your data is mounted under  /vgg  using  --data floydhub/datasets/vgg-ilsvrc-19-layers/1:vgg . However, your code expects the data to be present at  /home/data/vgg/2017 . Instead of copying the files, you can symlink the two locations  # NOTE: Ensure that /home/data/vgg/2017 already exists \n$ ln -s /vgg/* /home/data/vgg/2017  Jupyter Notebook example:", 
            "title": "Example 1"
        }, 
        {
            "location": "/guides/data/symlink_mounted_data/#example-2", 
            "text": "You have two datasources mounted under  /train  and  /test  respectively. Your Python script  train_and_eval.py  expects both the datasources to be available under the same parent directory, say  /data/train  and  /data/test . You can symlink the datasources to the respective destinations.  To do this, we can follow one of two solutions.  Solution 1 : Include the symlink commands as part of your  floyd run  command.  $ floyd run --data alice/datasets/imagenet-train/1:train --data alice/datasets/imagenet-test/1:test  mkdir /data   ln -s /train /data   ln -s /test /data   python train_and_eval.py   This example chains a series of commands, which are executed in sequence:  mkdir ,  ln -s /train /data ,  ln -s /test /data  and  python train_and_eval.py  Solution 2 : Solution 1 can get unwieldy when there are many commands. An alternative would be to create a bash script ( run.sh ) with the sequence of commands and then execute this bash script.  run.sh  #!/bin/bash  # Create a /data directory \nmkdir /data # Symlink mounted data to their destinations \nln -s /train /data\nln -s /test /data # Execute Python script \npython train_and_eval.py  Execute the bash script using  floyd run :  $ floyd run  bash run.sh", 
            "title": "Example 2"
        }, 
        {
            "location": "/guides/environments/", 
            "text": "Environments\n\n\nBelow is the list of Deep Learning environments supported by FloydHub. Any of\nthese can be specified in the floyd \nrun\n command using the\n\n--env\n option.\n\n\nIf no \n--env\n is provided, it uses the \nkeras\n image by default, which comes with Python\n3, Keras 2.0.4 and Tensorflow 1.1.0 pre-installed.\n\n\n\n\n\n\n\n\nFramework\n\n\nEnv name (--env parameter)\n\n\nDescription\n\n\nDocker Image\n\n\n\n\n\n\n\n\n\n\nTensorflow 1.2\n\n\ntensorflow-1.2\n\n\nTensorflow 1.2.0 + Keras 2.0.4 on Python3.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\n\n\ntensorflow-1.2:py2\n\n\nTensorflow 1.2.0 + Keras 2.0.4 on Python2.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\nTensorflow 1.1\n\n\ntensorflow\n\n\nTensorflow 1.1.0 + Keras 2.0.4 on Python3.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\n\n\ntensorflow:py2\n\n\nTensorflow 1.1.0 + Keras 2.0.4 on Python2.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\nTensorflow 1.0\n\n\ntensorflow-1.0\n\n\nTensorflow 1.0.0 + Keras 1.2.2 on Python3.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\n\n\ntensorflow-1.0:py2\n\n\nTensorflow 1.0.0 + Keras 1.2.2 on Python2.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\nTensorflow 0.12\n\n\ntensorflow-0.12\n\n\nTensorflow 0.12.1 + Keras 1.2.2 on Python3.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\n\n\ntensorflow-0.12:py2\n\n\nTensorflow 0.12.1 + Keras 1.2.2 on Python2.\n\n\nfloydhub/tensorflow\n\n\n\n\n\n\nTheano 0.8\n\n\ntheano-0.8\n\n\nTheano rel-0.8.2 + Keras 1.2.2 on Python3.\n\n\nfloydhub/theano\n\n\n\n\n\n\n\n\ntheano-0.8:py2\n\n\nTheano rel-0.8.2 + Keras 1.2.2 on Python2.\n\n\nfloydhub/theano\n\n\n\n\n\n\nTheano 0.9\n\n\ntheano-0.9\n\n\nTheano rel-0.8.2 + Keras 2.0.3 on Python3.\n\n\nfloydhub/theano\n\n\n\n\n\n\n\n\ntheano-0.9:py2\n\n\nTheano rel-0.8.2 + Keras 2.0.3 on Python2.\n\n\nfloydhub/theano\n\n\n\n\n\n\nKeras\n\n\n-\n\n\nUse tensorflow or theano for the appropriate Keras backend\n\n\n\n\n\n\n\n\nCaffe\n\n\ncaffe\n\n\nCaffe rc4 on Python3.\n\n\nfloydhub/caffe\n\n\n\n\n\n\n\n\ncaffe:py2\n\n\nCaffe rc4 on Python2.\n\n\nfloydhub/caffe\n\n\n\n\n\n\nTorch\n\n\ntorch\n\n\nTorch 7 with Python 3 env.\n\n\nfloydhub/torch\n\n\n\n\n\n\n\n\ntorch:py2\n\n\nTorch 7 with Python 2 env.\n\n\nfloydhub/torch\n\n\n\n\n\n\nPyTorch\n\n\npytorch\n\n\nPyTorch 0.1.9 on Python 3.\n\n\nfloydhub/pytorch\n\n\n\n\n\n\n\n\npytorch:py2\n\n\nPyTorch 0.1.9 on Python 2.\n\n\nfloydhub/pytorch\n\n\n\n\n\n\nChainer 1.23 (beta)\n\n\nchainer-1.23\n\n\nChainer 1.23.0 on Python 3.\n\n\nfloydhub/chainer\n\n\n\n\n\n\n\n\nchainer-1.23:py2\n\n\nChainer 1.23.0 on Python 2.\n\n\nfloydhub/chainer\n\n\n\n\n\n\nChainer 2.0 (beta)\n\n\nchainer-2.0\n\n\nChainer 1.23.0 on Python 3.\n\n\nfloydhub/chainer\n\n\n\n\n\n\n\n\nchainer-2.0:py2\n\n\nChainer 1.23.0 on Python 2.\n\n\nfloydhub/chainer\n\n\n\n\n\n\nMxNet (beta)\n\n\nmxnet:py2\n\n\nMxNet 0.9.3a on Python 2.\n\n\nfloydhub/mxnet\n\n\n\n\n\n\nKur\n\n\nkur\n\n\nKur 0.3.0 on Python 3.\n\n\nfloydhub/kur\n\n\n\n\n\n\n\n\nAll environments are available for both CPU and GPU execution. For example,\n\n\nTo run a Python2 Tensorflow job on CPU\n\n$ floyd run --env tensorflow:py2 \npython mnist_cnn.py\n\n\n\n\nTo run a Python2 Tensorflow job on GPU (CUDA, cuDNN, etc. installed)\n\n$ floyd run --env tensorflow:py2 --gpu \npython mnist_cnn.py\n\n\n\n\nThe following software packages (in addition to many other common libraries) are available in all the environments:\n\nh5py, iPython, Jupyter, matplotlib, numpy, OpenCV, Pandas, Pillow, scikit-learn, scipy, sklearn\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Environments"
        }, 
        {
            "location": "/guides/environments/#environments", 
            "text": "Below is the list of Deep Learning environments supported by FloydHub. Any of\nthese can be specified in the floyd  run  command using the --env  option.  If no  --env  is provided, it uses the  keras  image by default, which comes with Python\n3, Keras 2.0.4 and Tensorflow 1.1.0 pre-installed.     Framework  Env name (--env parameter)  Description  Docker Image      Tensorflow 1.2  tensorflow-1.2  Tensorflow 1.2.0 + Keras 2.0.4 on Python3.  floydhub/tensorflow     tensorflow-1.2:py2  Tensorflow 1.2.0 + Keras 2.0.4 on Python2.  floydhub/tensorflow    Tensorflow 1.1  tensorflow  Tensorflow 1.1.0 + Keras 2.0.4 on Python3.  floydhub/tensorflow     tensorflow:py2  Tensorflow 1.1.0 + Keras 2.0.4 on Python2.  floydhub/tensorflow    Tensorflow 1.0  tensorflow-1.0  Tensorflow 1.0.0 + Keras 1.2.2 on Python3.  floydhub/tensorflow     tensorflow-1.0:py2  Tensorflow 1.0.0 + Keras 1.2.2 on Python2.  floydhub/tensorflow    Tensorflow 0.12  tensorflow-0.12  Tensorflow 0.12.1 + Keras 1.2.2 on Python3.  floydhub/tensorflow     tensorflow-0.12:py2  Tensorflow 0.12.1 + Keras 1.2.2 on Python2.  floydhub/tensorflow    Theano 0.8  theano-0.8  Theano rel-0.8.2 + Keras 1.2.2 on Python3.  floydhub/theano     theano-0.8:py2  Theano rel-0.8.2 + Keras 1.2.2 on Python2.  floydhub/theano    Theano 0.9  theano-0.9  Theano rel-0.8.2 + Keras 2.0.3 on Python3.  floydhub/theano     theano-0.9:py2  Theano rel-0.8.2 + Keras 2.0.3 on Python2.  floydhub/theano    Keras  -  Use tensorflow or theano for the appropriate Keras backend     Caffe  caffe  Caffe rc4 on Python3.  floydhub/caffe     caffe:py2  Caffe rc4 on Python2.  floydhub/caffe    Torch  torch  Torch 7 with Python 3 env.  floydhub/torch     torch:py2  Torch 7 with Python 2 env.  floydhub/torch    PyTorch  pytorch  PyTorch 0.1.9 on Python 3.  floydhub/pytorch     pytorch:py2  PyTorch 0.1.9 on Python 2.  floydhub/pytorch    Chainer 1.23 (beta)  chainer-1.23  Chainer 1.23.0 on Python 3.  floydhub/chainer     chainer-1.23:py2  Chainer 1.23.0 on Python 2.  floydhub/chainer    Chainer 2.0 (beta)  chainer-2.0  Chainer 1.23.0 on Python 3.  floydhub/chainer     chainer-2.0:py2  Chainer 1.23.0 on Python 2.  floydhub/chainer    MxNet (beta)  mxnet:py2  MxNet 0.9.3a on Python 2.  floydhub/mxnet    Kur  kur  Kur 0.3.0 on Python 3.  floydhub/kur     All environments are available for both CPU and GPU execution. For example,  To run a Python2 Tensorflow job on CPU $ floyd run --env tensorflow:py2  python mnist_cnn.py   To run a Python2 Tensorflow job on GPU (CUDA, cuDNN, etc. installed) $ floyd run --env tensorflow:py2 --gpu  python mnist_cnn.py   The following software packages (in addition to many other common libraries) are available in all the environments: h5py, iPython, Jupyter, matplotlib, numpy, OpenCV, Pandas, Pillow, scikit-learn, scipy, sklearn", 
            "title": "Environments"
        }, 
        {
            "location": "/guides/environments/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/guides/floyd_ignore/", 
            "text": "Floydignore is a special floyd cli construct that allows you to specify\nwhich files need to be uploaded to the server. This is very similar to\nhow gitignore works.\n\n\nMinimizing the number of files to upload saves upload time and disk space used\nby your experiments.\n\n\nInitialization\n\n\nEverytime a new dataset or project is \ninitialized\n using \nfloyd-cli\n a new\n\n.floydignore\n file is created in the current path.\n\n\n$ \ncd\n /code/project\n$ floyd init style-transfer\nProject \nstyle-transfer\n initialized in current directory\n$ cat .floydignore\n\n\n# Directories and files to ignore when uploading code to floyd\n\n\n.git\n.eggs\neggs\nlib\nlib64\nparts\nsdist\nvar\n\n\n\n\nNote: If a \n.floydignore\n file already exists in the initialization path, it will not be overridden.\n\n\nOptions\n\n\nThere are different ways to specify files, directories, or\n\nglob patterns\n that you want\nto be ignored. Below is a list with examples:\n\n\n# Ignore all .dat files in the whole project:\n*.dat\n\n# Ignore all .dat files in some_folder:\nsome_folder/*.dat\n\n# Ignore all .dat files in some_folder and its subfolders:\nsome_folder/**/*.dat\n\n# Ignore all files (and folders) named .DS_Store\n.DS_Store\n\n# Ignore a specific file named .DS_Store located in some_folder\nsome_folder/.DS_Store\n\n# Ignore all files named .DS_Store in some_folder and its subfolders\nsome_folder/**/.DS_Store\n\n# Ignore all files in some_folder\n/some_folder/\n\n# Ignore all files in some_folder (works the same as the rule above)\nsome_folder/\n\n# Ignore all files in some_folder (works the same as the rule above)\nsome_folder\n\n\n\n\nYou can also whitelist files, directories, and glob patterns by preceding them\nwith a \n!\n.  Items matching the pattern following the \n!\n that were excluded by\na previous pattern will become included again. It is not possible to re-include\na file if a parent directory of that file is excluded. Put a backslash (\n\\\n) in\nfront of the first \n!\n for patterns that begin with a literal \n!\n, for example,\n\n\\!important!.txt\n.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Ignore files"
        }, 
        {
            "location": "/guides/floyd_ignore/#initialization", 
            "text": "Everytime a new dataset or project is  initialized  using  floyd-cli  a new .floydignore  file is created in the current path.  $  cd  /code/project\n$ floyd init style-transfer\nProject  style-transfer  initialized in current directory\n$ cat .floydignore # Directories and files to ignore when uploading code to floyd \n\n.git\n.eggs\neggs\nlib\nlib64\nparts\nsdist\nvar  Note: If a  .floydignore  file already exists in the initialization path, it will not be overridden.", 
            "title": "Initialization"
        }, 
        {
            "location": "/guides/floyd_ignore/#options", 
            "text": "There are different ways to specify files, directories, or glob patterns  that you want\nto be ignored. Below is a list with examples:  # Ignore all .dat files in the whole project:\n*.dat\n\n# Ignore all .dat files in some_folder:\nsome_folder/*.dat\n\n# Ignore all .dat files in some_folder and its subfolders:\nsome_folder/**/*.dat\n\n# Ignore all files (and folders) named .DS_Store\n.DS_Store\n\n# Ignore a specific file named .DS_Store located in some_folder\nsome_folder/.DS_Store\n\n# Ignore all files named .DS_Store in some_folder and its subfolders\nsome_folder/**/.DS_Store\n\n# Ignore all files in some_folder\n/some_folder/\n\n# Ignore all files in some_folder (works the same as the rule above)\nsome_folder/\n\n# Ignore all files in some_folder (works the same as the rule above)\nsome_folder  You can also whitelist files, directories, and glob patterns by preceding them\nwith a  ! .  Items matching the pattern following the  !  that were excluded by\na previous pattern will become included again. It is not possible to re-include\na file if a parent directory of that file is excluded. Put a backslash ( \\ ) in\nfront of the first  !  for patterns that begin with a literal  ! , for example, \\!important!.txt .", 
            "title": "Options"
        }, 
        {
            "location": "/guides/floyd_ignore/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/examples/style_transfer/", 
            "text": "Neural Style Transfer is an algorithm for combining the content of one image with the style of another image \nusing convolutional neural networks. Here's an example that maps the artistic style of The Starry Night \nonto a night-time photograph of the Stanford campus:\n\n\n\n\n\n\n\n\nWe will use this example to demonstrate how Floyd can be used to deploy your trained model as a REST API endpoint that can be accessed over the web. \nThis feature is very useful if you want to quickly compare models or have others play with your models. This guide will \nwalk you through how to do this.\n\n\nSetup project\n\n\nFor this guide we will be using \nFast Style Transfer\n\nproject.\n\n\n$ git clone https://github.com/floydhub/fast-style-transfer\n$ \ncd\n fast-style-transfer\n$ floyd init fast-style-transfer\nProject \nfast-style-transfer\n initialized in the current directory\n\n\n\n\nTrain a model\n\n\nYou can train your model by running the \nstyle.py\n script in this repo on Floyd. You can specify any style image to use in the command line. Just \ndownload it and keep it in current path. In this example we will be starting from a \n\npre-trained model\n.\n\n\nTraining data\n\n\nThis project also requires access to the imagenet-vgg-verydeep-19 model and image training data. Floyd already has this data source available.\nYou can mount this at runtime using the \n--data\n parameter.\n\n\nTraining\n\n\n$ floyd run --gpu --env tensorflow-0.12:py2 --data narenst/datasets/coco-train-2014/1:images --data narenst/datasets/neural-style-transfer-pre-trained-models/1:models --data floydhub/datasets/imagenet-vgg-verydeep-19/3:vgg \npython style.py --vgg-path /vgg/imagenet-vgg-verydeep-19.mat --train-path /images/train2014 --style examples/style/la_muse.jpg --base-model-path /models/la_muse.ckpt --epoch 1 --total-iterations 10 --checkpoint-dir /output\n\n\n\n\n\nThis will kick off a new job on Floyd. This will take a few minutes to run and will generate the model. You can follow along the progress \nby using the \nlogs\n command. \n\n\n$ floyd logs \nJOB_NAME\n -t\n\n\nNow you need to get the ID of the \nOutput\n generated by your job. Floyd \ninfo\n can give you that information.\n\n\n$ floyd info \nJOB_NAME\n\n\n\n\n\nEvaluate your model\n\n\nYou can evaluate the generated model by running \nevaluate.py\n on sample images. Use the output id from the training step\nas the datasource in this step. Add any image you want to style transfer to the \nimages\n directory. Then run \nevaluate.py\n.\n\n\nfloyd run --env tensorflow-0.12:py2 --data \nREPLACE_WITH_OUTPUT_ID\n:input \npython evaluate.py --allow-different-dimensions  --checkpoint /input/fns.ckpt --in-path ./images/ --out-path /output/\n\n\n\nYou can track the status of the run with the status or logs command.\n\n\n$ floyd status \nJOB_NAME\n\n$ floyd logs \nJOB_NAME\n -t\n\n\n\n\nAfter the job finishes successfully, view the output directory to see the style transferred images. Run the floyd \noutput\n\nfor this.\n\n\n$ floyd output \nJOB_NAME\n\n\n\n\n\nImproving the model\n\n\nYou may notice that the output does not look great. That is because we ran the training for a small number of iterations. To train \na fully working model try the train step again, this time without setting \n--total-iterations\n and increasing the \n--epoch\n to 2.\nIt takes about 8 hours to train a model that works well. You can instead try one of our pre-trained models in the next section.\n\n\nEvaluate pre-trained models\n\n\nIf you want to try out some awesome pre-trained models for various styles, you can use the datasource with models available publicly.\nYou can play with any of these model and style transfer any image you prefer. Just add them to \nimages\n directory. And point to the \nright model in the \n--checkpoint\n parameter.\n\n\nfloyd run --env tensorflow-0.12:py2 --data narenst/datasets/neural-style-transfer-pre-trained-models/1:models \npython evaluate.py --allow-different-dimensions  --checkpoint /models/la_muse.ckpt --in-path ./images/ --out-path /output/\n\n\n\n\n\nYou can track the status of the run with the status command.\n\n\n$ floyd status \nJOB_NAME\n\n\n\n\n\nWhen the experiment is finished, you can see the style transferred images by running:\n\n\n$ floyd output \nJOB_NAME\n\n\n\n\n\n\n\nModel API\n\n\nYou can now host this model as a REST API. This means you can send any image to this API as a HTTP request and it will be style transferred. \n\n\nServe mode\n\n\nFloyd \nrun\n command has a \nserve\n mode. This will upload the files in the current directory and run a special command - \n\npython app.py\n. Floyd expects this file to contain the code to run a web server and listen on port \n5000\n. You can see the \n\napp.py\n file in the sample repository. This file handles the \nincoming request, executes the code in \nevaluate.py\n and returns the output.\n\n\nNote that this feature is in preview mode and is not production ready yet\n\n\n$ floyd run --env tensorflow-0.12:py2 --data narenst/datasets/neural-style-transfer-pre-trained-models/1:input --mode serve\nSyncing code ...\nRUN ID                  NAME                              VERSION\n----------------------  ------------------------------  ---------\nDJSdJAVa3u7AsFEMZMBBL5  floydhub/fast-style-transfer:5          \n5\n\n\nPath to service endpoint: https://www.floydhub.com/expose/t4AdkU6awahkT3ooNazw8c\n\nTo view logs enter:\n    floyd logs DJSdJAVa3u7AsFEMZMBBL5\n\n\n\n\nSending requests to the REST API\n\n\nNow you can send any image file as request to this api and it will return the style transferred image.\n\n\ncurl -o taipei_output.jpg -F \nfile=@./images/taipei101.jpg\n https://www.floydhub.com/expose/t4AdkU6awahkT3ooNazw8c\n\n\n\n\n\n\nYou will see the default style (\nla_muse\n) is applied to the input image.\n\n\nTrying out different models\n\n\nYou can also pass in the name of the checkpoint to use and the image will be style transferred accordingly:\n\n\ncurl -o taipei_udnie.jpg -F \nfile=@./images/taipei101.jpg\n -F \ncheckpoint=udnie.ckpt\n  https://www.floydhub.com/expose/MUDFXViCLArG2drppvU3nm\n\n\n\n\n\n\nThis uses a different style checkpoint to render the image. All the logic for this is present in the \napp.py\n file. You can update it to \nbe as complex as you prefer.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Style Transfer"
        }, 
        {
            "location": "/examples/style_transfer/#setup-project", 
            "text": "For this guide we will be using  Fast Style Transfer \nproject.  $ git clone https://github.com/floydhub/fast-style-transfer\n$  cd  fast-style-transfer\n$ floyd init fast-style-transfer\nProject  fast-style-transfer  initialized in the current directory", 
            "title": "Setup project"
        }, 
        {
            "location": "/examples/style_transfer/#train-a-model", 
            "text": "You can train your model by running the  style.py  script in this repo on Floyd. You can specify any style image to use in the command line. Just \ndownload it and keep it in current path. In this example we will be starting from a  pre-trained model .", 
            "title": "Train a model"
        }, 
        {
            "location": "/examples/style_transfer/#training-data", 
            "text": "This project also requires access to the imagenet-vgg-verydeep-19 model and image training data. Floyd already has this data source available.\nYou can mount this at runtime using the  --data  parameter.", 
            "title": "Training data"
        }, 
        {
            "location": "/examples/style_transfer/#training", 
            "text": "$ floyd run --gpu --env tensorflow-0.12:py2 --data narenst/datasets/coco-train-2014/1:images --data narenst/datasets/neural-style-transfer-pre-trained-models/1:models --data floydhub/datasets/imagenet-vgg-verydeep-19/3:vgg  python style.py --vgg-path /vgg/imagenet-vgg-verydeep-19.mat --train-path /images/train2014 --style examples/style/la_muse.jpg --base-model-path /models/la_muse.ckpt --epoch 1 --total-iterations 10 --checkpoint-dir /output   This will kick off a new job on Floyd. This will take a few minutes to run and will generate the model. You can follow along the progress \nby using the  logs  command.   $ floyd logs  JOB_NAME  -t \nNow you need to get the ID of the  Output  generated by your job. Floyd  info  can give you that information.  $ floyd info  JOB_NAME", 
            "title": "Training"
        }, 
        {
            "location": "/examples/style_transfer/#evaluate-your-model", 
            "text": "You can evaluate the generated model by running  evaluate.py  on sample images. Use the output id from the training step\nas the datasource in this step. Add any image you want to style transfer to the  images  directory. Then run  evaluate.py .  floyd run --env tensorflow-0.12:py2 --data  REPLACE_WITH_OUTPUT_ID :input  python evaluate.py --allow-different-dimensions  --checkpoint /input/fns.ckpt --in-path ./images/ --out-path /output/  \nYou can track the status of the run with the status or logs command.  $ floyd status  JOB_NAME \n$ floyd logs  JOB_NAME  -t  After the job finishes successfully, view the output directory to see the style transferred images. Run the floyd  output \nfor this.  $ floyd output  JOB_NAME", 
            "title": "Evaluate your model"
        }, 
        {
            "location": "/examples/style_transfer/#improving-the-model", 
            "text": "You may notice that the output does not look great. That is because we ran the training for a small number of iterations. To train \na fully working model try the train step again, this time without setting  --total-iterations  and increasing the  --epoch  to 2.\nIt takes about 8 hours to train a model that works well. You can instead try one of our pre-trained models in the next section.", 
            "title": "Improving the model"
        }, 
        {
            "location": "/examples/style_transfer/#evaluate-pre-trained-models", 
            "text": "If you want to try out some awesome pre-trained models for various styles, you can use the datasource with models available publicly.\nYou can play with any of these model and style transfer any image you prefer. Just add them to  images  directory. And point to the \nright model in the  --checkpoint  parameter.  floyd run --env tensorflow-0.12:py2 --data narenst/datasets/neural-style-transfer-pre-trained-models/1:models  python evaluate.py --allow-different-dimensions  --checkpoint /models/la_muse.ckpt --in-path ./images/ --out-path /output/   You can track the status of the run with the status command.  $ floyd status  JOB_NAME   When the experiment is finished, you can see the style transferred images by running:  $ floyd output  JOB_NAME", 
            "title": "Evaluate pre-trained models"
        }, 
        {
            "location": "/examples/style_transfer/#model-api", 
            "text": "You can now host this model as a REST API. This means you can send any image to this API as a HTTP request and it will be style transferred.", 
            "title": "Model API"
        }, 
        {
            "location": "/examples/style_transfer/#serve-mode", 
            "text": "Floyd  run  command has a  serve  mode. This will upload the files in the current directory and run a special command -  python app.py . Floyd expects this file to contain the code to run a web server and listen on port  5000 . You can see the  app.py  file in the sample repository. This file handles the \nincoming request, executes the code in  evaluate.py  and returns the output.  Note that this feature is in preview mode and is not production ready yet  $ floyd run --env tensorflow-0.12:py2 --data narenst/datasets/neural-style-transfer-pre-trained-models/1:input --mode serve\nSyncing code ...\nRUN ID                  NAME                              VERSION\n----------------------  ------------------------------  ---------\nDJSdJAVa3u7AsFEMZMBBL5  floydhub/fast-style-transfer:5           5 \n\nPath to service endpoint: https://www.floydhub.com/expose/t4AdkU6awahkT3ooNazw8c\n\nTo view logs enter:\n    floyd logs DJSdJAVa3u7AsFEMZMBBL5", 
            "title": "Serve mode"
        }, 
        {
            "location": "/examples/style_transfer/#sending-requests-to-the-rest-api", 
            "text": "Now you can send any image file as request to this api and it will return the style transferred image.  curl -o taipei_output.jpg -F  file=@./images/taipei101.jpg  https://www.floydhub.com/expose/t4AdkU6awahkT3ooNazw8c   You will see the default style ( la_muse ) is applied to the input image.", 
            "title": "Sending requests to the REST API"
        }, 
        {
            "location": "/examples/style_transfer/#trying-out-different-models", 
            "text": "You can also pass in the name of the checkpoint to use and the image will be style transferred accordingly:  curl -o taipei_udnie.jpg -F  file=@./images/taipei101.jpg  -F  checkpoint=udnie.ckpt   https://www.floydhub.com/expose/MUDFXViCLArG2drppvU3nm   This uses a different style checkpoint to render the image. All the logic for this is present in the  app.py  file. You can update it to \nbe as complex as you prefer.", 
            "title": "Trying out different models"
        }, 
        {
            "location": "/examples/style_transfer/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/examples/deep_corrector/", 
            "text": "Deep Text Corrector is an Tensorflow project made by \nAlex Paino\n for correcting\ngrammatical errors in short sentences. For example, the message \"I'm going to\nstore\" would be unaffected by typical autocorrection systems, when the user\nmost likely intendend to write \"I'm going to \nthe\n store\".\n\n\nIn this guide we will train a Tensorflow model for correcting sentences and use\nit to evaluate input sentences.  Finally we will deploy the trained model as a\nREST endpoint that can be used to evaluate input sequences in real time.\n\n\nProject setup\n\n\nThe code for this project is available on Floyd's \nGithub page\n. Clone the project and\n\ninitialize\n a floyd project.\n\n\n$ git clone https://github.com/floydhub/deep-text-corrector\n$ \ncd\n deep-text-corrector\n$ floyd init deep-text-corrector\n\n\n\n\nTraining\n\n\nDataset\n\n\nFor this project we will use the Cornel Movie-Dialogs Corpus for training and testing.\nThe dataset should be preprocessed and split into 3 sets: 80% for training, and 10%\neach for validation and testing. This preprocessed dataset is available publicly on\n\nFloydHub\n.\n\n\nTraining\n\n\nYou can train the deep corrector model by running \ncorrect_text.py\n script with required\nparameters. Below is the \ncommand\n to start a training job on Floyd:\n\n\n$ floyd run --gpu --env tensorflow-0.12:py2 --data floydhub/datasets/deep-text-corrector/1 \npython correct_text.py --num_steps 1000 --train_path /input/data/movie_dialog_train.txt --val_path /input/data/movie_dialog_val.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --output_path /output\n\n\n\n\n\nNotes:\n\n\n\n\nThe input dataset is passed using the \n--data\n parameter. This mounts the pre-processed\nCornell Movie Dialog dataset at \n/input\n path. You will notice that other parameters use files\nmounted in this path.\n\n\nThe data name \nfloydhub/datasets/deep-text-corrector/1\n\npoints to the pre-processed dataset on FloydHub.\n\n\nThe job is running on a gpu instance (Because of the \n--gpu\n flag).\n\n\nThis project uses Tensorflow-0.12 installed on Python 2. (See the \n--env\n flag)\n\n\n\n\nThis job takes about 10 minutes to run and generate a model. You can follow along the progress\nby using the \nlogs\n command.\n\n\n$ floyd logs \nJOB_NAME\n -t\n\n\n\n\nFloyd saves any content stored in the \n/output\n directory after the job is\nfinished. This output can be used as a datasource in the next project.  To get\nthe name of the output generated by your job use the\n\ninfo\n command.\n\n\n$ floyd info \nJOB_NAME\n\n\n\n\n\nEvaluating\n\n\nTo evaluate your model you can run the \ncorrect_text.py\n script with the \ndecode\n flag.\nYou need a file containing short messages for evaluation. The \ntest.txt\n file already has some\ninputs. You can update or add more strings to this file - one per line. You also need to\nuse the output from the training step above as the datasource in this step.\n\n\nfloyd run --env tensorflow-0.12:py2 --data \nREPLACE_WITH_JOB_OUTPUT_NAME\n \npython correct_text.py --train_path /input/data/movie_dialog_train.txt --test_path test.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --input_path /input --decode\n\n\n\n\n\nYou can track the status of the run with the status or logs command. The logs should print the\nconcerted messages from the test.txt file.\n\n\n$ floyd status \nJOB_NAME\n\n$ floyd logs \nJOB_NAME\n -t\n\n\n\n\nImproving your model\n\n\nYou may notice that the output does not look great. In fact, the algorithm would've added more\nmistakes into the sentences than correct it. That is because we ran the training for a small number\nof iterations. To train a fully working model try the training step again, this time by setting\nthe flag \nnum_steps\n to a large value. In general, about 20000 steps are necessary to give a\nworking corrector model. (Note: This takes a few hours to run on the GPU instance)\n\n\nEvaluate pre-trained models\n\n\nIf you want to try out a pre-trained model, FloydHub has a public job output for\nthis. You can mount it with job output name:\n\nfloydhub/deep-text-corrector/23/output\n\n.\n\n\nfloyd run --env tensorflow-0.12:py2 --data floydhub/deep-text-corrector/23/output \npython correct_text.py --train_path /input/data/movie_dialog_train.txt --test_path test.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --input_path /input --decode\n\n\n\n\n\nThis model should perform better on the given inputs compared to the previous one.\n\n\nServe model through REST API\n\n\nFloydHub supports seving mode for demo and testing purpose. If you run a job\nwith \n--mode serve\n flag, FloydHub will run the \napp.py\n file in your prorject\nand attach it to a dynamic service endpoint:\n\n\nfloyd run --mode serve --env tensorflow-0.12:py2 --data floydhub/deep-text-corrector/23/output:input\n\n\n\n\nThe above command will print out a service endpoint for this job in your terminal console.\n\n\nThe service endpoint will take couple minutes to become ready. Once it's up, you can interact with the model by sending text you want to correct:\n\n\ncurl -X POST -d \nI see it tomorrow\n \nREPLACE_WITH_YOUR_SERVICE_ENDPOINT\n\n\n\n\n\nAny job running in serving mode will stay up until it reaches maximum runtime. So\nonce you are done testing, remember to shutdown the job.\n\n\nNote that this feature is in preview mode and is not production ready yet\n\n\nWhat Next?\n\n\nThe model was trained using movie dialogues which are not the greatest sources of gramatically correct\nsentences. An improvement to this approach would be to use other datasources like \nProject Gutenberg\n.\nThis project was also discussed on \nHackerNews\n and you can\nfind lots of interesting alternatives there.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Deep Text Corrector"
        }, 
        {
            "location": "/examples/deep_corrector/#project-setup", 
            "text": "The code for this project is available on Floyd's  Github page . Clone the project and initialize  a floyd project.  $ git clone https://github.com/floydhub/deep-text-corrector\n$  cd  deep-text-corrector\n$ floyd init deep-text-corrector", 
            "title": "Project setup"
        }, 
        {
            "location": "/examples/deep_corrector/#training", 
            "text": "", 
            "title": "Training"
        }, 
        {
            "location": "/examples/deep_corrector/#dataset", 
            "text": "For this project we will use the Cornel Movie-Dialogs Corpus for training and testing.\nThe dataset should be preprocessed and split into 3 sets: 80% for training, and 10%\neach for validation and testing. This preprocessed dataset is available publicly on FloydHub .", 
            "title": "Dataset"
        }, 
        {
            "location": "/examples/deep_corrector/#training_1", 
            "text": "You can train the deep corrector model by running  correct_text.py  script with required\nparameters. Below is the  command  to start a training job on Floyd:  $ floyd run --gpu --env tensorflow-0.12:py2 --data floydhub/datasets/deep-text-corrector/1  python correct_text.py --num_steps 1000 --train_path /input/data/movie_dialog_train.txt --val_path /input/data/movie_dialog_val.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --output_path /output   Notes:   The input dataset is passed using the  --data  parameter. This mounts the pre-processed\nCornell Movie Dialog dataset at  /input  path. You will notice that other parameters use files\nmounted in this path.  The data name  floydhub/datasets/deep-text-corrector/1 \npoints to the pre-processed dataset on FloydHub.  The job is running on a gpu instance (Because of the  --gpu  flag).  This project uses Tensorflow-0.12 installed on Python 2. (See the  --env  flag)   This job takes about 10 minutes to run and generate a model. You can follow along the progress\nby using the  logs  command.  $ floyd logs  JOB_NAME  -t  Floyd saves any content stored in the  /output  directory after the job is\nfinished. This output can be used as a datasource in the next project.  To get\nthe name of the output generated by your job use the info  command.  $ floyd info  JOB_NAME", 
            "title": "Training"
        }, 
        {
            "location": "/examples/deep_corrector/#evaluating", 
            "text": "To evaluate your model you can run the  correct_text.py  script with the  decode  flag.\nYou need a file containing short messages for evaluation. The  test.txt  file already has some\ninputs. You can update or add more strings to this file - one per line. You also need to\nuse the output from the training step above as the datasource in this step.  floyd run --env tensorflow-0.12:py2 --data  REPLACE_WITH_JOB_OUTPUT_NAME   python correct_text.py --train_path /input/data/movie_dialog_train.txt --test_path test.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --input_path /input --decode   You can track the status of the run with the status or logs command. The logs should print the\nconcerted messages from the test.txt file.  $ floyd status  JOB_NAME \n$ floyd logs  JOB_NAME  -t", 
            "title": "Evaluating"
        }, 
        {
            "location": "/examples/deep_corrector/#improving-your-model", 
            "text": "You may notice that the output does not look great. In fact, the algorithm would've added more\nmistakes into the sentences than correct it. That is because we ran the training for a small number\nof iterations. To train a fully working model try the training step again, this time by setting\nthe flag  num_steps  to a large value. In general, about 20000 steps are necessary to give a\nworking corrector model. (Note: This takes a few hours to run on the GPU instance)", 
            "title": "Improving your model"
        }, 
        {
            "location": "/examples/deep_corrector/#evaluate-pre-trained-models", 
            "text": "If you want to try out a pre-trained model, FloydHub has a public job output for\nthis. You can mount it with job output name: floydhub/deep-text-corrector/23/output \n.  floyd run --env tensorflow-0.12:py2 --data floydhub/deep-text-corrector/23/output  python correct_text.py --train_path /input/data/movie_dialog_train.txt --test_path test.txt --config DefaultMovieDialogConfig --data_reader_type MovieDialogReader --input_path /input --decode   This model should perform better on the given inputs compared to the previous one.", 
            "title": "Evaluate pre-trained models"
        }, 
        {
            "location": "/examples/deep_corrector/#serve-model-through-rest-api", 
            "text": "FloydHub supports seving mode for demo and testing purpose. If you run a job\nwith  --mode serve  flag, FloydHub will run the  app.py  file in your prorject\nand attach it to a dynamic service endpoint:  floyd run --mode serve --env tensorflow-0.12:py2 --data floydhub/deep-text-corrector/23/output:input  The above command will print out a service endpoint for this job in your terminal console.  The service endpoint will take couple minutes to become ready. Once it's up, you can interact with the model by sending text you want to correct:  curl -X POST -d  I see it tomorrow   REPLACE_WITH_YOUR_SERVICE_ENDPOINT   Any job running in serving mode will stay up until it reaches maximum runtime. So\nonce you are done testing, remember to shutdown the job.  Note that this feature is in preview mode and is not production ready yet", 
            "title": "Serve model through REST API"
        }, 
        {
            "location": "/examples/deep_corrector/#what-next", 
            "text": "The model was trained using movie dialogues which are not the greatest sources of gramatically correct\nsentences. An improvement to this approach would be to use other datasources like  Project Gutenberg .\nThis project was also discussed on  HackerNews  and you can\nfind lots of interesting alternatives there.", 
            "title": "What Next?"
        }, 
        {
            "location": "/examples/deep_corrector/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/faqs/installation/", 
            "text": "Using virtualenv to install floyd-cli\n\n\nWe highly recommend using \nvirtualenv\n for installing and using \nfloyd-cli\n. This helps avoid any library version conflicts and results in a smoother installation process.\n\n\nsudo pip install virtualenv\n\n\n\n\nTo create a virtualenv, you need to pass a path to store the installed packages.\n\n\nvirtualenv ~/floyd\n\n\n\n\nYou can now activate and start using the virtualenv by running:\n\nsource\n ~/floyd/bin/activate\n\n\n\nTo install floyd-cli in this virtualenv:\n\n\npip install -U floyd-cli\n\n\n\n\nYou are now ready to use the \nfloyd commands\n. Note: You need to activate your virtualenv using the \nsource\n command above each time you open a new terminal and want to use \nfloyd-cli\n in it.\n\n\nUsing conda to install floyd-cli\n\n\nIf you are using Anaconda Python, you can also use \nconda\n to install \nfloyd-cli\n, instead of \nvirtualenv\n. \n\n\nconda create -n \ninsert-your-env-name-here\n\n\nsource\n activate \ninsert-your-env-name-here\n\npip install -U floyd-cli\n\n\n\n\nPlease see \nthis guide\n on creating virtual environments for Python with conda.\n\n\nUsing sudo to install floyd-cli\n\n\nTry this if you see a permission error, such as \nPermission denied\n or \nAccess is denied\n. If you are not using virtualenv and you are installing \nfloyd-cli\n globally you may need to use \nsudo\n:\n\n\nsudo pip install -U floyd-cli\n\n\n\n\nDealing with missing dependencies when installing floyd-cli\n\n\nNot all python environments are installed the same way. So sometimes you may run \ninto install issues. If \npip\n cannot install dependencies itself, you may see errors like:\n\n\n...\nFailed building wheel \nfor\n scandir\n...\n\n\n\n\nor\n\n\n...\nNo distributions matching the version \nfor\n backports.tempfile \n(\nfrom floyd-cli\n)\n\n...\n\n\n\n\nIn such cases, you can install the dependencies directly:\n\n\npip install -U scandir\npip install -U backports.tempfile\n\n\n\n\nand then try installing \nfloyd-cli\n.\n\n\nPython.h: No such file or directory\n\n\nIf you get this error in a linux environment:\n\n\n...\nPython.h: No such file or directory\n\n\n\n\nyou need to install \npython-dev\n package\n\n\nsudo apt-get install python-dev\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Installation FAQs"
        }, 
        {
            "location": "/faqs/installation/#using-virtualenv-to-install-floyd-cli", 
            "text": "We highly recommend using  virtualenv  for installing and using  floyd-cli . This helps avoid any library version conflicts and results in a smoother installation process.  sudo pip install virtualenv  To create a virtualenv, you need to pass a path to store the installed packages.  virtualenv ~/floyd  You can now activate and start using the virtualenv by running: source  ~/floyd/bin/activate  To install floyd-cli in this virtualenv:  pip install -U floyd-cli  You are now ready to use the  floyd commands . Note: You need to activate your virtualenv using the  source  command above each time you open a new terminal and want to use  floyd-cli  in it.", 
            "title": "Using virtualenv to install floyd-cli"
        }, 
        {
            "location": "/faqs/installation/#using-conda-to-install-floyd-cli", 
            "text": "If you are using Anaconda Python, you can also use  conda  to install  floyd-cli , instead of  virtualenv .   conda create -n  insert-your-env-name-here  source  activate  insert-your-env-name-here \npip install -U floyd-cli  Please see  this guide  on creating virtual environments for Python with conda.", 
            "title": "Using conda to install floyd-cli"
        }, 
        {
            "location": "/faqs/installation/#using-sudo-to-install-floyd-cli", 
            "text": "Try this if you see a permission error, such as  Permission denied  or  Access is denied . If you are not using virtualenv and you are installing  floyd-cli  globally you may need to use  sudo :  sudo pip install -U floyd-cli", 
            "title": "Using sudo to install floyd-cli"
        }, 
        {
            "location": "/faqs/installation/#dealing-with-missing-dependencies-when-installing-floyd-cli", 
            "text": "Not all python environments are installed the same way. So sometimes you may run \ninto install issues. If  pip  cannot install dependencies itself, you may see errors like:  ...\nFailed building wheel  for  scandir\n...  or  ...\nNo distributions matching the version  for  backports.tempfile  ( from floyd-cli ) \n...  In such cases, you can install the dependencies directly:  pip install -U scandir\npip install -U backports.tempfile  and then try installing  floyd-cli .", 
            "title": "Dealing with missing dependencies when installing floyd-cli"
        }, 
        {
            "location": "/faqs/installation/#pythonh-no-such-file-or-directory", 
            "text": "If you get this error in a linux environment:  ...\nPython.h: No such file or directory  you need to install  python-dev  package  sudo apt-get install python-dev", 
            "title": "Python.h: No such file or directory"
        }, 
        {
            "location": "/faqs/installation/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/faqs/authentication/", 
            "text": "Signup\n\n\nHow does the free CPU / GPU hours work?\n\n\nEvery one who signups to Floydhub will receive 2 hours of free CPU / GPU time\nfor running your projects. We hope this will give you enough time to evaluate\nFloydhub for your needs. We are working on a new free plan right now to better\nhelp new users explore the platform.\n\n\nEmail Verification\n\n\nAfter you signup on FloydHub, you have to verify your email address. You will receive an automated email from Floyd with a link that you can click to verify.\n\n\nI did not receive my verification email\n\n\nAs soon as you sign up on FloydHub, you should receive an automated email in your inbox with instructions to verify your email address. \n\n\nIf you do not receive an email within a few minutes:\n\n\n\n\nPlease check your spam folder. If the email is there, please \"Mark as not Spam\" to avoid this happening in the future\n\n\nIf you still don't receive an email, please try resending the verification email by clicking on \"Resend Verification Email\" at \nfloydhub.com/settings/security\n\n\n\n\n\n\n\n\nIf this still doesn't work, it is likely that your mail server (e.g. your work email server) is filtering out our emails. Please check with your email adminstrator to allow emails from the \nfloydhub.com\n domain.\n\n\n\n\nLogin\n\n\nWindows\n\n\nI get \"Invalid Token\" error on my Windows 10 machine when I run floyd login.\n\n\nIf you are using Windows command shell, there is an issue with pasting the token using the \nstandard \nCtrl + V\n shortcut. You need to use the Shell's Edit menu to paste the token. After copying the token from the browser, right click on the top bar of the command shell and select Edit -\n Paste. See image below:\n\n\n\n\nI still get the \"Invalid Token\" error after trying the above suggestion.\n\n\nIn some windows shells (like Git Bash) there is an extra space added to the token field\nbefore you paste the token. So you need to hit Backspace and clear out the field before pasting \nthe token. So the steps are:\n\n\n\n\nType \nfloyd login\n in the console.\n\n\nFrom the FloydHub web page, select the token and click on the \"Copy to clipboard\" button.\n\n\n\nIn the console, hit \"backspace\" a few times to remove the extra characters from the token login prompt request.\n\n\nRight click on the menu bar, and select \"Edit\", and then \"Paste\"\n\n\nThen press \"Enter\"\n\n\n\n\nYou should be able to login successfully now. If it's still not working, please give it a try on powershell.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Signup and Login FAQs"
        }, 
        {
            "location": "/faqs/authentication/#signup", 
            "text": "", 
            "title": "Signup"
        }, 
        {
            "location": "/faqs/authentication/#how-does-the-free-cpu-gpu-hours-work", 
            "text": "Every one who signups to Floydhub will receive 2 hours of free CPU / GPU time\nfor running your projects. We hope this will give you enough time to evaluate\nFloydhub for your needs. We are working on a new free plan right now to better\nhelp new users explore the platform.", 
            "title": "How does the free CPU / GPU hours work?"
        }, 
        {
            "location": "/faqs/authentication/#email-verification", 
            "text": "After you signup on FloydHub, you have to verify your email address. You will receive an automated email from Floyd with a link that you can click to verify.", 
            "title": "Email Verification"
        }, 
        {
            "location": "/faqs/authentication/#i-did-not-receive-my-verification-email", 
            "text": "As soon as you sign up on FloydHub, you should receive an automated email in your inbox with instructions to verify your email address.   If you do not receive an email within a few minutes:   Please check your spam folder. If the email is there, please \"Mark as not Spam\" to avoid this happening in the future  If you still don't receive an email, please try resending the verification email by clicking on \"Resend Verification Email\" at  floydhub.com/settings/security     If this still doesn't work, it is likely that your mail server (e.g. your work email server) is filtering out our emails. Please check with your email adminstrator to allow emails from the  floydhub.com  domain.", 
            "title": "I did not receive my verification email"
        }, 
        {
            "location": "/faqs/authentication/#login", 
            "text": "", 
            "title": "Login"
        }, 
        {
            "location": "/faqs/authentication/#windows", 
            "text": "", 
            "title": "Windows"
        }, 
        {
            "location": "/faqs/authentication/#i-get-invalid-token-error-on-my-windows-10-machine-when-i-run-floyd-login", 
            "text": "If you are using Windows command shell, there is an issue with pasting the token using the \nstandard  Ctrl + V  shortcut. You need to use the Shell's Edit menu to paste the token. After copying the token from the browser, right click on the top bar of the command shell and select Edit -  Paste. See image below:", 
            "title": "I get \"Invalid Token\" error on my Windows 10 machine when I run floyd login."
        }, 
        {
            "location": "/faqs/authentication/#i-still-get-the-invalid-token-error-after-trying-the-above-suggestion", 
            "text": "In some windows shells (like Git Bash) there is an extra space added to the token field\nbefore you paste the token. So you need to hit Backspace and clear out the field before pasting \nthe token. So the steps are:   Type  floyd login  in the console.  From the FloydHub web page, select the token and click on the \"Copy to clipboard\" button.  In the console, hit \"backspace\" a few times to remove the extra characters from the token login prompt request.  Right click on the menu bar, and select \"Edit\", and then \"Paste\"  Then press \"Enter\"   You should be able to login successfully now. If it's still not working, please give it a try on powershell.", 
            "title": "I still get the \"Invalid Token\" error after trying the above suggestion."
        }, 
        {
            "location": "/faqs/authentication/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/faqs/job/", 
            "text": "Why does \nfloyd status\n return an empty list even though I have several\n\n\nruns in my account?\n\n\nFloyd CLI uses the project directory to store the run information (similar to git). So you need\nto be in the directory where you initialized the project and you should be able to see all your\nruns. You can also use the \nweb dashboard\n to view all your\nprojects in one place.\n\n\nWhat do I do when I get \"What do you do when you get \u201cYou are over the allowed limits for this operation. Consider upgrading your account\u201d?\n\n\nFloydhub currently allows only 1 active job per user for trial plan and 3 active jobs for individual plan. If you require more concurrency, contact\nus from the \npricing\n page.\n\n\nI get \"Too many open files\" error when I run my project.\n\n\nFloyd CLI throws this error when you have too many files in your current directory that needs to be uploaded.\nThe actual limit depends on your OS / machine specs.\n\n\nYou can either:\n\n\n\n\nRemove unnecessary files from the directory (like build directory, docs etc.)\n\n\nAdd them to \n.floydignore\n file. Floyd CLI will just ignore these directories.\nSee the \nfloydignore\n documentation to understand how this can be configured.\n\n\nTar them into a single file and untar them at runtime.\n\n\n\n\nAlternatively, instead of uploading files from your local machine, you can also\n\ndownload files\n from a remote URL\ndirectly into Floyd servers.\n\n\nWhy do I get an \"Experiments limit reached\" error when I run a job?\n\n\nFloydHub currently allows only 1 active job in the free Trial plan and 3 active jobs in the Individual plan. \nIf you see an \nError\n:\n \nExperiments\n \nlimit\n \nreached\n message when you run a job, it means you have maxed out your \nconcurrency limits. Please stop you running job(s) or wait for them to finish, and try again.\n\n\nWe have to enforce this concurrency constraint because we have a finite number of GPU machines and have to ensure that no single user is starving the group. In the near future, we will support queueing of jobs so that you can queue multiple jobs to be run as slots become available.\n\n\nI ran my project in Jupyter mode but the url does not seem to work.\n\n\nJupyter notebook server takes a couple of minutes to start. Until then you will get a \"Bad Gateway\"\nor similar error when you access the URL. You can check the status of the Jupyter notebook\nby running the \nlogs\n command.\n\n\nAm I using the GPU instance by default?\n\n\nJobs are run on CPU instances by default. You can specify \n--gpu\n to run them on GPU instances.\n\n\nMy job is taking a while to \"sync changes\". How do I make it go faster?\n\n\nFloyd CLI uploads \nall\n the files in your current directory before starting your experiment.\nThere are a few ways to make this go faster:\n\n\n\n\nRemove unnecessary files from the directory (like build directory, docs etc.)\n\n\nAdd sub-directories to \n.floydignore\n file. Floyd CLI will ignore and not upload these sub-directories.\nSee the \ninit\n command and \nignore files guide\n to understand how this can be configured.\n\n\nIf you have large data files consider uploading them separately as a \ndata source\n.\nYou can then \nrefer\n to them in your project.\n\n\n\n\nMy job finished but how I do I see my output?\n\n\nYou can use the floyd \noutput\n command to view the output of your\nproject. If you want to use this output in your next run view \nthis guide\n.\n\n\nDo I have to pay for the entire time my Jupyter Notebook is running?\n\n\nUnfortunately, yes. As much as we would like to, we are unable to charge you only for the \ncomputation time\n.\n\n\nThis is an engineering challenge. When you start a Jupyter Notebook instance and start executing commands,\nyour state is maintained in memory (both CPU and GPU memory). So the instance has to be alive for the\nentire duration of your notebook, not just when you are executing commands.\n\n\nFor example, when you execute \nimport\n \ntensorflow\n\ncommand, Tensorflow will allocate the entire GPU memory to the current session and waits for the next command. This makes the instance unusable by anyone else, so we have to charge you for the duration your Notebook is alive.\n\n\nCan I view my Jupyter Notebook after my job has stopped?\n\n\nYes. When you use a Jupyter Notebook on FloydHub, your Notebook is saved periodically in the \n/output\n dir. So, your work is not lost after your job has ended, shutdown or timed out.\n\n\nYou can view your saved Notebook using the \nfloyd output\n command. Example:\n\n\n$ floyd output saip/projects/mnist-pytorch/3\n\n\n\n\nOr in the \nOutput\n tab of your job on the web dashboard, example: \nwww.floydhub.com/saip/projects/mnist-pytorch/3/output\n\n\nCan I restart a stopped or timed out job?\n\n\nUnfortunately, not directly. We will be implementing a single command to do this soon!\n\n\nIn the meanwhile, you can follow these steps to do this manually:\n\n\n\n\nJupyter Notebook\n: Your Notebook is \nsaved periodically\n. To restart your Notebook after your job has stopped, please download the output of your stopped job to your machine and start another job. Example:\n\n\n\n\n# Download the saved Notebook from previous job\n\n\n# NOTE: This will overwrite the contents of your current dir\n\n$ floyd data clone saip/projects/mnist-pytorch/3/output\n\n\n# Start a new job\n\n$ floyd run --mode jupyter\n\n\n\n\n\n\nScript\n: If you are running a script/command, you will have to start a new job using the \nfloyd run \ncommand\n command.\n\n\n\n\nWhy is my job in the \"Queued\" state for several minutes?\n\n\nThis means that a machine is being prepared to run your job. \n\n\nMost times, we have several CPU and GPU machines that are ready and your job can start execution in a few seconds. During high traffic periods, we may not have a machine ready for you and have to spin up a new instance for your job on-demand (details below). This might take up to 10 minutes in some cases. We are actively working on reducing this wait time.\n\n\nDetails\n: When you execute a \nfloyd run\n command, Floyd does several things in the background:\n\n\n\n\nProvision a CPU or GPU instance on the cloud\n\n\nSet up a deep learning environment with GPU drivers and the correct environment (as specified by \n--env\n) installed using Docker\n\n\nMount any data you specify using the \n--data\n flag\n\n\nSpin up a Jupyter server, if \n--mode jupyter\n flag\n\n\n\n\nEach of these steps can take up to a couple of minutes. Usually Steps 1 and 2 are already done, but during peak usage hours, we might have to do this on-demand.\n\n\nWhy do I see \"Setting up your instance...\" for several minutes when running a Jupyter Notebook?\n\n\nThe \nSetting up your instance...\n message is displayed when a machine is being prepared to run your Jupyter Notebook.\n\n\n\n\nWhen you execute a \nfloyd run --mode jupyter\n command, the CLI waits for a CPU or GPU machine to be ready before it opens up an interactive Jupyter Notebook for your work on. Usually, this takes a few seconds, but during high traffic periods it can take up to 10 minutes in some cases.\n\n\nFor more details on why it takes time, please see \nWhy is my job in the \"Queued\" state for several minutes?\n\n\nWhy are my logs not displayed in real-time?\n\n\nYou can stream your logs from the CLI using the \nfloyd logs -t \nJOB_NAME\n command. However, sometimes you may notice that the logs are not displayed in real-time. This is because of output buffering. Please make sure that your logs are flushed out if you prefer to view real-time logs.\n\n\nFor example, in Python:\n\n\nimport\n \nsys\n\n\n...\n\n\nprint\n(\nHello world\n)\n\n\nsys\n.\nstdout\n.\nflush\n()\n\n\n\n\n\nWhy did my job timeout after 1 hour?\n\n\nYou are likely in the Free Trial Plan. Jobs run in the trial plan have a maximum runtime of 1 hour. It will automatically timeout after that. \n\n\n\n\nYou can upgrade to the \nPaid Plan\n to overcome these limits.\n\n\nWhy was my CPU job Killed without warning?\n\n\nOccasionally, you may notice that your CPU job died without warning. The output logs just display \nKilled\n. For example,\n\n\n################################################################################\n\n\n\n2017\n-07-24 \n03\n:33:42,530 INFO - Run Output:\n...\n\n2017\n-07-24 \n03\n:33:52,920 INFO - Using TensorFlow backend.\n\n2017\n-07-24 \n03\n:34:04,381 INFO - \n loading UNet of size 1152x256...\n\n2017\n-07-24 \n03\n:34:10,942 INFO - Epoch \n1\n/100\n\n2017\n-07-24 \n03\n:35:17,221 INFO - Killed\n\n2017\n-07-24 \n03\n:35:18,680 INFO - \n\n################################################################################\n\n\n\n\n\nThis happens when your machine runs out of memory (OOM). i.e. your job consumes more memory than is available on our CPU machines.\n\n\nAll jobs run on FloydHub are executed inside a Docker container. Our current CPU machines have \n7GB memory\n. When memory used by your job exceeds 7GB, Docker automatically kills the job to protect the system and avoid abuse.\n\n\nThe resolution is to optimize your code to consume less memory. For example, read less data into your in-memory datastructures or reduce your batch size. We will be introducing more powerful CPUs, which higher memory in the near future.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Job FAQs"
        }, 
        {
            "location": "/faqs/job/#why-does-floyd-status-return-an-empty-list-even-though-i-have-several", 
            "text": "runs in my account?  Floyd CLI uses the project directory to store the run information (similar to git). So you need\nto be in the directory where you initialized the project and you should be able to see all your\nruns. You can also use the  web dashboard  to view all your\nprojects in one place.", 
            "title": "Why does floyd status return an empty list even though I have several"
        }, 
        {
            "location": "/faqs/job/#what-do-i-do-when-i-get-what-do-you-do-when-you-get-you-are-over-the-allowed-limits-for-this-operation-consider-upgrading-your-account", 
            "text": "Floydhub currently allows only 1 active job per user for trial plan and 3 active jobs for individual plan. If you require more concurrency, contact\nus from the  pricing  page.", 
            "title": "What do I do when I get \"What do you do when you get \u201cYou are over the allowed limits for this operation. Consider upgrading your account\u201d?"
        }, 
        {
            "location": "/faqs/job/#i-get-too-many-open-files-error-when-i-run-my-project", 
            "text": "Floyd CLI throws this error when you have too many files in your current directory that needs to be uploaded.\nThe actual limit depends on your OS / machine specs.  You can either:   Remove unnecessary files from the directory (like build directory, docs etc.)  Add them to  .floydignore  file. Floyd CLI will just ignore these directories.\nSee the  floydignore  documentation to understand how this can be configured.  Tar them into a single file and untar them at runtime.   Alternatively, instead of uploading files from your local machine, you can also download files  from a remote URL\ndirectly into Floyd servers.", 
            "title": "I get \"Too many open files\" error when I run my project."
        }, 
        {
            "location": "/faqs/job/#why-do-i-get-an-experiments-limit-reached-error-when-i-run-a-job", 
            "text": "FloydHub currently allows only 1 active job in the free Trial plan and 3 active jobs in the Individual plan. \nIf you see an  Error :   Experiments   limit   reached  message when you run a job, it means you have maxed out your \nconcurrency limits. Please stop you running job(s) or wait for them to finish, and try again.  We have to enforce this concurrency constraint because we have a finite number of GPU machines and have to ensure that no single user is starving the group. In the near future, we will support queueing of jobs so that you can queue multiple jobs to be run as slots become available.", 
            "title": "Why do I get an \"Experiments limit reached\" error when I run a job?"
        }, 
        {
            "location": "/faqs/job/#i-ran-my-project-in-jupyter-mode-but-the-url-does-not-seem-to-work", 
            "text": "Jupyter notebook server takes a couple of minutes to start. Until then you will get a \"Bad Gateway\"\nor similar error when you access the URL. You can check the status of the Jupyter notebook\nby running the  logs  command.", 
            "title": "I ran my project in Jupyter mode but the url does not seem to work."
        }, 
        {
            "location": "/faqs/job/#am-i-using-the-gpu-instance-by-default", 
            "text": "Jobs are run on CPU instances by default. You can specify  --gpu  to run them on GPU instances.", 
            "title": "Am I using the GPU instance by default?"
        }, 
        {
            "location": "/faqs/job/#my-job-is-taking-a-while-to-sync-changes-how-do-i-make-it-go-faster", 
            "text": "Floyd CLI uploads  all  the files in your current directory before starting your experiment.\nThere are a few ways to make this go faster:   Remove unnecessary files from the directory (like build directory, docs etc.)  Add sub-directories to  .floydignore  file. Floyd CLI will ignore and not upload these sub-directories.\nSee the  init  command and  ignore files guide  to understand how this can be configured.  If you have large data files consider uploading them separately as a  data source .\nYou can then  refer  to them in your project.", 
            "title": "My job is taking a while to \"sync changes\". How do I make it go faster?"
        }, 
        {
            "location": "/faqs/job/#my-job-finished-but-how-i-do-i-see-my-output", 
            "text": "You can use the floyd  output  command to view the output of your\nproject. If you want to use this output in your next run view  this guide .", 
            "title": "My job finished but how I do I see my output?"
        }, 
        {
            "location": "/faqs/job/#do-i-have-to-pay-for-the-entire-time-my-jupyter-notebook-is-running", 
            "text": "Unfortunately, yes. As much as we would like to, we are unable to charge you only for the  computation time .  This is an engineering challenge. When you start a Jupyter Notebook instance and start executing commands,\nyour state is maintained in memory (both CPU and GPU memory). So the instance has to be alive for the\nentire duration of your notebook, not just when you are executing commands.  For example, when you execute  import   tensorflow \ncommand, Tensorflow will allocate the entire GPU memory to the current session and waits for the next command. This makes the instance unusable by anyone else, so we have to charge you for the duration your Notebook is alive.", 
            "title": "Do I have to pay for the entire time my Jupyter Notebook is running?"
        }, 
        {
            "location": "/faqs/job/#can-i-view-my-jupyter-notebook-after-my-job-has-stopped", 
            "text": "Yes. When you use a Jupyter Notebook on FloydHub, your Notebook is saved periodically in the  /output  dir. So, your work is not lost after your job has ended, shutdown or timed out.  You can view your saved Notebook using the  floyd output  command. Example:  $ floyd output saip/projects/mnist-pytorch/3  Or in the  Output  tab of your job on the web dashboard, example:  www.floydhub.com/saip/projects/mnist-pytorch/3/output", 
            "title": "Can I view my Jupyter Notebook after my job has stopped?"
        }, 
        {
            "location": "/faqs/job/#can-i-restart-a-stopped-or-timed-out-job", 
            "text": "Unfortunately, not directly. We will be implementing a single command to do this soon!  In the meanwhile, you can follow these steps to do this manually:   Jupyter Notebook : Your Notebook is  saved periodically . To restart your Notebook after your job has stopped, please download the output of your stopped job to your machine and start another job. Example:   # Download the saved Notebook from previous job  # NOTE: This will overwrite the contents of your current dir \n$ floyd data clone saip/projects/mnist-pytorch/3/output # Start a new job \n$ floyd run --mode jupyter   Script : If you are running a script/command, you will have to start a new job using the  floyd run  command  command.", 
            "title": "Can I restart a stopped or timed out job?"
        }, 
        {
            "location": "/faqs/job/#why-is-my-job-in-the-queued-state-for-several-minutes", 
            "text": "This means that a machine is being prepared to run your job.   Most times, we have several CPU and GPU machines that are ready and your job can start execution in a few seconds. During high traffic periods, we may not have a machine ready for you and have to spin up a new instance for your job on-demand (details below). This might take up to 10 minutes in some cases. We are actively working on reducing this wait time.  Details : When you execute a  floyd run  command, Floyd does several things in the background:   Provision a CPU or GPU instance on the cloud  Set up a deep learning environment with GPU drivers and the correct environment (as specified by  --env ) installed using Docker  Mount any data you specify using the  --data  flag  Spin up a Jupyter server, if  --mode jupyter  flag   Each of these steps can take up to a couple of minutes. Usually Steps 1 and 2 are already done, but during peak usage hours, we might have to do this on-demand.", 
            "title": "Why is my job in the \"Queued\" state for several minutes?"
        }, 
        {
            "location": "/faqs/job/#why-do-i-see-setting-up-your-instance-for-several-minutes-when-running-a-jupyter-notebook", 
            "text": "The  Setting up your instance...  message is displayed when a machine is being prepared to run your Jupyter Notebook.   When you execute a  floyd run --mode jupyter  command, the CLI waits for a CPU or GPU machine to be ready before it opens up an interactive Jupyter Notebook for your work on. Usually, this takes a few seconds, but during high traffic periods it can take up to 10 minutes in some cases.  For more details on why it takes time, please see  Why is my job in the \"Queued\" state for several minutes?", 
            "title": "Why do I see \"Setting up your instance...\" for several minutes when running a Jupyter Notebook?"
        }, 
        {
            "location": "/faqs/job/#why-are-my-logs-not-displayed-in-real-time", 
            "text": "You can stream your logs from the CLI using the  floyd logs -t  JOB_NAME  command. However, sometimes you may notice that the logs are not displayed in real-time. This is because of output buffering. Please make sure that your logs are flushed out if you prefer to view real-time logs.  For example, in Python:  import   sys  ...  print ( Hello world )  sys . stdout . flush ()", 
            "title": "Why are my logs not displayed in real-time?"
        }, 
        {
            "location": "/faqs/job/#why-did-my-job-timeout-after-1-hour", 
            "text": "You are likely in the Free Trial Plan. Jobs run in the trial plan have a maximum runtime of 1 hour. It will automatically timeout after that.    You can upgrade to the  Paid Plan  to overcome these limits.", 
            "title": "Why did my job timeout after 1 hour?"
        }, 
        {
            "location": "/faqs/job/#why-was-my-cpu-job-killed-without-warning", 
            "text": "Occasionally, you may notice that your CPU job died without warning. The output logs just display  Killed . For example,  ################################################################################  2017 -07-24  03 :33:42,530 INFO - Run Output:\n... 2017 -07-24  03 :33:52,920 INFO - Using TensorFlow backend. 2017 -07-24  03 :34:04,381 INFO -   loading UNet of size 1152x256... 2017 -07-24  03 :34:10,942 INFO - Epoch  1 /100 2017 -07-24  03 :35:17,221 INFO - Killed 2017 -07-24  03 :35:18,680 INFO -  ################################################################################   This happens when your machine runs out of memory (OOM). i.e. your job consumes more memory than is available on our CPU machines.  All jobs run on FloydHub are executed inside a Docker container. Our current CPU machines have  7GB memory . When memory used by your job exceeds 7GB, Docker automatically kills the job to protect the system and avoid abuse.  The resolution is to optimize your code to consume less memory. For example, read less data into your in-memory datastructures or reduce your batch size. We will be introducing more powerful CPUs, which higher memory in the near future.", 
            "title": "Why was my CPU job Killed without warning?"
        }, 
        {
            "location": "/faqs/job/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/faqs/environments/", 
            "text": "Can I switch between Python 2 and Python 3 environments?\n\n\nMost of our Python based \nenvironments\n support both Python 2 and Python 3.\n\n\nThe default environments are Python 3. But you can use Python 2 by using the \n:py2\n tag with the environment name, when available. For example,\n\n\n\n\n\n\nTensorflow 1.2 with Python 3\n\n$ floyd run --env tensorflow-1.2\n\n\n\n\n\n\n\nTensorflow 1.2 with Python 2\n\n$ floyd run --env tensorflow-1.2:py2\n\n\n\n\n\n\n\nWe currently have Python 2 and 3 environments for Tensorflow, Theano, Caffe, PyTorch and Chainer. Please see our \ncomplete list of environments\n for more details on the \n--env\n name.", 
            "title": "Environments FAQs"
        }, 
        {
            "location": "/faqs/environments/#can-i-switch-between-python-2-and-python-3-environments", 
            "text": "Most of our Python based  environments  support both Python 2 and Python 3.  The default environments are Python 3. But you can use Python 2 by using the  :py2  tag with the environment name, when available. For example,    Tensorflow 1.2 with Python 3 $ floyd run --env tensorflow-1.2    Tensorflow 1.2 with Python 2 $ floyd run --env tensorflow-1.2:py2    We currently have Python 2 and 3 environments for Tensorflow, Theano, Caffe, PyTorch and Chainer. Please see our  complete list of environments  for more details on the  --env  name.", 
            "title": "Can I switch between Python 2 and Python 3 environments?"
        }, 
        {
            "location": "/faqs/plans/", 
            "text": "Please see here for \nBilling FAQs\n\n\nPlans\n\n\nWhich Plan is right for me?\n\n\nFree Plan\n\n\nIf you're just exploring, the Free plan is for you! You are automatically enrolled in the Free plan when you sign up on FloydHub. It includes \n20 hours of free CPU every month. You cannot, however, use a GPU or run multiple jobs \nin parallel.\n\n\nData Scientist Plan\n\n\nOur Data Scientist plans offer varying levels of \njob concurrency\n, GPU computing hours \nand storage. You can also purchase \nPowerups\n to add more compute hours to supplement your plan.\n\n\nData Scientist Base Plan\n: If you are getting started with deep learning and primarily use Jupyter Notebooks, the Base plan should work well for you. You can run 2 concurrent jobs on GPU and get 100 GB of storage included in the plan. \n\n\nData Scientist Plus and Pro Plans\n: If you are a more advanced user, you may need more job concurrency to run multiple parallel experiments and more storage for your data. The Plus and Pro plans will serve you better. \n\n\nPlease see the \nfeature comparison table\n for a full list of features.\n\n\nWhat is in the Trial plan?\n\n\nAll users that sign up on FloydHub are automatically enrolled in the Free plan. Additionally, we offer 2 hours of free GPU credits to try out FloydHub. The GPU credits expire in 14 days, but you will be able to use all the features of the Free plan forever.\n\n\nTake FloydHub for a pin with our \nQuick Start Guide\n or \nJupyter Notebook Guide\n!\n\n\nWhat is included in the Free plan?\n\n\nThe free plan comes with the following:\n\n\n\n\n20 hours of CPU compute / month\n\n\n10 GB free storage\n\n\nUnlimited public projects and datasets\n\n\nConcurrent jobs: You can only run one job at a time\n\n\n6 hour job timeout: The maximum runtime of a job on the Trial Plan is 6 hours. It will automatically timeout after that\n\n\n\n\nYou can upgrade to one of the \nData Scientist Plan\n to overcome these limits.\n\n\nDo the plans come with preemptible or dedicated instances?\n\n\nThe GPU and CPU compute hours included in your plan (Free or Data Scientist) are \n\npreemptible instances\n. This means that there is a small chance that your job will be terminated without notice. In practice, this happens infrequently and this is perfect for most users. If you need \ndedicated instances\n for your jobs, you \ncan buy the GPU+ or CPU+ Powerups.\n\n\nDo my remaining compute credits roll over each month if I don't use them all?\n\n\nNo, your monthly Plan compute credits are not rolled over. However, your Powerup credits will remain valid for one year from purchase date.\n\n\nWhat happened to the old Pay-as-you-go Individual Plan?\n\n\nWe are transitioning from the Individual Plan, which offered a pay-as-you-go payment method, to our current pricing plan. The Individual Plan is no longer available for new users. \n\n\nI am in the Pay-as-you-go Individual Plan. What will happen to me?\n\n\nIf you signed up for the Individual Plan before August 20\nth\n 2017, you will be grandfathered till October 1\nst\n 2017. After this, you will be automatically enrolled in the Free plan. Please note that any remaining promotional credits will also expire on this date.\n\n\nPlease \nupgrade\n to one of the Data Scientist plans to continue using FloydHub without interruption. We will also be reaching out to you with more information about this transition.\n\n\nWhy did I not get 100 free GPU hours when I signed up?\n\n\nWe offered 100 hours of free GPU for all users during our promotional period. This has ended.\n\n\nWill my free credits expire?\n\n\nThe current Trial plan includes 2 hours of free GPU credits. These will expire 14 days from the day you sign up. After 14 days, you will be transitioned to our Free plan.\n\n\nAre there any academic discounts for students?\n\n\nWe don't have discounts. However, a lot of students create content for us. If you are willing to contribute high quality content to FLoydHub, we will give you \nfree GPU credits\n in exchange! \n\n\nContent we are looking for: \n\n\n\n\nTechnical blogs on deep learning and AI\n\n\nFloydHub tutorials, text or video\n\n\nPort popular deep learning projects to FloydHub\n\n\nCreate interesting datasets\n\n\nInsert your own idea here\n\n\n\n\nIf this is interesting to you, please let us know about it \nhere\n.\n\n\nCompute\n\n\nWhat is job concurrency?\n\n\nJob concurrency is the number of jobs you can run in parallel. Each plan has a limit \non the number of concurrent jobs you can run. For example, in the Free plan, \nyou can only run 1 job at a time. In the Data Scientist Pro plan, you can run up \nto 8 jobs in parallel.\n\n\nHaving a higher concurrency is useful when you want to parallelize your training, for \nexample while hyperparameter sweeping.\n\n\nWhat will happen to my running job when I run out of computing credits?\n\n\nYou job will be shutdown immediately when you run out of computing credits. \n\n\nIf you run long-running jobs and expect them to exceed the computing hours offered by your plan, you can purchase \nPowerups\n.\n\n\nYou can also enable auto-refresh on your Powerups to ensure your long-running jobs are never killed because you ran out of computing hours. We'll automatically refresh your selected Powerup so that your job can continue running.\n\n\nPreemptible Instances\n\n\nPreemptible instances have medium job uptime SLA of 98%. This means that there is a small chance that your job can be terminated (preempted) at any point during its runtime by FloydHub if it requires access to those resources for other, higher priority tasks. \n\n\nPreemptible instances (CPU / GPU) offer top notch compute at affordable prices, in exchange for fault tolerance.\n\n\nNote that SLA refers to what we can guarantee. In practice, this happens infrequently. Historically, less than 0.1% of jobs run on FloydHub have encountered interruption. However, you need to be aware that there is the possibility.\n\n\nDedicated Instances\n\n\nDedicated instances have high job uptime SLA of 99.95%. Use dedicated instances for your jobs if they are critical or not fault tolerant. You can purchase '+' \nPowerups\n (CPU+ / GPU+) to utilize dedicated instances.\n\n\nWhy do you use preemptible instances?\n\n\nTo be able to offer you compute at a much lower cost.\n\n\nWe have a fixed pool of resources that we have to allocate amongst all our users. Some of our users require dedicated instances and are willing to pay the premium for uninterrupted access. But, the majority of our users can tolerate a 98% job uptime SLA for the significant price savings that preemptible instances offer.\n\n\nShould I use Dedicated instances?\n\n\nIf your job is not fault tolerant and cannot withstand a small (\n2%) chance \nof your job being shutdown without notice, you should use our \n+\n Dedicated instances. \nPrice sensitivity also plays a factor - dedicated instances are more expensive than \npremptible instances.\n\n\nGiven that deep learning models typically train over long periods of time, it \nis good practice to build your application to be fault tolerant by regularly checkpointing your training.\n\n\nWhat is the difference between GPU vs. GPU+ and CPU vs. CPU+?\n\n\nGPU and CPU are preemptible instances. GPU+ and CPU+ are dedicated instances.\n\n\nWhat is the SLA of Preemptible instances and Dedicated instances?\n\n\nPreemptible instances have 98% job up time SLA. Dedicated instances have 99.95% job up time SLA.\n\n\nWill I get a refund if my job is preempted?\n\n\nNo. \n\n\nOur preemptible instances have a 98% job uptime SLA. By using them, you are accepting a small chance \nof your job being terminated without notice, in exchange for paying a much lower price than dedicated instances.\n\n\nHow will I know when my job is preempted?\n\n\nYour job's state will turn from \nRunning\n to \nShutdown\n. We will send you a notification informing you about this. Unfortunately, we are currently unable to warn your ahead of time of an impending preemption.\n\n\nPowerups\n\n\nWhat are Powerups?\n\n\nYour subscription plan comes with a monthly quota of CPU and GPU computing hours. \nIf you need more computing hours, you can buy Powerups to supplement your plan.\n\n\nWhat Powerups should I buy?\n\n\nThis depends on your computing needs. We offer multiple tiers of Powerups:\n\n\n\n\nPreemptible vs. Dedicated\n: CPU / GPU are affordable \npreemptible instances\n, CPU+ / GPU+ are high-reliability \ndedicated instances\n.\n\n\n10 vs. 50 vs. 100 hours\n: Purchase a pack that suits your computing needs. Note that the larger packs offer compute at a much cheaper rate/hour than smaller packs.\n\n\nAuto-refresh\n: You can enable auto-refresh on any pack.\n\n\n\n\nIf you are \njust starting out\n and need more computing hours than your plan offers, you can start with the \nGPU10 Powerup\n. \n\n\nIf you run \nlong-running jobs\n, you should purchase the \nGPU100 with auto-refresh enabled\n, to ensure that you never run out of computing credits.\n\n\nIf you run \ncritical jobs\n that are not fault-tolerant, you should purchase the \nGPU+ Powerup\n.\n\n\nHow can I buy Powerups?\n\n\nYou can purchase them from your \nPowerups Dashboard\n\n\nWhy would I enable auto-refresh?\n\n\nAuto-refresh ensures your long-running jobs are never killed because you \nran out of computing hours\n. We'll automatically refresh your selected Powerup so that your Job can continue running.\n\n\nCan I buy a Powerup if I am in the Free Plan?\n\n\nNo. You have to be enrolled in one of the Data Scientist plans to be eligible for \npurchasing Powerups.\n\n\nDo Powerups expire?\n\n\nYes. Powerups are valid for 1 year from the date of purchase.\n\n\nHow will my Powerups be used?\n\n\nYour compute hours will be consumed in the following order:\n\n\n\n\nHours from your subscription plan\n\n\nHours from free credits\n\n\nHours from Powerups\n\n\n\n\nStorage\n\n\nHow much storage do I get?\n\n\nEach plan comes with its own storage limit. For example, the Free plan has \n10GB storage, while the Data Scientist Pro plan has 400GB. Please see the \n\nfeature comparison table\n for details.\n\n\nWhat counts against my storage?\n\n\nStorage is consumed by the datasets that you upload, your code and the data that your jobs output.\n\n\nNote that you are only responsible for the data that you own. For example, if you use a public dataset in your job, you won't be charged for it.\n\n\nCan I buy more storage than my plan offers?\n\n\nThe Data Scientist Pro plan includes 400GB of storage. If this doesn't fit your needs, \nplease contact us at \n.\n\n\nWe will soon have a storage Powerup that can you buy to add more storage to your base plan. \n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Plans FAQs"
        }, 
        {
            "location": "/faqs/plans/#plans", 
            "text": "", 
            "title": "Plans"
        }, 
        {
            "location": "/faqs/plans/#which-plan-is-right-for-me", 
            "text": "", 
            "title": "Which Plan is right for me?"
        }, 
        {
            "location": "/faqs/plans/#free-plan", 
            "text": "If you're just exploring, the Free plan is for you! You are automatically enrolled in the Free plan when you sign up on FloydHub. It includes \n20 hours of free CPU every month. You cannot, however, use a GPU or run multiple jobs \nin parallel.", 
            "title": "Free Plan"
        }, 
        {
            "location": "/faqs/plans/#data-scientist-plan", 
            "text": "Our Data Scientist plans offer varying levels of  job concurrency , GPU computing hours \nand storage. You can also purchase  Powerups  to add more compute hours to supplement your plan.  Data Scientist Base Plan : If you are getting started with deep learning and primarily use Jupyter Notebooks, the Base plan should work well for you. You can run 2 concurrent jobs on GPU and get 100 GB of storage included in the plan.   Data Scientist Plus and Pro Plans : If you are a more advanced user, you may need more job concurrency to run multiple parallel experiments and more storage for your data. The Plus and Pro plans will serve you better.   Please see the  feature comparison table  for a full list of features.", 
            "title": "Data Scientist Plan"
        }, 
        {
            "location": "/faqs/plans/#what-is-in-the-trial-plan", 
            "text": "All users that sign up on FloydHub are automatically enrolled in the Free plan. Additionally, we offer 2 hours of free GPU credits to try out FloydHub. The GPU credits expire in 14 days, but you will be able to use all the features of the Free plan forever.  Take FloydHub for a pin with our  Quick Start Guide  or  Jupyter Notebook Guide !", 
            "title": "What is in the Trial plan?"
        }, 
        {
            "location": "/faqs/plans/#what-is-included-in-the-free-plan", 
            "text": "The free plan comes with the following:   20 hours of CPU compute / month  10 GB free storage  Unlimited public projects and datasets  Concurrent jobs: You can only run one job at a time  6 hour job timeout: The maximum runtime of a job on the Trial Plan is 6 hours. It will automatically timeout after that   You can upgrade to one of the  Data Scientist Plan  to overcome these limits.", 
            "title": "What is included in the Free plan?"
        }, 
        {
            "location": "/faqs/plans/#do-the-plans-come-with-preemptible-or-dedicated-instances", 
            "text": "The GPU and CPU compute hours included in your plan (Free or Data Scientist) are  preemptible instances . This means that there is a small chance that your job will be terminated without notice. In practice, this happens infrequently and this is perfect for most users. If you need  dedicated instances  for your jobs, you \ncan buy the GPU+ or CPU+ Powerups.", 
            "title": "Do the plans come with preemptible or dedicated instances?"
        }, 
        {
            "location": "/faqs/plans/#do-my-remaining-compute-credits-roll-over-each-month-if-i-dont-use-them-all", 
            "text": "No, your monthly Plan compute credits are not rolled over. However, your Powerup credits will remain valid for one year from purchase date.", 
            "title": "Do my remaining compute credits roll over each month if I don't use them all?"
        }, 
        {
            "location": "/faqs/plans/#what-happened-to-the-old-pay-as-you-go-individual-plan", 
            "text": "We are transitioning from the Individual Plan, which offered a pay-as-you-go payment method, to our current pricing plan. The Individual Plan is no longer available for new users.", 
            "title": "What happened to the old Pay-as-you-go Individual Plan?"
        }, 
        {
            "location": "/faqs/plans/#i-am-in-the-pay-as-you-go-individual-plan-what-will-happen-to-me", 
            "text": "If you signed up for the Individual Plan before August 20 th  2017, you will be grandfathered till October 1 st  2017. After this, you will be automatically enrolled in the Free plan. Please note that any remaining promotional credits will also expire on this date.  Please  upgrade  to one of the Data Scientist plans to continue using FloydHub without interruption. We will also be reaching out to you with more information about this transition.", 
            "title": "I am in the Pay-as-you-go Individual Plan. What will happen to me?"
        }, 
        {
            "location": "/faqs/plans/#why-did-i-not-get-100-free-gpu-hours-when-i-signed-up", 
            "text": "We offered 100 hours of free GPU for all users during our promotional period. This has ended.", 
            "title": "Why did I not get 100 free GPU hours when I signed up?"
        }, 
        {
            "location": "/faqs/plans/#will-my-free-credits-expire", 
            "text": "The current Trial plan includes 2 hours of free GPU credits. These will expire 14 days from the day you sign up. After 14 days, you will be transitioned to our Free plan.", 
            "title": "Will my free credits expire?"
        }, 
        {
            "location": "/faqs/plans/#are-there-any-academic-discounts-for-students", 
            "text": "We don't have discounts. However, a lot of students create content for us. If you are willing to contribute high quality content to FLoydHub, we will give you  free GPU credits  in exchange!   Content we are looking for:    Technical blogs on deep learning and AI  FloydHub tutorials, text or video  Port popular deep learning projects to FloydHub  Create interesting datasets  Insert your own idea here   If this is interesting to you, please let us know about it  here .", 
            "title": "Are there any academic discounts for students?"
        }, 
        {
            "location": "/faqs/plans/#compute", 
            "text": "", 
            "title": "Compute"
        }, 
        {
            "location": "/faqs/plans/#what-is-job-concurrency", 
            "text": "Job concurrency is the number of jobs you can run in parallel. Each plan has a limit \non the number of concurrent jobs you can run. For example, in the Free plan, \nyou can only run 1 job at a time. In the Data Scientist Pro plan, you can run up \nto 8 jobs in parallel.  Having a higher concurrency is useful when you want to parallelize your training, for \nexample while hyperparameter sweeping.", 
            "title": "What is job concurrency?"
        }, 
        {
            "location": "/faqs/plans/#what-will-happen-to-my-running-job-when-i-run-out-of-computing-credits", 
            "text": "You job will be shutdown immediately when you run out of computing credits.   If you run long-running jobs and expect them to exceed the computing hours offered by your plan, you can purchase  Powerups .  You can also enable auto-refresh on your Powerups to ensure your long-running jobs are never killed because you ran out of computing hours. We'll automatically refresh your selected Powerup so that your job can continue running.", 
            "title": "What will happen to my running job when I run out of computing credits?"
        }, 
        {
            "location": "/faqs/plans/#preemptible-instances", 
            "text": "Preemptible instances have medium job uptime SLA of 98%. This means that there is a small chance that your job can be terminated (preempted) at any point during its runtime by FloydHub if it requires access to those resources for other, higher priority tasks.   Preemptible instances (CPU / GPU) offer top notch compute at affordable prices, in exchange for fault tolerance.  Note that SLA refers to what we can guarantee. In practice, this happens infrequently. Historically, less than 0.1% of jobs run on FloydHub have encountered interruption. However, you need to be aware that there is the possibility.", 
            "title": "Preemptible Instances"
        }, 
        {
            "location": "/faqs/plans/#dedicated-instances", 
            "text": "Dedicated instances have high job uptime SLA of 99.95%. Use dedicated instances for your jobs if they are critical or not fault tolerant. You can purchase '+'  Powerups  (CPU+ / GPU+) to utilize dedicated instances.", 
            "title": "Dedicated Instances"
        }, 
        {
            "location": "/faqs/plans/#why-do-you-use-preemptible-instances", 
            "text": "To be able to offer you compute at a much lower cost.  We have a fixed pool of resources that we have to allocate amongst all our users. Some of our users require dedicated instances and are willing to pay the premium for uninterrupted access. But, the majority of our users can tolerate a 98% job uptime SLA for the significant price savings that preemptible instances offer.", 
            "title": "Why do you use preemptible instances?"
        }, 
        {
            "location": "/faqs/plans/#should-i-use-dedicated-instances", 
            "text": "If your job is not fault tolerant and cannot withstand a small ( 2%) chance \nof your job being shutdown without notice, you should use our  +  Dedicated instances. \nPrice sensitivity also plays a factor - dedicated instances are more expensive than \npremptible instances.  Given that deep learning models typically train over long periods of time, it \nis good practice to build your application to be fault tolerant by regularly checkpointing your training.", 
            "title": "Should I use Dedicated instances?"
        }, 
        {
            "location": "/faqs/plans/#what-is-the-difference-between-gpu-vs-gpu-and-cpu-vs-cpu", 
            "text": "GPU and CPU are preemptible instances. GPU+ and CPU+ are dedicated instances.", 
            "title": "What is the difference between GPU vs. GPU+ and CPU vs. CPU+?"
        }, 
        {
            "location": "/faqs/plans/#what-is-the-sla-of-preemptible-instances-and-dedicated-instances", 
            "text": "Preemptible instances have 98% job up time SLA. Dedicated instances have 99.95% job up time SLA.", 
            "title": "What is the SLA of Preemptible instances and Dedicated instances?"
        }, 
        {
            "location": "/faqs/plans/#will-i-get-a-refund-if-my-job-is-preempted", 
            "text": "No.   Our preemptible instances have a 98% job uptime SLA. By using them, you are accepting a small chance \nof your job being terminated without notice, in exchange for paying a much lower price than dedicated instances.", 
            "title": "Will I get a refund if my job is preempted?"
        }, 
        {
            "location": "/faqs/plans/#how-will-i-know-when-my-job-is-preempted", 
            "text": "Your job's state will turn from  Running  to  Shutdown . We will send you a notification informing you about this. Unfortunately, we are currently unable to warn your ahead of time of an impending preemption.", 
            "title": "How will I know when my job is preempted?"
        }, 
        {
            "location": "/faqs/plans/#powerups", 
            "text": "", 
            "title": "Powerups"
        }, 
        {
            "location": "/faqs/plans/#what-are-powerups", 
            "text": "Your subscription plan comes with a monthly quota of CPU and GPU computing hours. \nIf you need more computing hours, you can buy Powerups to supplement your plan.", 
            "title": "What are Powerups?"
        }, 
        {
            "location": "/faqs/plans/#what-powerups-should-i-buy", 
            "text": "This depends on your computing needs. We offer multiple tiers of Powerups:   Preemptible vs. Dedicated : CPU / GPU are affordable  preemptible instances , CPU+ / GPU+ are high-reliability  dedicated instances .  10 vs. 50 vs. 100 hours : Purchase a pack that suits your computing needs. Note that the larger packs offer compute at a much cheaper rate/hour than smaller packs.  Auto-refresh : You can enable auto-refresh on any pack.   If you are  just starting out  and need more computing hours than your plan offers, you can start with the  GPU10 Powerup .   If you run  long-running jobs , you should purchase the  GPU100 with auto-refresh enabled , to ensure that you never run out of computing credits.  If you run  critical jobs  that are not fault-tolerant, you should purchase the  GPU+ Powerup .", 
            "title": "What Powerups should I buy?"
        }, 
        {
            "location": "/faqs/plans/#how-can-i-buy-powerups", 
            "text": "You can purchase them from your  Powerups Dashboard", 
            "title": "How can I buy Powerups?"
        }, 
        {
            "location": "/faqs/plans/#why-would-i-enable-auto-refresh", 
            "text": "Auto-refresh ensures your long-running jobs are never killed because you  ran out of computing hours . We'll automatically refresh your selected Powerup so that your Job can continue running.", 
            "title": "Why would I enable auto-refresh?"
        }, 
        {
            "location": "/faqs/plans/#can-i-buy-a-powerup-if-i-am-in-the-free-plan", 
            "text": "No. You have to be enrolled in one of the Data Scientist plans to be eligible for \npurchasing Powerups.", 
            "title": "Can I buy a Powerup if I am in the Free Plan?"
        }, 
        {
            "location": "/faqs/plans/#do-powerups-expire", 
            "text": "Yes. Powerups are valid for 1 year from the date of purchase.", 
            "title": "Do Powerups expire?"
        }, 
        {
            "location": "/faqs/plans/#how-will-my-powerups-be-used", 
            "text": "Your compute hours will be consumed in the following order:   Hours from your subscription plan  Hours from free credits  Hours from Powerups", 
            "title": "How will my Powerups be used?"
        }, 
        {
            "location": "/faqs/plans/#storage", 
            "text": "", 
            "title": "Storage"
        }, 
        {
            "location": "/faqs/plans/#how-much-storage-do-i-get", 
            "text": "Each plan comes with its own storage limit. For example, the Free plan has \n10GB storage, while the Data Scientist Pro plan has 400GB. Please see the  feature comparison table  for details.", 
            "title": "How much storage do I get?"
        }, 
        {
            "location": "/faqs/plans/#what-counts-against-my-storage", 
            "text": "Storage is consumed by the datasets that you upload, your code and the data that your jobs output.  Note that you are only responsible for the data that you own. For example, if you use a public dataset in your job, you won't be charged for it.", 
            "title": "What counts against my storage?"
        }, 
        {
            "location": "/faqs/plans/#can-i-buy-more-storage-than-my-plan-offers", 
            "text": "The Data Scientist Pro plan includes 400GB of storage. If this doesn't fit your needs, \nplease contact us at  .  We will soon have a storage Powerup that can you buy to add more storage to your base plan.", 
            "title": "Can I buy more storage than my plan offers?"
        }, 
        {
            "location": "/faqs/plans/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/faqs/billing/", 
            "text": "Please see here for \nPlan FAQs\n\n\nPayment Questions\n\n\nWhat forms of payments do you accept?\n\n\nWe accept Visa, MasterCard, American Express and Discover credit and debit cards. We do not accept prepaid cards at the moment. \n\n\nWe are a US based company. If you are outside the US, please ensure your card has \ninternational transactions enabled.\n\n\nDo you keep my credit card information?\n\n\nNo, we do not retain any credit card information. We use\n\nStripe\n to process payments.\n\n\nPayment processing failed. Whay am I unable to add my payment method?\n\n\nWhen you submit your payment details, you may received a \"Error: Payment processing failed\" error notification.\n\n\n\n\nSome common causes are:\n\n\n\n\nCredit and Debit cards only\n: We currently accept only Visa, Mastercard and AmEx credit and debit cards. We do not accept prepaid cards. Please ensure you are using a valid credit or debit card.\n\n\nBalance\n: We issue a small $0-1 transaction on your card as a pending authorization request between our billing system and the bank that issued your credit or debit card. If this authorization fails, you won't be able to add your card. Please ensure you have enough balance and are using a valid card. \nNote\n: This is an authorization request only, not an actual charge.\n\n\nFraud Detection\n: We use Stripe for managing all our payments. They have their own fraud detection algorithm which can decline some cards. Please try a different payment method.\n\n\nInternational Cards\n: We are a US based company. If you are outside the US please ensure your card has international transactions enabled.\n\n\n\n\nIf you are still unable to add your payment, please contact us directly at \n.\n\n\nBilling Questions\n\n\nWhat am I billed for?\n\n\nYour usage includes compute (CPU / GPU) usage and storage consumption. \n\n\n\n\n\n\nCompute\n: You will be billed exactly for the duration that your job runs, rounded off to the nearest second.\n\n\nNote that you are only charged for compute when your job is in the \nRunning\n state. You will \nnot\n be charged when your job is in any other state, including \nQueued\n and \nShutdown\n.\n\n\n\n\n\n\nStorage\n: You will also be charged for the storage you consume, rounded off to the nearest kB. \n\n\nStorage is consumed by the datasets that you upload, your code and the data that your jobs output.\n\n\n\n\n\n\nWhen will my card be charged?\n\n\nFor subscription plans, your card will be charged every month on the day you upgraded to the plan. For example, if you upgraded from the Free to the Data Scientist Pro plan on the 22\nnd\n of August, you will be charged immediately. You will be then billed on the 22\nnd\n of every month.\n\n\nWhen you purchase Powerups, either directly from the \nPowerups Dashboard\n or via auto-refresh, you will be charged at the time of purchase.\n\n\nCan I upgrade or downgrade my plan?\n\n\nYou can upgrade or downgrade your subscriptions at anytime from your \nPlans page\n under Settings on your dashboard.\n\n\nWhen you upgrade, you will be immediately elevated to the new plan. When you downgrade, your new plan will start at the end of your billing cycle (since you will have already paid for the month in advance).\n\n\nUpgrades and downgrades inside the Data Scientist plans do not affect any Powerups you \nmay have purchased.\n\n\nHow do upgrades work?\n\n\nWhen you upgrade from the Free plan to a paid plan, you will be charged immediately. You will then be billed on the 1 month anniversary of your subscription date every month. For example, if you upgrade on August 20\nth\n, 2017, you will be charged on that day and on the 20\nth\n of every subsequent month.\n\n\nWhen you upgrade from one paid plan to another, you will be charged for your new plan on a pro-rated basis. Lets say your billing cycle is on the 20\nth\n of every month. If you upgrade from the Data Scientist Base to the Pro plan on the 5\nth\n, you will be charged for the new plan on a pro-rated basis (5\nth\n to 20\nth\n).\n\n\nHow do downgrades work?\n\n\nYou can downgrade at any time to a lower or Free plan. \n\n\nIf you are over the usage limits for the plan you are downgrading to, you will have to handle that first. For example, if you are downgrading from the Data Scientist Pro to Base plan, but have 300GB data, you will have to delete some of your data before downgrading since the Base plan only offers 100 GB.\n\n\nIf you downgrade to the Free plan, you will no longer have access to any Powerups that you may have purchased.\n\n\nHow do I remove my credit card?\n\n\nPlease downgrade to the Free plan. We will remove your credit card at the end of your billing cycle.\n\n\nDo my remaining compute credits roll over each month if I don't use them all?\n\n\nNo, your monthly Plan compute credits are not rolled over. However, your Powerup credits will remain valid for one year from purchase date.\n\n\nDo you offer refunds?\n\n\nNo, we do not offer refunds. If there are extenuating circumstances, please open a ticket by contacting our support team.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "Billing FAQs"
        }, 
        {
            "location": "/faqs/billing/#payment-questions", 
            "text": "", 
            "title": "Payment Questions"
        }, 
        {
            "location": "/faqs/billing/#what-forms-of-payments-do-you-accept", 
            "text": "We accept Visa, MasterCard, American Express and Discover credit and debit cards. We do not accept prepaid cards at the moment.   We are a US based company. If you are outside the US, please ensure your card has \ninternational transactions enabled.", 
            "title": "What forms of payments do you accept?"
        }, 
        {
            "location": "/faqs/billing/#do-you-keep-my-credit-card-information", 
            "text": "No, we do not retain any credit card information. We use Stripe  to process payments.", 
            "title": "Do you keep my credit card information?"
        }, 
        {
            "location": "/faqs/billing/#payment-processing-failed-whay-am-i-unable-to-add-my-payment-method", 
            "text": "When you submit your payment details, you may received a \"Error: Payment processing failed\" error notification.   Some common causes are:   Credit and Debit cards only : We currently accept only Visa, Mastercard and AmEx credit and debit cards. We do not accept prepaid cards. Please ensure you are using a valid credit or debit card.  Balance : We issue a small $0-1 transaction on your card as a pending authorization request between our billing system and the bank that issued your credit or debit card. If this authorization fails, you won't be able to add your card. Please ensure you have enough balance and are using a valid card.  Note : This is an authorization request only, not an actual charge.  Fraud Detection : We use Stripe for managing all our payments. They have their own fraud detection algorithm which can decline some cards. Please try a different payment method.  International Cards : We are a US based company. If you are outside the US please ensure your card has international transactions enabled.   If you are still unable to add your payment, please contact us directly at  .", 
            "title": "Payment processing failed. Whay am I unable to add my payment method?"
        }, 
        {
            "location": "/faqs/billing/#billing-questions", 
            "text": "", 
            "title": "Billing Questions"
        }, 
        {
            "location": "/faqs/billing/#what-am-i-billed-for", 
            "text": "Your usage includes compute (CPU / GPU) usage and storage consumption.     Compute : You will be billed exactly for the duration that your job runs, rounded off to the nearest second.  Note that you are only charged for compute when your job is in the  Running  state. You will  not  be charged when your job is in any other state, including  Queued  and  Shutdown .    Storage : You will also be charged for the storage you consume, rounded off to the nearest kB.   Storage is consumed by the datasets that you upload, your code and the data that your jobs output.", 
            "title": "What am I billed for?"
        }, 
        {
            "location": "/faqs/billing/#when-will-my-card-be-charged", 
            "text": "For subscription plans, your card will be charged every month on the day you upgraded to the plan. For example, if you upgraded from the Free to the Data Scientist Pro plan on the 22 nd  of August, you will be charged immediately. You will be then billed on the 22 nd  of every month.  When you purchase Powerups, either directly from the  Powerups Dashboard  or via auto-refresh, you will be charged at the time of purchase.", 
            "title": "When will my card be charged?"
        }, 
        {
            "location": "/faqs/billing/#can-i-upgrade-or-downgrade-my-plan", 
            "text": "You can upgrade or downgrade your subscriptions at anytime from your  Plans page  under Settings on your dashboard.  When you upgrade, you will be immediately elevated to the new plan. When you downgrade, your new plan will start at the end of your billing cycle (since you will have already paid for the month in advance).  Upgrades and downgrades inside the Data Scientist plans do not affect any Powerups you \nmay have purchased.", 
            "title": "Can I upgrade or downgrade my plan?"
        }, 
        {
            "location": "/faqs/billing/#how-do-upgrades-work", 
            "text": "When you upgrade from the Free plan to a paid plan, you will be charged immediately. You will then be billed on the 1 month anniversary of your subscription date every month. For example, if you upgrade on August 20 th , 2017, you will be charged on that day and on the 20 th  of every subsequent month.  When you upgrade from one paid plan to another, you will be charged for your new plan on a pro-rated basis. Lets say your billing cycle is on the 20 th  of every month. If you upgrade from the Data Scientist Base to the Pro plan on the 5 th , you will be charged for the new plan on a pro-rated basis (5 th  to 20 th ).", 
            "title": "How do upgrades work?"
        }, 
        {
            "location": "/faqs/billing/#how-do-downgrades-work", 
            "text": "You can downgrade at any time to a lower or Free plan.   If you are over the usage limits for the plan you are downgrading to, you will have to handle that first. For example, if you are downgrading from the Data Scientist Pro to Base plan, but have 300GB data, you will have to delete some of your data before downgrading since the Base plan only offers 100 GB.  If you downgrade to the Free plan, you will no longer have access to any Powerups that you may have purchased.", 
            "title": "How do downgrades work?"
        }, 
        {
            "location": "/faqs/billing/#how-do-i-remove-my-credit-card", 
            "text": "Please downgrade to the Free plan. We will remove your credit card at the end of your billing cycle.", 
            "title": "How do I remove my credit card?"
        }, 
        {
            "location": "/faqs/billing/#do-my-remaining-compute-credits-roll-over-each-month-if-i-dont-use-them-all", 
            "text": "No, your monthly Plan compute credits are not rolled over. However, your Powerup credits will remain valid for one year from purchase date.", 
            "title": "Do my remaining compute credits roll over each month if I don't use them all?"
        }, 
        {
            "location": "/faqs/billing/#do-you-offer-refunds", 
            "text": "No, we do not offer refunds. If there are extenuating circumstances, please open a ticket by contacting our support team.", 
            "title": "Do you offer refunds?"
        }, 
        {
            "location": "/faqs/billing/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/", 
            "text": "Floyd Commands\n\n\nBelow are the commands that are part of Floyd CLI.\n\n\n\n\n\n\n\n\nCommand\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfloyd login\n\n\nLogin to Floyd.\n\n\n\n\n\n\nfloyd init\n\n\nInitialize a Floyd project\n\n\n\n\n\n\nfloyd run\n\n\nRun your project on Floyd\n\n\n\n\n\n\nfloyd data\n\n\nManage data on Floyd\n\n\n\n\n\n\nfloyd logs\n\n\nStream logs of your job\n\n\n\n\n\n\nfloyd status\n\n\nCheck status of your jobs\n\n\n\n\n\n\nfloyd clone\n\n\nClone an existing floyd project\n\n\n\n\n\n\nfloyd output\n\n\nView the output of a job\n\n\n\n\n\n\nfloyd info\n\n\nSee details of a job\n\n\n\n\n\n\nfloyd stop\n\n\nTerminate a job\n\n\n\n\n\n\nfloyd logout\n\n\nLogout from Floyd\n\n\n\n\n\n\nfloyd version\n\n\nSee version of floyd client\n\n\n\n\n\n\nfloyd upgrade\n\n\nUpgrade floyd client", 
            "title": "floyd"
        }, 
        {
            "location": "/commands/#floyd-commands", 
            "text": "Below are the commands that are part of Floyd CLI.     Command  Description      floyd login  Login to Floyd.    floyd init  Initialize a Floyd project    floyd run  Run your project on Floyd    floyd data  Manage data on Floyd    floyd logs  Stream logs of your job    floyd status  Check status of your jobs    floyd clone  Clone an existing floyd project    floyd output  View the output of a job    floyd info  See details of a job    floyd stop  Terminate a job    floyd logout  Logout from Floyd    floyd version  See version of floyd client    floyd upgrade  Upgrade floyd client", 
            "title": "Floyd Commands"
        }, 
        {
            "location": "/commands/login/", 
            "text": "Login to Floyd.\n\n\nUsage\n\n\nfloyd login\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--token\n\n\nFalse\n\n\nIf specified, browser will not open. You can paste your token in the command line. \nNote\n: This is only supported with \nversion 0.7.2+\n of \nfloyd-cli\n. If you get an error, please upgrade using \npip install -U floyd-cli\n and try again\n\n\n\n\n\n\n\n\nDescription\n\n\nYou need to login to Floyd before running any other command. The login flow will require an access token from the Floydhub \nwebsite. You will be prompted to enter you credentials to get your access token. Copy and paste the token on the command line \nto complete login.\n\n\nExample\n\n\nTo automatically open your browser\n\n$ floyd login\nAuthentication token page will now open in your browser. Continue? \n[\nY/n\n]\n:\nPlease paste the token here:\nLogin Successful\n\n\n\nIn case you use remote machines and do not have access to the browser, you can copy the token from the \n\ndashboard\n and use the \n--token\n parameter when you login.\n\n$ floyd login --token\nPlease copy and paste the token here:\nLogin Successful\n\n\n\nAuthentication Tokens\n\n\nFloyd uses \nJson Web Tokens\n for authentication. Your \ntoken will be stored in the \n~/.floydconfig\n file. They are valid for 7 days after \nwhich you need to login again. This file will be removed when you \nlogout\n.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd login"
        }, 
        {
            "location": "/commands/login/#usage", 
            "text": "floyd login", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/login/#options", 
            "text": "Name, shorthand  Default  Description      --token  False  If specified, browser will not open. You can paste your token in the command line.  Note : This is only supported with  version 0.7.2+  of  floyd-cli . If you get an error, please upgrade using  pip install -U floyd-cli  and try again", 
            "title": "Options"
        }, 
        {
            "location": "/commands/login/#description", 
            "text": "You need to login to Floyd before running any other command. The login flow will require an access token from the Floydhub \nwebsite. You will be prompted to enter you credentials to get your access token. Copy and paste the token on the command line \nto complete login.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/login/#example", 
            "text": "To automatically open your browser $ floyd login\nAuthentication token page will now open in your browser. Continue?  [ Y/n ] :\nPlease paste the token here:\nLogin Successful  In case you use remote machines and do not have access to the browser, you can copy the token from the  dashboard  and use the  --token  parameter when you login. $ floyd login --token\nPlease copy and paste the token here:\nLogin Successful", 
            "title": "Example"
        }, 
        {
            "location": "/commands/login/#authentication-tokens", 
            "text": "Floyd uses  Json Web Tokens  for authentication. Your \ntoken will be stored in the  ~/.floydconfig  file. They are valid for 7 days after \nwhich you need to login again. This file will be removed when you  logout .", 
            "title": "Authentication Tokens"
        }, 
        {
            "location": "/commands/login/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/init/", 
            "text": "Initialize a Floyd project.\n\n\nUsage\n\n\nfloyd init PROJECT_NAME\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nPROJECT_NAME\n\n\n\n\nName of your project (Pick a name from the projects page in web dashboard)\n\n\n\n\n\n\n\n\nDescription\n\n\nThis command initializes the current directory for a given project name and tracks all the files and subdirectories. \nMake sure that the project name you enter here already exists in Floyd. In case the project name does not exist, \nthe CLI will open the create project page in your browser.\n\n\nTo initialize a new dataset you should use \nfloyd data init\n command.\n\n\nThe init command also creates a \n.floydignore\n file. Any files and directories you do not want Floyd to track can be added \nto this file. When you run your project on Floyd, these files will not be uploaded. More details on how floydignore \nfile works is available \nhere\n.\n\n\nExample\n\n\nInitialize a floyd project in your project directory.\n\n$ \ncd\n /code/project\n$ floyd init style-transfer\nProject \nstyle-transfer\n initialized in current directory\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd init"
        }, 
        {
            "location": "/commands/init/#usage", 
            "text": "floyd init PROJECT_NAME", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/init/#options", 
            "text": "Name, shorthand  Default  Description      PROJECT_NAME   Name of your project (Pick a name from the projects page in web dashboard)", 
            "title": "Options"
        }, 
        {
            "location": "/commands/init/#description", 
            "text": "This command initializes the current directory for a given project name and tracks all the files and subdirectories. \nMake sure that the project name you enter here already exists in Floyd. In case the project name does not exist, \nthe CLI will open the create project page in your browser.  To initialize a new dataset you should use  floyd data init  command.  The init command also creates a  .floydignore  file. Any files and directories you do not want Floyd to track can be added \nto this file. When you run your project on Floyd, these files will not be uploaded. More details on how floydignore \nfile works is available  here .", 
            "title": "Description"
        }, 
        {
            "location": "/commands/init/#example", 
            "text": "Initialize a floyd project in your project directory. $  cd  /code/project\n$ floyd init style-transfer\nProject  style-transfer  initialized in current directory", 
            "title": "Example"
        }, 
        {
            "location": "/commands/init/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/run/", 
            "text": "Run your project on Floyd.\n\n\nUsage\n\n\nfloyd run \n[\nOPTIONS\n]\n \n[\nCOMMAND\n]\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--gpu/--cpu\n\n\ncpu\n\n\nIf specified, runs the job on a GPU (G1) instance or CPU (C1) instance. See instance specifications on the \npricing\n page.\n\n\n\n\n\n\n--data \nID:mount\n\n\n\n\nID\n of the data source to link to. \nmount\n specifies the path to mount it at. You can use this parameter multiple times. See \ndata\n section for more details.\n\n\n\n\n\n\n--mode [jupyter|serve]\n\n\ncommand\n\n\nSpecify the mode you want to run the project. The default behavior executes the command you specify. See \njupyter\n and \nserve\n sections for more info on them.\n\n\n\n\n\n\n--no-open\n\n\n\n\nYou can disable the CLI from opening the jupyter notebook url. It will print the URL instead.\n\n\n\n\n\n\n--env [tensorflow:py3|tensorflow:py2|...]\n\n\nkeras:py3\n\n\nSpecify the environment you want to use for your project. See \nenvironments\n for the full list.\n\n\n\n\n\n\n--message \nmessage_str\n\n\n\n\nAttach a message to the specific run of the project.\n\n\n\n\n\n\n--tensorboard\n\n\n\n\nStarts tensorboard in the environment. Tensorboard URL can be found in the dashboard.\n\n\n\n\n\n\ncommand\n\n\n\n\nCommand to execute when running your project on Floyd.\n\n\n\n\n\n\n\n\nDescription\n\n\nThis command syncs the code tracked by the CLI to the Floyd servers and executes your command. You can see the progress \nwith \nstatus\n command. To view the logs from your code use \nlogs\n command.\n\n\nExample\n\n\n$ floyd run \npython train_tf.py -lr 0.01 -output /output/model.bin\n\nSyncing code ...\nRUN ID                  NAME                         \n----------------------  -----------------------------\ndTe2cJJrNR2CBD74rSZXPA  floydhub/tensorflow-project/7\n\n...\n$ floyd logs floydhub/tensorflow-project/7\n\n\n\n\nfloyd_requirements.txt\n\n\nFloyd runs standard Docker images for various deep learning frameworks.(See \nenvironments\n for details). If your \ncode requires additional Python dependencies you can specify them in a \nfloyd_requirements.txt\n file and place it at the root \ndirectory of your project. These dependencies will be installed before running your code.\n\n\nExample\n\n\n$ cat floyd_requirements.txt\nPillow\nscipy\n$ floyd run \npython train_tf.py -lr 0.01 -output /output/model.bin\n\n\n\n\n\nJupyter notebook\n\n\nFloyd supports running Jupyter/iPython notebooks on the server. Make sure that the notebook (.ipynb) files are present in the \ncurrent directory. Use \n--mode jupyter\n and you will be presented with a URL to view your Jupyter environment. You do not need \nto specify a command in this mode. See \njupyter\n page for more details.\n\n\nExample\n\n\n$ floyd run --mode jupyter\n...\nPath to jupyter notebook: https://www.floydhub.com/notebooks/g8uGRZFQz85meArJGToEcs\n\n\n\n\nAttaching multiple datasets\n\n\nYou can attach upto 5 datasets when you run a project using the run command. You can specify both \ndatasets you uploaded and output datasets of your previous runs. You can specify the mount point \nalso when you specify the data id to mount.\n\n\nExample:\n\n\n$ floyd run --data floydhub/datasets/cifar/1:training --data floydhub/datasets/faces/21:testing \npython script.py\n\n\n\nThe above datasets will be mounted at \n/training\n and \n/testing\n respectively.\n\n\nServe\n\n\nFloyd can be used to host the model you generated as a REST api. This api can be used to evaluate your model over HTTP.\nUse \n--mode serve\n and you will be presented with a URL to access your API. Floyd currently supports only Flask apps.\nIt runs app.py file and expects the service to run on port 5000. You do not need to specify a command in this mode.\nSee \nserve\n page for more details.\n\n\nExample\n\n\n$ floyd run --mode serve\n...\nPath to service endpoint: https://www.floydhub.com/expose/vbKSKgVYGgZqmM9i3LjLBb\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd run"
        }, 
        {
            "location": "/commands/run/#usage", 
            "text": "floyd run  [ OPTIONS ]   [ COMMAND ]", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/run/#options", 
            "text": "Name, shorthand  Default  Description      --gpu/--cpu  cpu  If specified, runs the job on a GPU (G1) instance or CPU (C1) instance. See instance specifications on the  pricing  page.    --data  ID:mount   ID  of the data source to link to.  mount  specifies the path to mount it at. You can use this parameter multiple times. See  data  section for more details.    --mode [jupyter|serve]  command  Specify the mode you want to run the project. The default behavior executes the command you specify. See  jupyter  and  serve  sections for more info on them.    --no-open   You can disable the CLI from opening the jupyter notebook url. It will print the URL instead.    --env [tensorflow:py3|tensorflow:py2|...]  keras:py3  Specify the environment you want to use for your project. See  environments  for the full list.    --message  message_str   Attach a message to the specific run of the project.    --tensorboard   Starts tensorboard in the environment. Tensorboard URL can be found in the dashboard.    command   Command to execute when running your project on Floyd.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/run/#description", 
            "text": "This command syncs the code tracked by the CLI to the Floyd servers and executes your command. You can see the progress \nwith  status  command. To view the logs from your code use  logs  command.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/run/#example", 
            "text": "$ floyd run  python train_tf.py -lr 0.01 -output /output/model.bin \nSyncing code ...\nRUN ID                  NAME                         \n----------------------  -----------------------------\ndTe2cJJrNR2CBD74rSZXPA  floydhub/tensorflow-project/7\n\n...\n$ floyd logs floydhub/tensorflow-project/7", 
            "title": "Example"
        }, 
        {
            "location": "/commands/run/#floyd_requirementstxt", 
            "text": "Floyd runs standard Docker images for various deep learning frameworks.(See  environments  for details). If your \ncode requires additional Python dependencies you can specify them in a  floyd_requirements.txt  file and place it at the root \ndirectory of your project. These dependencies will be installed before running your code.", 
            "title": "floyd_requirements.txt"
        }, 
        {
            "location": "/commands/run/#example_1", 
            "text": "$ cat floyd_requirements.txt\nPillow\nscipy\n$ floyd run  python train_tf.py -lr 0.01 -output /output/model.bin", 
            "title": "Example"
        }, 
        {
            "location": "/commands/run/#jupyter-notebook", 
            "text": "Floyd supports running Jupyter/iPython notebooks on the server. Make sure that the notebook (.ipynb) files are present in the \ncurrent directory. Use  --mode jupyter  and you will be presented with a URL to view your Jupyter environment. You do not need \nto specify a command in this mode. See  jupyter  page for more details.", 
            "title": "Jupyter notebook"
        }, 
        {
            "location": "/commands/run/#example_2", 
            "text": "$ floyd run --mode jupyter\n...\nPath to jupyter notebook: https://www.floydhub.com/notebooks/g8uGRZFQz85meArJGToEcs", 
            "title": "Example"
        }, 
        {
            "location": "/commands/run/#attaching-multiple-datasets", 
            "text": "You can attach upto 5 datasets when you run a project using the run command. You can specify both \ndatasets you uploaded and output datasets of your previous runs. You can specify the mount point \nalso when you specify the data id to mount.", 
            "title": "Attaching multiple datasets"
        }, 
        {
            "location": "/commands/run/#example_3", 
            "text": "$ floyd run --data floydhub/datasets/cifar/1:training --data floydhub/datasets/faces/21:testing  python script.py  \nThe above datasets will be mounted at  /training  and  /testing  respectively.", 
            "title": "Example:"
        }, 
        {
            "location": "/commands/run/#serve", 
            "text": "Floyd can be used to host the model you generated as a REST api. This api can be used to evaluate your model over HTTP.\nUse  --mode serve  and you will be presented with a URL to access your API. Floyd currently supports only Flask apps.\nIt runs app.py file and expects the service to run on port 5000. You do not need to specify a command in this mode.\nSee  serve  page for more details.", 
            "title": "Serve"
        }, 
        {
            "location": "/commands/run/#example_4", 
            "text": "$ floyd run --mode serve\n...\nPath to service endpoint: https://www.floydhub.com/expose/vbKSKgVYGgZqmM9i3LjLBb", 
            "title": "Example"
        }, 
        {
            "location": "/commands/run/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/data/", 
            "text": "Manage your data sets on Floyd. The subcommands are:\n\n\n\n\n\n\n\n\nCommand\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfloyd data init\n\n\nInitialize a dataset\n\n\n\n\n\n\nfloyd data upload\n\n\nCreate a new dataset version\n\n\n\n\n\n\nfloyd data status\n\n\nList all your datasets\n\n\n\n\n\n\nfloyd data clone\n\n\nClone an existing dataset\n\n\n\n\n\n\nfloyd data delete\n\n\nDelete your datasets\n\n\n\n\n\n\nfloyd data output\n\n\nView contents of a dataset\n\n\n\n\n\n\n\n\nfloyd data init\n\n\nInitialize a Floyd dataset.\n\n\nUsage\n\n\nfloyd data init DATASET_NAME\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nDATASET_NAME\n\n\n\n\nName of the dataset (Pick a name from the dataset page in web dashboard)\n\n\n\n\n\n\n\n\nDescription\n\n\nFloyd can manage your experiment datasets and make them available when running your projects.This command initializes the \ncurrent directory and tracks all files and subdirectories. Make sure the dataset name you enter here already \nexists in Floyd. In case the dataset name does not exist, the CLI will open the create dataset page in your browser.\n\n\nThe init command also creates a \n.floydignore\n file. Any files and directories you do not want Floyd to track can be added \nto this file. When you upload this dataset to Floyd, these files will not be uploaded.\n\n\nExample\n\n\nInitialize a floyd dataset in your data directory.\n\n$ \ncd\n /data/mnist\n$ floyd data init mnist-data\nData \nsource\n \nmnist-data\n initialized in current directory\n\n\n\n\n\nfloyd data upload\n\n\nUpload a new version of dataset\n\n\nUsage\n\n\nfloyd data upload\n\n\n\n\nDescription\n\n\nUpload contents of the current directory as a new version of the dataset. This data can now be referred to in the \nrun\n command.\nAt run time the data will be available at the \n/input\n path.\n\n\nFloyd also versions your data so you can choose any specific version to use in your runs.\n\n\nExample\n\n\n$ floyd data upload\nCreating data source. Uploading files ...\nDATA ID                 NAME                \n----------------------  ------------------\nGY3QRFFUA8KpbnqvroTPPW  alice/mnist-data:1  \n\n\nFloyd will generate a data id for the uploaded dataset. This uploaded dataset can be used in your future experiments, if needed,\nusing this data id. See \nhere\n for more details.\n\n\n\n\nfloyd data status\n\n\nView your datasets on Floyd\n\n\nUsage\n\n\nfloyd data status \n[\nNAME or ID\n]\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nName or ID of your data.\n\n\n\n\n\n\n\n\nDescription\n\n\nLists all your datasets on Floyd with more details.\n\n\nExample\n\n\n$ floyd data status\nDATA ID                 CREATED         DISK USAGE    NAME               \n----------------------  --------------  ------------  ------------------\nHYLEc2czGKRpYVm7rGtBoY  \n12\n minutes ago  \n372\n.0 MB      floydhub/mnist:1  \nqNcS5bXHtFdSiMZ35kkEPh  an hour ago     \n456\n.2 MB      floydhub/csr:7    \n\n\n\n\n\n\nfloyd data delete\n\n\nDelete datasets on FloydHub\n\n\nUsage\n\n\nfloyd data delete \n[\nOPTIONS\n]\n \n[\nNAMES or IDS\n]\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNAMES or IDS\n\n\n\n\nOne or more Names or IDs of your data.\n\n\n\n\n\n\n--yes\n, \n-y\n\n\nFalse\n\n\nSkip delete confirmation step\n\n\n\n\n\n\n\n\nDescription\n\n\nDeletes your datasets from FloydHub. This data will no longer \nbe accessible.\n\n\nNote: You do \nnot\n have to be in the project directory to run this command.\n\n\nExample\n\n\n$ floyd data delete floydhub/csr:7\nDelete Data: floydhub/csr:7? \n[\ny/N\n]\n: y\nData deleted\n\n\n\n\n\n\nfloyd data output\n\n\nView datasets\n\n\nUsage\n\n\nfloyd data output \n[\nOPTIONS\n]\n ID\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--url\n, \n-u\n\n\n\n\nOnly print the URL. The data directory can be viewed in the browser.\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nNAME or ID of your data.\n\n\n\n\n\n\n\n\nDescription\n\n\nThe output command gives the url to access a dataset. This command by default opens the data url \nin your default browser.\n\n\nExample\n\n\n$ floyd data output floydhub/csr:11\nOpening output directory in your browser ...\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd data"
        }, 
        {
            "location": "/commands/data/#floyd-data-init", 
            "text": "Initialize a Floyd dataset.", 
            "title": "floyd data init"
        }, 
        {
            "location": "/commands/data/#usage", 
            "text": "floyd data init DATASET_NAME", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/data/#options", 
            "text": "Name, shorthand  Default  Description      DATASET_NAME   Name of the dataset (Pick a name from the dataset page in web dashboard)", 
            "title": "Options"
        }, 
        {
            "location": "/commands/data/#description", 
            "text": "Floyd can manage your experiment datasets and make them available when running your projects.This command initializes the \ncurrent directory and tracks all files and subdirectories. Make sure the dataset name you enter here already \nexists in Floyd. In case the dataset name does not exist, the CLI will open the create dataset page in your browser.  The init command also creates a  .floydignore  file. Any files and directories you do not want Floyd to track can be added \nto this file. When you upload this dataset to Floyd, these files will not be uploaded.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/data/#example", 
            "text": "Initialize a floyd dataset in your data directory. $  cd  /data/mnist\n$ floyd data init mnist-data\nData  source   mnist-data  initialized in current directory", 
            "title": "Example"
        }, 
        {
            "location": "/commands/data/#floyd-data-upload", 
            "text": "Upload a new version of dataset", 
            "title": "floyd data upload"
        }, 
        {
            "location": "/commands/data/#usage_1", 
            "text": "floyd data upload", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/data/#description_1", 
            "text": "Upload contents of the current directory as a new version of the dataset. This data can now be referred to in the  run  command.\nAt run time the data will be available at the  /input  path.  Floyd also versions your data so you can choose any specific version to use in your runs.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/data/#example_1", 
            "text": "$ floyd data upload\nCreating data source. Uploading files ...\nDATA ID                 NAME                \n----------------------  ------------------\nGY3QRFFUA8KpbnqvroTPPW  alice/mnist-data:1   \nFloyd will generate a data id for the uploaded dataset. This uploaded dataset can be used in your future experiments, if needed,\nusing this data id. See  here  for more details.", 
            "title": "Example"
        }, 
        {
            "location": "/commands/data/#floyd-data-status", 
            "text": "View your datasets on Floyd", 
            "title": "floyd data status"
        }, 
        {
            "location": "/commands/data/#usage_2", 
            "text": "floyd data status  [ NAME or ID ]", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/data/#options_1", 
            "text": "Name, shorthand  Default  Description      NAME or ID   Name or ID of your data.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/data/#description_2", 
            "text": "Lists all your datasets on Floyd with more details.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/data/#example_2", 
            "text": "$ floyd data status\nDATA ID                 CREATED         DISK USAGE    NAME               \n----------------------  --------------  ------------  ------------------\nHYLEc2czGKRpYVm7rGtBoY   12  minutes ago   372 .0 MB      floydhub/mnist:1  \nqNcS5bXHtFdSiMZ35kkEPh  an hour ago      456 .2 MB      floydhub/csr:7", 
            "title": "Example"
        }, 
        {
            "location": "/commands/data/#floyd-data-delete", 
            "text": "Delete datasets on FloydHub", 
            "title": "floyd data delete"
        }, 
        {
            "location": "/commands/data/#usage_3", 
            "text": "floyd data delete  [ OPTIONS ]   [ NAMES or IDS ]", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/data/#options_2", 
            "text": "Name, shorthand  Default  Description      NAMES or IDS   One or more Names or IDs of your data.    --yes ,  -y  False  Skip delete confirmation step", 
            "title": "Options"
        }, 
        {
            "location": "/commands/data/#description_3", 
            "text": "Deletes your datasets from FloydHub. This data will no longer \nbe accessible.  Note: You do  not  have to be in the project directory to run this command.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/data/#example_3", 
            "text": "$ floyd data delete floydhub/csr:7\nDelete Data: floydhub/csr:7?  [ y/N ] : y\nData deleted", 
            "title": "Example"
        }, 
        {
            "location": "/commands/data/#floyd-data-output", 
            "text": "View datasets", 
            "title": "floyd data output"
        }, 
        {
            "location": "/commands/data/#usage_4", 
            "text": "floyd data output  [ OPTIONS ]  ID", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/data/#options_3", 
            "text": "Name, shorthand  Default  Description      --url ,  -u   Only print the URL. The data directory can be viewed in the browser.    NAME or ID   NAME or ID of your data.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/data/#description_4", 
            "text": "The output command gives the url to access a dataset. This command by default opens the data url \nin your default browser.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/data/#example_4", 
            "text": "$ floyd data output floydhub/csr:11\nOpening output directory in your browser ...", 
            "title": "Example"
        }, 
        {
            "location": "/commands/data/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/logs/", 
            "text": "View the logs of your run\n\n\nUsage\n\n\nfloyd logs \n[\nOPTIONS\n]\n ID\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--url\n, \n-u\n\n\n\n\nOnly print the URL. The logs can be viewed in the browser.\n\n\n\n\n\n\n--tail\n, \n-t\n\n\n\n\nStream the output of your code in real-time.\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nName or ID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nAny data sent to STDOUT and STDERR by your code will become available here. Make sure your \nlogs are flushed out if you prefer to view logs in real-time. There will be some information from \nFloyd servers before and after your project logs. They are usually useful for debugging purposes.\n\n\nExample\n\n\n$ floyd logs floydhub/projects/style-transfer/4\nPreparing to run \nStarting container...\n\n\n#################################################\n\n\nRun Output:\n...\n\n\n#################################################\n\n\nWaiting \nfor\n container to complete...\n\n[\nsuccess\n]\n Finishing execution\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd logs"
        }, 
        {
            "location": "/commands/logs/#usage", 
            "text": "floyd logs  [ OPTIONS ]  ID", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/logs/#options", 
            "text": "Name, shorthand  Default  Description      --url ,  -u   Only print the URL. The logs can be viewed in the browser.    --tail ,  -t   Stream the output of your code in real-time.    NAME or ID   Name or ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/logs/#description", 
            "text": "Any data sent to STDOUT and STDERR by your code will become available here. Make sure your \nlogs are flushed out if you prefer to view logs in real-time. There will be some information from \nFloyd servers before and after your project logs. They are usually useful for debugging purposes.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/logs/#example", 
            "text": "$ floyd logs floydhub/projects/style-transfer/4\nPreparing to run \nStarting container... ################################################# \n\nRun Output:\n... ################################################# \n\nWaiting  for  container to complete... [ success ]  Finishing execution", 
            "title": "Example"
        }, 
        {
            "location": "/commands/logs/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/status/", 
            "text": "View status of your jobs.\n\n\nUsage\n\n\nfloyd status \n[\nNAME or ID\n]\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nName or ID\n\n\n\n\nID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nShows the status of a run, if the ID is specified. It can also list the status of all \nthe runs in the current project. You need to be in the project directory for this command to work.\n\n\nExample\n\n\n$ floyd status\nRUN ID                  CREATED         STATUS      DURATION\n(\ns\n)\n  NAME                           INSTANCE      VERSION\n----------------------  --------------  --------  -------------  -----------------------------  ----------  ---------\ndTe2cJJrNR2CBD74rSZXPA  \n31\n minutes ago  success             \n108\n  floydhub/tensorflow-project:7  cpu                 \n2\n\nB8wkLbuGs2mtjhe9jqrkYT  \n2\n hours ago     success            \n2349\n  floydhub/tensorflow-project:7  gpu                 \n1\n\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd status"
        }, 
        {
            "location": "/commands/status/#usage", 
            "text": "floyd status  [ NAME or ID ]", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/status/#options", 
            "text": "Name, shorthand  Default  Description      Name or ID   ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/status/#description", 
            "text": "Shows the status of a run, if the ID is specified. It can also list the status of all \nthe runs in the current project. You need to be in the project directory for this command to work.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/status/#example", 
            "text": "$ floyd status\nRUN ID                  CREATED         STATUS      DURATION ( s )   NAME                           INSTANCE      VERSION\n----------------------  --------------  --------  -------------  -----------------------------  ----------  ---------\ndTe2cJJrNR2CBD74rSZXPA   31  minutes ago  success              108   floydhub/tensorflow-project:7  cpu                  2 \nB8wkLbuGs2mtjhe9jqrkYT   2  hours ago     success             2349   floydhub/tensorflow-project:7  gpu                  1", 
            "title": "Example"
        }, 
        {
            "location": "/commands/status/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/output/", 
            "text": "View the output of a job.\n\n\nUsage\n\n\nfloyd output \n[\nOPTIONS\n]\n ID\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--url\n, \n-u\n\n\n\n\nOnly print the URL. The output directory can be viewed in the browser.\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nName or ID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nMost jobs generate output. Any output that needs to be retained after the job is finished should be send to \n/output\n path.\nThis is the only path Floyd will preserve. The output command gives the url to access this output. This command by default opens the \noutput url in your default browser.\n\n\nExample\n\n\n$ floyd output floydhub/projects/style-transfer/4\nOpening output directory in your browser ...\n\n\nor\n\n$ floyd output dTe2cJJrNR2CBD74rSZXPA\nOpening output directory in your browser ...\n\n\n\nDownloading output\n\n\nTo download the output you can use the data \nclone\n command.\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd output"
        }, 
        {
            "location": "/commands/output/#usage", 
            "text": "floyd output  [ OPTIONS ]  ID", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/output/#options", 
            "text": "Name, shorthand  Default  Description      --url ,  -u   Only print the URL. The output directory can be viewed in the browser.    NAME or ID   Name or ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/output/#description", 
            "text": "Most jobs generate output. Any output that needs to be retained after the job is finished should be send to  /output  path.\nThis is the only path Floyd will preserve. The output command gives the url to access this output. This command by default opens the \noutput url in your default browser.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/output/#example", 
            "text": "$ floyd output floydhub/projects/style-transfer/4\nOpening output directory in your browser ... \nor $ floyd output dTe2cJJrNR2CBD74rSZXPA\nOpening output directory in your browser ...", 
            "title": "Example"
        }, 
        {
            "location": "/commands/output/#downloading-output", 
            "text": "To download the output you can use the data  clone  command.", 
            "title": "Downloading output"
        }, 
        {
            "location": "/commands/output/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/clone/", 
            "text": "Clone the code for a specific job.\n\n\nUsage\n\n\nfloyd clone JOB_NAME\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nJOB_NAME or ID\n\n\n\n\nName or ID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nUse this command to clone an existing project on floyd. The code used for the job is downloaded to the \ncurrent directory. This will override any existing file or directory in the process.\n\n\nThis command is a great way to get started on floyd by starting from an existing project.\n\n\nExample\n\n\n$ floyd clone floydhub/projects/style-transfer/4\nDownloading the tar file to the current directory ...\nUntarring the contents of the file ...\nCleaning up the tar file ...\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd clone"
        }, 
        {
            "location": "/commands/clone/#usage", 
            "text": "floyd clone JOB_NAME", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/clone/#options", 
            "text": "Name, shorthand  Default  Description      JOB_NAME or ID   Name or ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/clone/#description", 
            "text": "Use this command to clone an existing project on floyd. The code used for the job is downloaded to the \ncurrent directory. This will override any existing file or directory in the process.  This command is a great way to get started on floyd by starting from an existing project.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/clone/#example", 
            "text": "$ floyd clone floydhub/projects/style-transfer/4\nDownloading the tar file to the current directory ...\nUntarring the contents of the file ...\nCleaning up the tar file ...", 
            "title": "Example"
        }, 
        {
            "location": "/commands/clone/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/info/", 
            "text": "View the details of a job.\n\n\nUsage\n\n\nfloyd info \n[\nOPTIONS\n]\n NAME\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nName or ID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nThis command gives detailed information about your job. Some useful information here:\n\n\nOutput ID\n\n\nOutput ID is the reference to the output generated by your run. \n\n\nUrl\n\n\nIf your job is running in \njupyter\n or \nserve\n mode, you can get their URL here.\n\n\nExample\n\n\n$ floyd info floydhub/jupyter-notebook/1\n-----------  ----------------------------------------------------\nRun ID       Faa2xpokjAfJL5Jd7vCVXo\nName         floydhub/jupyter-notebook/1\nCreated      \n2\n minutes ago\nStatus       running\nDuration\n(\ns\n)\n  \n0\n\nOutput ID    VB9bF6vtyvrHLdUsFbUuvW\nInstance     cpu\nVersion      \n1\n\nMode         jupyter\nUrl          https://www.floydhub.com:8000/VB9bF6vtyvrHLdUsFbUuvW\n-----------  ----------------------------------------------------\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd info"
        }, 
        {
            "location": "/commands/info/#usage", 
            "text": "floyd info  [ OPTIONS ]  NAME", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/info/#options", 
            "text": "Name, shorthand  Default  Description      NAME or ID   Name or ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/info/#description", 
            "text": "This command gives detailed information about your job. Some useful information here:", 
            "title": "Description"
        }, 
        {
            "location": "/commands/info/#output-id", 
            "text": "Output ID is the reference to the output generated by your run.", 
            "title": "Output ID"
        }, 
        {
            "location": "/commands/info/#url", 
            "text": "If your job is running in  jupyter  or  serve  mode, you can get their URL here.", 
            "title": "Url"
        }, 
        {
            "location": "/commands/info/#example", 
            "text": "$ floyd info floydhub/jupyter-notebook/1\n-----------  ----------------------------------------------------\nRun ID       Faa2xpokjAfJL5Jd7vCVXo\nName         floydhub/jupyter-notebook/1\nCreated       2  minutes ago\nStatus       running\nDuration ( s )    0 \nOutput ID    VB9bF6vtyvrHLdUsFbUuvW\nInstance     cpu\nVersion       1 \nMode         jupyter\nUrl          https://www.floydhub.com:8000/VB9bF6vtyvrHLdUsFbUuvW\n-----------  ----------------------------------------------------", 
            "title": "Example"
        }, 
        {
            "location": "/commands/info/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/stop/", 
            "text": "Terminate a queued or running job.\n\n\nUsage\n\n\nfloyd stop NAME\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nNAME or ID\n\n\n\n\nName or ID of your job.\n\n\n\n\n\n\n\n\nDescription\n\n\nSometimes you want to terminate a job before it can finish. The stop command sends a request \nto the server to stop the job. You can view the \nstatus\n of the job to confirm. When you stop \na job, you will be charged only for the duration your job was running.\n\n\nExample\n\n\n$ floyd stop floydhub/projects/tensorflow-example/4\nExperiment shutdown request submitted. Check status to confirm shutdown\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd stop"
        }, 
        {
            "location": "/commands/stop/#usage", 
            "text": "floyd stop NAME", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/stop/#options", 
            "text": "Name, shorthand  Default  Description      NAME or ID   Name or ID of your job.", 
            "title": "Options"
        }, 
        {
            "location": "/commands/stop/#description", 
            "text": "Sometimes you want to terminate a job before it can finish. The stop command sends a request \nto the server to stop the job. You can view the  status  of the job to confirm. When you stop \na job, you will be charged only for the duration your job was running.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/stop/#example", 
            "text": "$ floyd stop floydhub/projects/tensorflow-example/4\nExperiment shutdown request submitted. Check status to confirm shutdown", 
            "title": "Example"
        }, 
        {
            "location": "/commands/stop/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/delete/", 
            "text": "Delete one or more floyd jobs.\n\n\nUsage\n\n\nfloyd delete \n[\nIDS\n]\n\n\n\n\n\nOptions\n\n\n\n\n\n\n\n\nName, shorthand\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIDS\n\n\n\n\nOne or more IDs of your job.\n\n\n\n\n\n\n--yes\n, \n-y\n\n\nFalse\n\n\nSkip delete confirmation step\n\n\n\n\n\n\n\n\nDescription\n\n\nDeletes a job from FloydHub. The experiment information is no longer \navailable. You will not be able to access the code uploaded to run the \nexperiment. You need to make sure that the project is currently not \nrunning. If so, you can use the \nstop\n command for that.\n\n\nNote: You do \nnot\n have to be in the project directory to run this command.\n\n\nExample\n\n\n$ floyd delete J2ggstKWTNmL24nQTgi36o qNcS5bXHtFdSiMZ35kkEPh\nDelete Run: floydhub/fastText:1? \n[\ny/N\n]\n: y\nExperiment deleted\nDelete Run: floydhub/cnr:1? \n[\ny/N\n]\n: y\nExperiment deleted\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd delete"
        }, 
        {
            "location": "/commands/delete/#usage", 
            "text": "floyd delete  [ IDS ]", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/delete/#options", 
            "text": "Name, shorthand  Default  Description      IDS   One or more IDs of your job.    --yes ,  -y  False  Skip delete confirmation step", 
            "title": "Options"
        }, 
        {
            "location": "/commands/delete/#description", 
            "text": "Deletes a job from FloydHub. The experiment information is no longer \navailable. You will not be able to access the code uploaded to run the \nexperiment. You need to make sure that the project is currently not \nrunning. If so, you can use the  stop  command for that.  Note: You do  not  have to be in the project directory to run this command.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/delete/#example", 
            "text": "$ floyd delete J2ggstKWTNmL24nQTgi36o qNcS5bXHtFdSiMZ35kkEPh\nDelete Run: floydhub/fastText:1?  [ y/N ] : y\nExperiment deleted\nDelete Run: floydhub/cnr:1?  [ y/N ] : y\nExperiment deleted", 
            "title": "Example"
        }, 
        {
            "location": "/commands/delete/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/logout/", 
            "text": "Logout from Floyd.\n\n\nDescription\n\n\nLogout the CLI from Floyd\n\n\nUsage\n\n\nfloyd \nlogout\n\n\n\n\n\nDescription\n\n\nLogs you out and expires your current token. You will need to login again to run further commands.\n\n\nExample\n\n\n$ floyd \nlogout\n\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd logout"
        }, 
        {
            "location": "/commands/logout/#logout-from-floyd", 
            "text": "", 
            "title": "Logout from Floyd."
        }, 
        {
            "location": "/commands/logout/#description", 
            "text": "Logout the CLI from Floyd", 
            "title": "Description"
        }, 
        {
            "location": "/commands/logout/#usage", 
            "text": "floyd  logout", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/logout/#description_1", 
            "text": "Logs you out and expires your current token. You will need to login again to run further commands.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/logout/#example", 
            "text": "$ floyd  logout", 
            "title": "Example"
        }, 
        {
            "location": "/commands/logout/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/upgrade/", 
            "text": "Upgrade the floyd client.\n\n\nUsage\n\n\nfloyd upgrade\n\n\n\n\nDescription\n\n\nThis will upgrade the floyd cli to the latest version using pip.\n\n\nExample\n\n\n$ floyd upgrade\nCollecting floyd-cli from ...\n...\nSuccessfully installed floyd-cli-0.9.1\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd upgrade"
        }, 
        {
            "location": "/commands/upgrade/#usage", 
            "text": "floyd upgrade", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/upgrade/#description", 
            "text": "This will upgrade the floyd cli to the latest version using pip.", 
            "title": "Description"
        }, 
        {
            "location": "/commands/upgrade/#example", 
            "text": "$ floyd upgrade\nCollecting floyd-cli from ...\n...\nSuccessfully installed floyd-cli-0.9.1", 
            "title": "Example"
        }, 
        {
            "location": "/commands/upgrade/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/commands/version/", 
            "text": "Get the current version of floyd-cli\n\n\nUsage\n\n\nfloyd version\n\n\n\n\nDescription\n\n\nPrints the current version of floyd-cli\n\n\nExample\n\n\n$ floyd version\n\n0\n.9.1\n\n\n\n\n\n\nHelp make this document better\n\n\nThis guide, as well as the rest of our docs, are open-source and available on \n\nGitHub\n. We welcome your contributions.\n\n\n\n\nSuggest an edit to this page (by clicking the edit icon at the top next to the title).\n\n\nOpen an issue about this page\n to report a problem.", 
            "title": "floyd version"
        }, 
        {
            "location": "/commands/version/#usage", 
            "text": "floyd version", 
            "title": "Usage"
        }, 
        {
            "location": "/commands/version/#description", 
            "text": "Prints the current version of floyd-cli", 
            "title": "Description"
        }, 
        {
            "location": "/commands/version/#example", 
            "text": "$ floyd version 0 .9.1", 
            "title": "Example"
        }, 
        {
            "location": "/commands/version/#help-make-this-document-better", 
            "text": "This guide, as well as the rest of our docs, are open-source and available on  GitHub . We welcome your contributions.   Suggest an edit to this page (by clicking the edit icon at the top next to the title).  Open an issue about this page  to report a problem.", 
            "title": "Help make this document better"
        }, 
        {
            "location": "/changelogs/1/", 
            "text": "", 
            "title": "July 12 2017"
        }
    ]
}